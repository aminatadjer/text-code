{"repo": "openai/baselines", "path": "baselines/deepq/deepq.py", "func_name": "ActWrapper.save_act", "original_string": "def save_act(self, path=None):\n        \"\"\"Save model to a pickle located at `path`\"\"\"\n        if path is None:\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\n\n        with tempfile.TemporaryDirectory() as td:\n            save_variables(os.path.join(td, \"model\"))\n            arc_name = os.path.join(td, \"packed.zip\")\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\n                for root, dirs, files in os.walk(td):\n                    for fname in files:\n                        file_path = os.path.join(root, fname)\n                        if file_path != arc_name:\n                            zipf.write(file_path, os.path.relpath(file_path, td))\n            with open(arc_name, \"rb\") as f:\n                model_data = f.read()\n        with open(path, \"wb\") as f:\n            cloudpickle.dump((model_data, self._act_params), f)", "language": "python", "code": "def save_act(self, path=None):\n        \"\"\"Save model to a pickle located at `path`\"\"\"\n        if path is None:\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\n\n        with tempfile.TemporaryDirectory() as td:\n            save_variables(os.path.join(td, \"model\"))\n            arc_name = os.path.join(td, \"packed.zip\")\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\n                for root, dirs, files in os.walk(td):\n                    for fname in files:\n                        file_path = os.path.join(root, fname)\n                        if file_path != arc_name:\n                            zipf.write(file_path, os.path.relpath(file_path, td))\n            with open(arc_name, \"rb\") as f:\n                model_data = f.read()\n        with open(path, \"wb\") as f:\n            cloudpickle.dump((model_data, self._act_params), f)", "code_tokens": ["def", "save_act", "(", "self", ",", "path", "=", "None", ")", ":", "if", "path", "is", "None", ":", "path", "=", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "\"model.pkl\"", ")", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "save_variables", "(", "os", ".", "path", ".", "join", "(", "td", ",", "\"model\"", ")", ")", "arc_name", "=", "os", ".", "path", ".", "join", "(", "td", ",", "\"packed.zip\"", ")", "with", "zipfile", ".", "ZipFile", "(", "arc_name", ",", "'w'", ")", "as", "zipf", ":", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "td", ")", ":", "for", "fname", "in", "files", ":", "file_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "if", "file_path", "!=", "arc_name", ":", "zipf", ".", "write", "(", "file_path", ",", "os", ".", "path", ".", "relpath", "(", "file_path", ",", "td", ")", ")", "with", "open", "(", "arc_name", ",", "\"rb\"", ")", "as", "f", ":", "model_data", "=", "f", ".", "read", "(", ")", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "f", ":", "cloudpickle", ".", "dump", "(", "(", "model_data", ",", "self", ".", "_act_params", ")", ",", "f", ")"], "docstring": "Save model to a pickle located at `path`", "docstring_tokens": ["Save", "model", "to", "a", "pickle", "located", "at", "path"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/deepq/deepq.py#L55-L72", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/models.py", "func_name": "nature_cnn", "original_string": "def nature_cnn(unscaled_images, **conv_kwargs):\n    \"\"\"\n    CNN from Nature paper.\n    \"\"\"\n    scaled_images = tf.cast(unscaled_images, tf.float32) / 255.\n    activ = tf.nn.relu\n    h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2),\n                   **conv_kwargs))\n    h2 = activ(conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2), **conv_kwargs))\n    h3 = activ(conv(h2, 'c3', nf=64, rf=3, stride=1, init_scale=np.sqrt(2), **conv_kwargs))\n    h3 = conv_to_fc(h3)\n    return activ(fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2)))", "language": "python", "code": "def nature_cnn(unscaled_images, **conv_kwargs):\n    \"\"\"\n    CNN from Nature paper.\n    \"\"\"\n    scaled_images = tf.cast(unscaled_images, tf.float32) / 255.\n    activ = tf.nn.relu\n    h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2),\n                   **conv_kwargs))\n    h2 = activ(conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2), **conv_kwargs))\n    h3 = activ(conv(h2, 'c3', nf=64, rf=3, stride=1, init_scale=np.sqrt(2), **conv_kwargs))\n    h3 = conv_to_fc(h3)\n    return activ(fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2)))", "code_tokens": ["def", "nature_cnn", "(", "unscaled_images", ",", "*", "*", "conv_kwargs", ")", ":", "scaled_images", "=", "tf", ".", "cast", "(", "unscaled_images", ",", "tf", ".", "float32", ")", "/", "255.", "activ", "=", "tf", ".", "nn", ".", "relu", "h", "=", "activ", "(", "conv", "(", "scaled_images", ",", "'c1'", ",", "nf", "=", "32", ",", "rf", "=", "8", ",", "stride", "=", "4", ",", "init_scale", "=", "np", ".", "sqrt", "(", "2", ")", ",", "*", "*", "conv_kwargs", ")", ")", "h2", "=", "activ", "(", "conv", "(", "h", ",", "'c2'", ",", "nf", "=", "64", ",", "rf", "=", "4", ",", "stride", "=", "2", ",", "init_scale", "=", "np", ".", "sqrt", "(", "2", ")", ",", "*", "*", "conv_kwargs", ")", ")", "h3", "=", "activ", "(", "conv", "(", "h2", ",", "'c3'", ",", "nf", "=", "64", ",", "rf", "=", "3", ",", "stride", "=", "1", ",", "init_scale", "=", "np", ".", "sqrt", "(", "2", ")", ",", "*", "*", "conv_kwargs", ")", ")", "h3", "=", "conv_to_fc", "(", "h3", ")", "return", "activ", "(", "fc", "(", "h3", ",", "'fc1'", ",", "nh", "=", "512", ",", "init_scale", "=", "np", ".", "sqrt", "(", "2", ")", ")", ")"], "docstring": "CNN from Nature paper.", "docstring_tokens": ["CNN", "from", "Nature", "paper", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/models.py#L16-L27", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/models.py", "func_name": "conv_only", "original_string": "def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):\n    '''\n    convolutions-only net\n\n    Parameters:\n    ----------\n\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\n\n    Returns:\n\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer\n\n    '''\n\n    def network_fn(X):\n        out = tf.cast(X, tf.float32) / 255.\n        with tf.variable_scope(\"convnet\"):\n            for num_outputs, kernel_size, stride in convs:\n                out = layers.convolution2d(out,\n                                           num_outputs=num_outputs,\n                                           kernel_size=kernel_size,\n                                           stride=stride,\n                                           activation_fn=tf.nn.relu,\n                                           **conv_kwargs)\n\n        return out\n    return network_fn", "language": "python", "code": "def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):\n    '''\n    convolutions-only net\n\n    Parameters:\n    ----------\n\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\n\n    Returns:\n\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer\n\n    '''\n\n    def network_fn(X):\n        out = tf.cast(X, tf.float32) / 255.\n        with tf.variable_scope(\"convnet\"):\n            for num_outputs, kernel_size, stride in convs:\n                out = layers.convolution2d(out,\n                                           num_outputs=num_outputs,\n                                           kernel_size=kernel_size,\n                                           stride=stride,\n                                           activation_fn=tf.nn.relu,\n                                           **conv_kwargs)\n\n        return out\n    return network_fn", "code_tokens": ["def", "conv_only", "(", "convs", "=", "[", "(", "32", ",", "8", ",", "4", ")", ",", "(", "64", ",", "4", ",", "2", ")", ",", "(", "64", ",", "3", ",", "1", ")", "]", ",", "*", "*", "conv_kwargs", ")", ":", "def", "network_fn", "(", "X", ")", ":", "out", "=", "tf", ".", "cast", "(", "X", ",", "tf", ".", "float32", ")", "/", "255.", "with", "tf", ".", "variable_scope", "(", "\"convnet\"", ")", ":", "for", "num_outputs", ",", "kernel_size", ",", "stride", "in", "convs", ":", "out", "=", "layers", ".", "convolution2d", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "*", "*", "conv_kwargs", ")", "return", "out", "return", "network_fn"], "docstring": "convolutions-only net\n\n    Parameters:\n    ----------\n\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\n\n    Returns:\n\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer", "docstring_tokens": ["convolutions", "-", "only", "net"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/models.py#L171-L198", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/cmd_util.py", "func_name": "make_vec_env", "original_string": "def make_vec_env(env_id, env_type, num_env, seed,\n                 wrapper_kwargs=None,\n                 start_index=0,\n                 reward_scale=1.0,\n                 flatten_dict_observations=True,\n                 gamestate=None):\n    \"\"\"\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\n    \"\"\"\n    wrapper_kwargs = wrapper_kwargs or {}\n    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\n    seed = seed + 10000 * mpi_rank if seed is not None else None\n    logger_dir = logger.get_dir()\n    def make_thunk(rank):\n        return lambda: make_env(\n            env_id=env_id,\n            env_type=env_type,\n            mpi_rank=mpi_rank,\n            subrank=rank,\n            seed=seed,\n            reward_scale=reward_scale,\n            gamestate=gamestate,\n            flatten_dict_observations=flatten_dict_observations,\n            wrapper_kwargs=wrapper_kwargs,\n            logger_dir=logger_dir\n        )\n\n    set_global_seeds(seed)\n    if num_env > 1:\n        return SubprocVecEnv([make_thunk(i + start_index) for i in range(num_env)])\n    else:\n        return DummyVecEnv([make_thunk(start_index)])", "language": "python", "code": "def make_vec_env(env_id, env_type, num_env, seed,\n                 wrapper_kwargs=None,\n                 start_index=0,\n                 reward_scale=1.0,\n                 flatten_dict_observations=True,\n                 gamestate=None):\n    \"\"\"\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\n    \"\"\"\n    wrapper_kwargs = wrapper_kwargs or {}\n    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\n    seed = seed + 10000 * mpi_rank if seed is not None else None\n    logger_dir = logger.get_dir()\n    def make_thunk(rank):\n        return lambda: make_env(\n            env_id=env_id,\n            env_type=env_type,\n            mpi_rank=mpi_rank,\n            subrank=rank,\n            seed=seed,\n            reward_scale=reward_scale,\n            gamestate=gamestate,\n            flatten_dict_observations=flatten_dict_observations,\n            wrapper_kwargs=wrapper_kwargs,\n            logger_dir=logger_dir\n        )\n\n    set_global_seeds(seed)\n    if num_env > 1:\n        return SubprocVecEnv([make_thunk(i + start_index) for i in range(num_env)])\n    else:\n        return DummyVecEnv([make_thunk(start_index)])", "code_tokens": ["def", "make_vec_env", "(", "env_id", ",", "env_type", ",", "num_env", ",", "seed", ",", "wrapper_kwargs", "=", "None", ",", "start_index", "=", "0", ",", "reward_scale", "=", "1.0", ",", "flatten_dict_observations", "=", "True", ",", "gamestate", "=", "None", ")", ":", "wrapper_kwargs", "=", "wrapper_kwargs", "or", "{", "}", "mpi_rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "if", "MPI", "else", "0", "seed", "=", "seed", "+", "10000", "*", "mpi_rank", "if", "seed", "is", "not", "None", "else", "None", "logger_dir", "=", "logger", ".", "get_dir", "(", ")", "def", "make_thunk", "(", "rank", ")", ":", "return", "lambda", ":", "make_env", "(", "env_id", "=", "env_id", ",", "env_type", "=", "env_type", ",", "mpi_rank", "=", "mpi_rank", ",", "subrank", "=", "rank", ",", "seed", "=", "seed", ",", "reward_scale", "=", "reward_scale", ",", "gamestate", "=", "gamestate", ",", "flatten_dict_observations", "=", "flatten_dict_observations", ",", "wrapper_kwargs", "=", "wrapper_kwargs", ",", "logger_dir", "=", "logger_dir", ")", "set_global_seeds", "(", "seed", ")", "if", "num_env", ">", "1", ":", "return", "SubprocVecEnv", "(", "[", "make_thunk", "(", "i", "+", "start_index", ")", "for", "i", "in", "range", "(", "num_env", ")", "]", ")", "else", ":", "return", "DummyVecEnv", "(", "[", "make_thunk", "(", "start_index", ")", "]", ")"], "docstring": "Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.", "docstring_tokens": ["Create", "a", "wrapped", "monitored", "SubprocVecEnv", "for", "Atari", "and", "MuJoCo", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/cmd_util.py#L21-L52", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/cmd_util.py", "func_name": "parse_unknown_args", "original_string": "def parse_unknown_args(args):\n    \"\"\"\n    Parse arguments not consumed by arg parser into a dicitonary\n    \"\"\"\n    retval = {}\n    preceded_by_key = False\n    for arg in args:\n        if arg.startswith('--'):\n            if '=' in arg:\n                key = arg.split('=')[0][2:]\n                value = arg.split('=')[1]\n                retval[key] = value\n            else:\n                key = arg[2:]\n                preceded_by_key = True\n        elif preceded_by_key:\n            retval[key] = arg\n            preceded_by_key = False\n\n    return retval", "language": "python", "code": "def parse_unknown_args(args):\n    \"\"\"\n    Parse arguments not consumed by arg parser into a dicitonary\n    \"\"\"\n    retval = {}\n    preceded_by_key = False\n    for arg in args:\n        if arg.startswith('--'):\n            if '=' in arg:\n                key = arg.split('=')[0][2:]\n                value = arg.split('=')[1]\n                retval[key] = value\n            else:\n                key = arg[2:]\n                preceded_by_key = True\n        elif preceded_by_key:\n            retval[key] = arg\n            preceded_by_key = False\n\n    return retval", "code_tokens": ["def", "parse_unknown_args", "(", "args", ")", ":", "retval", "=", "{", "}", "preceded_by_key", "=", "False", "for", "arg", "in", "args", ":", "if", "arg", ".", "startswith", "(", "'--'", ")", ":", "if", "'='", "in", "arg", ":", "key", "=", "arg", ".", "split", "(", "'='", ")", "[", "0", "]", "[", "2", ":", "]", "value", "=", "arg", ".", "split", "(", "'='", ")", "[", "1", "]", "retval", "[", "key", "]", "=", "value", "else", ":", "key", "=", "arg", "[", "2", ":", "]", "preceded_by_key", "=", "True", "elif", "preceded_by_key", ":", "retval", "[", "key", "]", "=", "arg", "preceded_by_key", "=", "False", "return", "retval"], "docstring": "Parse arguments not consumed by arg parser into a dicitonary", "docstring_tokens": ["Parse", "arguments", "not", "consumed", "by", "arg", "parser", "into", "a", "dicitonary"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/cmd_util.py#L166-L185", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/vec_env/vec_env.py", "func_name": "clear_mpi_env_vars", "original_string": "def clear_mpi_env_vars():\n    \"\"\"\n    from mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.\n    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing\n    Processes.\n    \"\"\"\n    removed_environment = {}\n    for k, v in list(os.environ.items()):\n        for prefix in ['OMPI_', 'PMI_']:\n            if k.startswith(prefix):\n                removed_environment[k] = v\n                del os.environ[k]\n    try:\n        yield\n    finally:\n        os.environ.update(removed_environment)", "language": "python", "code": "def clear_mpi_env_vars():\n    \"\"\"\n    from mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.\n    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing\n    Processes.\n    \"\"\"\n    removed_environment = {}\n    for k, v in list(os.environ.items()):\n        for prefix in ['OMPI_', 'PMI_']:\n            if k.startswith(prefix):\n                removed_environment[k] = v\n                del os.environ[k]\n    try:\n        yield\n    finally:\n        os.environ.update(removed_environment)", "code_tokens": ["def", "clear_mpi_env_vars", "(", ")", ":", "removed_environment", "=", "{", "}", "for", "k", ",", "v", "in", "list", "(", "os", ".", "environ", ".", "items", "(", ")", ")", ":", "for", "prefix", "in", "[", "'OMPI_'", ",", "'PMI_'", "]", ":", "if", "k", ".", "startswith", "(", "prefix", ")", ":", "removed_environment", "[", "k", "]", "=", "v", "del", "os", ".", "environ", "[", "k", "]", "try", ":", "yield", "finally", ":", "os", ".", "environ", ".", "update", "(", "removed_environment", ")"], "docstring": "from mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.\n    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing\n    Processes.", "docstring_tokens": ["from", "mpi4py", "import", "MPI", "will", "call", "MPI_Init", "by", "default", ".", "If", "the", "child", "process", "has", "MPI", "environment", "variables", "MPI", "will", "think", "that", "the", "child", "process", "is", "an", "MPI", "process", "just", "like", "the", "parent", "and", "do", "bad", "things", "such", "as", "hang", ".", "This", "context", "manager", "is", "a", "hacky", "way", "to", "clear", "those", "environment", "variables", "temporarily", "such", "as", "when", "we", "are", "starting", "multiprocessing", "Processes", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/vec_env/vec_env.py#L204-L219", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/cg.py", "func_name": "cg", "original_string": "def cg(f_Ax, b, cg_iters=10, callback=None, verbose=False, residual_tol=1e-10):\n    \"\"\"\n    Demmel p 312\n    \"\"\"\n    p = b.copy()\n    r = b.copy()\n    x = np.zeros_like(b)\n    rdotr = r.dot(r)\n\n    fmtstr =  \"%10i %10.3g %10.3g\"\n    titlestr =  \"%10s %10s %10s\"\n    if verbose: print(titlestr % (\"iter\", \"residual norm\", \"soln norm\"))\n\n    for i in range(cg_iters):\n        if callback is not None:\n            callback(x)\n        if verbose: print(fmtstr % (i, rdotr, np.linalg.norm(x)))\n        z = f_Ax(p)\n        v = rdotr / p.dot(z)\n        x += v*p\n        r -= v*z\n        newrdotr = r.dot(r)\n        mu = newrdotr/rdotr\n        p = r + mu*p\n\n        rdotr = newrdotr\n        if rdotr < residual_tol:\n            break\n\n    if callback is not None:\n        callback(x)\n    if verbose: print(fmtstr % (i+1, rdotr, np.linalg.norm(x)))  # pylint: disable=W0631\n    return x", "language": "python", "code": "def cg(f_Ax, b, cg_iters=10, callback=None, verbose=False, residual_tol=1e-10):\n    \"\"\"\n    Demmel p 312\n    \"\"\"\n    p = b.copy()\n    r = b.copy()\n    x = np.zeros_like(b)\n    rdotr = r.dot(r)\n\n    fmtstr =  \"%10i %10.3g %10.3g\"\n    titlestr =  \"%10s %10s %10s\"\n    if verbose: print(titlestr % (\"iter\", \"residual norm\", \"soln norm\"))\n\n    for i in range(cg_iters):\n        if callback is not None:\n            callback(x)\n        if verbose: print(fmtstr % (i, rdotr, np.linalg.norm(x)))\n        z = f_Ax(p)\n        v = rdotr / p.dot(z)\n        x += v*p\n        r -= v*z\n        newrdotr = r.dot(r)\n        mu = newrdotr/rdotr\n        p = r + mu*p\n\n        rdotr = newrdotr\n        if rdotr < residual_tol:\n            break\n\n    if callback is not None:\n        callback(x)\n    if verbose: print(fmtstr % (i+1, rdotr, np.linalg.norm(x)))  # pylint: disable=W0631\n    return x", "code_tokens": ["def", "cg", "(", "f_Ax", ",", "b", ",", "cg_iters", "=", "10", ",", "callback", "=", "None", ",", "verbose", "=", "False", ",", "residual_tol", "=", "1e-10", ")", ":", "p", "=", "b", ".", "copy", "(", ")", "r", "=", "b", ".", "copy", "(", ")", "x", "=", "np", ".", "zeros_like", "(", "b", ")", "rdotr", "=", "r", ".", "dot", "(", "r", ")", "fmtstr", "=", "\"%10i %10.3g %10.3g\"", "titlestr", "=", "\"%10s %10s %10s\"", "if", "verbose", ":", "print", "(", "titlestr", "%", "(", "\"iter\"", ",", "\"residual norm\"", ",", "\"soln norm\"", ")", ")", "for", "i", "in", "range", "(", "cg_iters", ")", ":", "if", "callback", "is", "not", "None", ":", "callback", "(", "x", ")", "if", "verbose", ":", "print", "(", "fmtstr", "%", "(", "i", ",", "rdotr", ",", "np", ".", "linalg", ".", "norm", "(", "x", ")", ")", ")", "z", "=", "f_Ax", "(", "p", ")", "v", "=", "rdotr", "/", "p", ".", "dot", "(", "z", ")", "x", "+=", "v", "*", "p", "r", "-=", "v", "*", "z", "newrdotr", "=", "r", ".", "dot", "(", "r", ")", "mu", "=", "newrdotr", "/", "rdotr", "p", "=", "r", "+", "mu", "*", "p", "rdotr", "=", "newrdotr", "if", "rdotr", "<", "residual_tol", ":", "break", "if", "callback", "is", "not", "None", ":", "callback", "(", "x", ")", "if", "verbose", ":", "print", "(", "fmtstr", "%", "(", "i", "+", "1", ",", "rdotr", ",", "np", ".", "linalg", ".", "norm", "(", "x", ")", ")", ")", "# pylint: disable=W0631", "return", "x"], "docstring": "Demmel p 312", "docstring_tokens": ["Demmel", "p", "312"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/cg.py#L2-L34", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/input.py", "func_name": "observation_placeholder", "original_string": "def observation_placeholder(ob_space, batch_size=None, name='Ob'):\n    '''\n    Create placeholder to feed observations into of the size appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space     observation space\n\n    batch_size: int         size of the batch to be fed into input. Can be left None in most cases.\n\n    name: str               name of the placeholder\n\n    Returns:\n    -------\n\n    tensorflow placeholder tensor\n    '''\n\n    assert isinstance(ob_space, Discrete) or isinstance(ob_space, Box) or isinstance(ob_space, MultiDiscrete), \\\n        'Can only deal with Discrete and Box observation spaces for now'\n\n    dtype = ob_space.dtype\n    if dtype == np.int8:\n        dtype = np.uint8\n\n    return tf.placeholder(shape=(batch_size,) + ob_space.shape, dtype=dtype, name=name)", "language": "python", "code": "def observation_placeholder(ob_space, batch_size=None, name='Ob'):\n    '''\n    Create placeholder to feed observations into of the size appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space     observation space\n\n    batch_size: int         size of the batch to be fed into input. Can be left None in most cases.\n\n    name: str               name of the placeholder\n\n    Returns:\n    -------\n\n    tensorflow placeholder tensor\n    '''\n\n    assert isinstance(ob_space, Discrete) or isinstance(ob_space, Box) or isinstance(ob_space, MultiDiscrete), \\\n        'Can only deal with Discrete and Box observation spaces for now'\n\n    dtype = ob_space.dtype\n    if dtype == np.int8:\n        dtype = np.uint8\n\n    return tf.placeholder(shape=(batch_size,) + ob_space.shape, dtype=dtype, name=name)", "code_tokens": ["def", "observation_placeholder", "(", "ob_space", ",", "batch_size", "=", "None", ",", "name", "=", "'Ob'", ")", ":", "assert", "isinstance", "(", "ob_space", ",", "Discrete", ")", "or", "isinstance", "(", "ob_space", ",", "Box", ")", "or", "isinstance", "(", "ob_space", ",", "MultiDiscrete", ")", ",", "'Can only deal with Discrete and Box observation spaces for now'", "dtype", "=", "ob_space", ".", "dtype", "if", "dtype", "==", "np", ".", "int8", ":", "dtype", "=", "np", ".", "uint8", "return", "tf", ".", "placeholder", "(", "shape", "=", "(", "batch_size", ",", ")", "+", "ob_space", ".", "shape", ",", "dtype", "=", "dtype", ",", "name", "=", "name", ")"], "docstring": "Create placeholder to feed observations into of the size appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space     observation space\n\n    batch_size: int         size of the batch to be fed into input. Can be left None in most cases.\n\n    name: str               name of the placeholder\n\n    Returns:\n    -------\n\n    tensorflow placeholder tensor", "docstring_tokens": ["Create", "placeholder", "to", "feed", "observations", "into", "of", "the", "size", "appropriate", "to", "the", "observation", "space"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/input.py#L5-L31", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/input.py", "func_name": "observation_input", "original_string": "def observation_input(ob_space, batch_size=None, name='Ob'):\n    '''\n    Create placeholder to feed observations into of the size appropriate to the observation space, and add input\n    encoder of the appropriate type.\n    '''\n\n    placeholder = observation_placeholder(ob_space, batch_size, name)\n    return placeholder, encode_observation(ob_space, placeholder)", "language": "python", "code": "def observation_input(ob_space, batch_size=None, name='Ob'):\n    '''\n    Create placeholder to feed observations into of the size appropriate to the observation space, and add input\n    encoder of the appropriate type.\n    '''\n\n    placeholder = observation_placeholder(ob_space, batch_size, name)\n    return placeholder, encode_observation(ob_space, placeholder)", "code_tokens": ["def", "observation_input", "(", "ob_space", ",", "batch_size", "=", "None", ",", "name", "=", "'Ob'", ")", ":", "placeholder", "=", "observation_placeholder", "(", "ob_space", ",", "batch_size", ",", "name", ")", "return", "placeholder", ",", "encode_observation", "(", "ob_space", ",", "placeholder", ")"], "docstring": "Create placeholder to feed observations into of the size appropriate to the observation space, and add input\n    encoder of the appropriate type.", "docstring_tokens": ["Create", "placeholder", "to", "feed", "observations", "into", "of", "the", "size", "appropriate", "to", "the", "observation", "space", "and", "add", "input", "encoder", "of", "the", "appropriate", "type", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/input.py#L34-L41", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/input.py", "func_name": "encode_observation", "original_string": "def encode_observation(ob_space, placeholder):\n    '''\n    Encode input in the way that is appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space             observation space\n\n    placeholder: tf.placeholder     observation input placeholder\n    '''\n    if isinstance(ob_space, Discrete):\n        return tf.to_float(tf.one_hot(placeholder, ob_space.n))\n    elif isinstance(ob_space, Box):\n        return tf.to_float(placeholder)\n    elif isinstance(ob_space, MultiDiscrete):\n        placeholder = tf.cast(placeholder, tf.int32)\n        one_hots = [tf.to_float(tf.one_hot(placeholder[..., i], ob_space.nvec[i])) for i in range(placeholder.shape[-1])]\n        return tf.concat(one_hots, axis=-1)\n    else:\n        raise NotImplementedError", "language": "python", "code": "def encode_observation(ob_space, placeholder):\n    '''\n    Encode input in the way that is appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space             observation space\n\n    placeholder: tf.placeholder     observation input placeholder\n    '''\n    if isinstance(ob_space, Discrete):\n        return tf.to_float(tf.one_hot(placeholder, ob_space.n))\n    elif isinstance(ob_space, Box):\n        return tf.to_float(placeholder)\n    elif isinstance(ob_space, MultiDiscrete):\n        placeholder = tf.cast(placeholder, tf.int32)\n        one_hots = [tf.to_float(tf.one_hot(placeholder[..., i], ob_space.nvec[i])) for i in range(placeholder.shape[-1])]\n        return tf.concat(one_hots, axis=-1)\n    else:\n        raise NotImplementedError", "code_tokens": ["def", "encode_observation", "(", "ob_space", ",", "placeholder", ")", ":", "if", "isinstance", "(", "ob_space", ",", "Discrete", ")", ":", "return", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "placeholder", ",", "ob_space", ".", "n", ")", ")", "elif", "isinstance", "(", "ob_space", ",", "Box", ")", ":", "return", "tf", ".", "to_float", "(", "placeholder", ")", "elif", "isinstance", "(", "ob_space", ",", "MultiDiscrete", ")", ":", "placeholder", "=", "tf", ".", "cast", "(", "placeholder", ",", "tf", ".", "int32", ")", "one_hots", "=", "[", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "placeholder", "[", "...", ",", "i", "]", ",", "ob_space", ".", "nvec", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "placeholder", ".", "shape", "[", "-", "1", "]", ")", "]", "return", "tf", ".", "concat", "(", "one_hots", ",", "axis", "=", "-", "1", ")", "else", ":", "raise", "NotImplementedError"], "docstring": "Encode input in the way that is appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space             observation space\n\n    placeholder: tf.placeholder     observation input placeholder", "docstring_tokens": ["Encode", "input", "in", "the", "way", "that", "is", "appropriate", "to", "the", "observation", "space"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/input.py#L43-L63", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/rollout.py", "func_name": "RolloutWorker.save_policy", "original_string": "def save_policy(self, path):\n        \"\"\"Pickles the current policy for later inspection.\n        \"\"\"\n        with open(path, 'wb') as f:\n            pickle.dump(self.policy, f)", "language": "python", "code": "def save_policy(self, path):\n        \"\"\"Pickles the current policy for later inspection.\n        \"\"\"\n        with open(path, 'wb') as f:\n            pickle.dump(self.policy, f)", "code_tokens": ["def", "save_policy", "(", "self", ",", "path", ")", ":", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "pickle", ".", "dump", "(", "self", ".", "policy", ",", "f", ")"], "docstring": "Pickles the current policy for later inspection.", "docstring_tokens": ["Pickles", "the", "current", "policy", "for", "later", "inspection", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/rollout.py#L151-L155", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/rollout.py", "func_name": "RolloutWorker.logs", "original_string": "def logs(self, prefix='worker'):\n        \"\"\"Generates a dictionary that contains all collected statistics.\n        \"\"\"\n        logs = []\n        logs += [('success_rate', np.mean(self.success_history))]\n        if self.compute_Q:\n            logs += [('mean_Q', np.mean(self.Q_history))]\n        logs += [('episode', self.n_episodes)]\n\n        if prefix != '' and not prefix.endswith('/'):\n            return [(prefix + '/' + key, val) for key, val in logs]\n        else:\n            return logs", "language": "python", "code": "def logs(self, prefix='worker'):\n        \"\"\"Generates a dictionary that contains all collected statistics.\n        \"\"\"\n        logs = []\n        logs += [('success_rate', np.mean(self.success_history))]\n        if self.compute_Q:\n            logs += [('mean_Q', np.mean(self.Q_history))]\n        logs += [('episode', self.n_episodes)]\n\n        if prefix != '' and not prefix.endswith('/'):\n            return [(prefix + '/' + key, val) for key, val in logs]\n        else:\n            return logs", "code_tokens": ["def", "logs", "(", "self", ",", "prefix", "=", "'worker'", ")", ":", "logs", "=", "[", "]", "logs", "+=", "[", "(", "'success_rate'", ",", "np", ".", "mean", "(", "self", ".", "success_history", ")", ")", "]", "if", "self", ".", "compute_Q", ":", "logs", "+=", "[", "(", "'mean_Q'", ",", "np", ".", "mean", "(", "self", ".", "Q_history", ")", ")", "]", "logs", "+=", "[", "(", "'episode'", ",", "self", ".", "n_episodes", ")", "]", "if", "prefix", "!=", "''", "and", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "return", "[", "(", "prefix", "+", "'/'", "+", "key", ",", "val", ")", "for", "key", ",", "val", "in", "logs", "]", "else", ":", "return", "logs"], "docstring": "Generates a dictionary that contains all collected statistics.", "docstring_tokens": ["Generates", "a", "dictionary", "that", "contains", "all", "collected", "statistics", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/rollout.py#L157-L169", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/plot_util.py", "func_name": "smooth", "original_string": "def smooth(y, radius, mode='two_sided', valid_only=False):\n    '''\n    Smooth signal y, where radius is determines the size of the window\n\n    mode='twosided':\n        average over the window [max(index - radius, 0), min(index + radius, len(y)-1)]\n    mode='causal':\n        average over the window [max(index - radius, 0), index]\n\n    valid_only: put nan in entries where the full-sized window is not available\n\n    '''\n    assert mode in ('two_sided', 'causal')\n    if len(y) < 2*radius+1:\n        return np.ones_like(y) * y.mean()\n    elif mode == 'two_sided':\n        convkernel = np.ones(2 * radius+1)\n        out = np.convolve(y, convkernel,mode='same') / np.convolve(np.ones_like(y), convkernel, mode='same')\n        if valid_only:\n            out[:radius] = out[-radius:] = np.nan\n    elif mode == 'causal':\n        convkernel = np.ones(radius)\n        out = np.convolve(y, convkernel,mode='full') / np.convolve(np.ones_like(y), convkernel, mode='full')\n        out = out[:-radius+1]\n        if valid_only:\n            out[:radius] = np.nan\n    return out", "language": "python", "code": "def smooth(y, radius, mode='two_sided', valid_only=False):\n    '''\n    Smooth signal y, where radius is determines the size of the window\n\n    mode='twosided':\n        average over the window [max(index - radius, 0), min(index + radius, len(y)-1)]\n    mode='causal':\n        average over the window [max(index - radius, 0), index]\n\n    valid_only: put nan in entries where the full-sized window is not available\n\n    '''\n    assert mode in ('two_sided', 'causal')\n    if len(y) < 2*radius+1:\n        return np.ones_like(y) * y.mean()\n    elif mode == 'two_sided':\n        convkernel = np.ones(2 * radius+1)\n        out = np.convolve(y, convkernel,mode='same') / np.convolve(np.ones_like(y), convkernel, mode='same')\n        if valid_only:\n            out[:radius] = out[-radius:] = np.nan\n    elif mode == 'causal':\n        convkernel = np.ones(radius)\n        out = np.convolve(y, convkernel,mode='full') / np.convolve(np.ones_like(y), convkernel, mode='full')\n        out = out[:-radius+1]\n        if valid_only:\n            out[:radius] = np.nan\n    return out", "code_tokens": ["def", "smooth", "(", "y", ",", "radius", ",", "mode", "=", "'two_sided'", ",", "valid_only", "=", "False", ")", ":", "assert", "mode", "in", "(", "'two_sided'", ",", "'causal'", ")", "if", "len", "(", "y", ")", "<", "2", "*", "radius", "+", "1", ":", "return", "np", ".", "ones_like", "(", "y", ")", "*", "y", ".", "mean", "(", ")", "elif", "mode", "==", "'two_sided'", ":", "convkernel", "=", "np", ".", "ones", "(", "2", "*", "radius", "+", "1", ")", "out", "=", "np", ".", "convolve", "(", "y", ",", "convkernel", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "convkernel", ",", "mode", "=", "'same'", ")", "if", "valid_only", ":", "out", "[", ":", "radius", "]", "=", "out", "[", "-", "radius", ":", "]", "=", "np", ".", "nan", "elif", "mode", "==", "'causal'", ":", "convkernel", "=", "np", ".", "ones", "(", "radius", ")", "out", "=", "np", ".", "convolve", "(", "y", ",", "convkernel", ",", "mode", "=", "'full'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "convkernel", ",", "mode", "=", "'full'", ")", "out", "=", "out", "[", ":", "-", "radius", "+", "1", "]", "if", "valid_only", ":", "out", "[", ":", "radius", "]", "=", "np", ".", "nan", "return", "out"], "docstring": "Smooth signal y, where radius is determines the size of the window\n\n    mode='twosided':\n        average over the window [max(index - radius, 0), min(index + radius, len(y)-1)]\n    mode='causal':\n        average over the window [max(index - radius, 0), index]\n\n    valid_only: put nan in entries where the full-sized window is not available", "docstring_tokens": ["Smooth", "signal", "y", "where", "radius", "is", "determines", "the", "size", "of", "the", "window"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/plot_util.py#L11-L37", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/vec_env/util.py", "func_name": "copy_obs_dict", "original_string": "def copy_obs_dict(obs):\n    \"\"\"\n    Deep-copy an observation dict.\n    \"\"\"\n    return {k: np.copy(v) for k, v in obs.items()}", "language": "python", "code": "def copy_obs_dict(obs):\n    \"\"\"\n    Deep-copy an observation dict.\n    \"\"\"\n    return {k: np.copy(v) for k, v in obs.items()}", "code_tokens": ["def", "copy_obs_dict", "(", "obs", ")", ":", "return", "{", "k", ":", "np", ".", "copy", "(", "v", ")", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "}"], "docstring": "Deep-copy an observation dict.", "docstring_tokens": ["Deep", "-", "copy", "an", "observation", "dict", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/vec_env/util.py#L11-L15", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/vec_env/util.py", "func_name": "obs_space_info", "original_string": "def obs_space_info(obs_space):\n    \"\"\"\n    Get dict-structured information about a gym.Space.\n\n    Returns:\n      A tuple (keys, shapes, dtypes):\n        keys: a list of dict keys.\n        shapes: a dict mapping keys to shapes.\n        dtypes: a dict mapping keys to dtypes.\n    \"\"\"\n    if isinstance(obs_space, gym.spaces.Dict):\n        assert isinstance(obs_space.spaces, OrderedDict)\n        subspaces = obs_space.spaces\n    else:\n        subspaces = {None: obs_space}\n    keys = []\n    shapes = {}\n    dtypes = {}\n    for key, box in subspaces.items():\n        keys.append(key)\n        shapes[key] = box.shape\n        dtypes[key] = box.dtype\n    return keys, shapes, dtypes", "language": "python", "code": "def obs_space_info(obs_space):\n    \"\"\"\n    Get dict-structured information about a gym.Space.\n\n    Returns:\n      A tuple (keys, shapes, dtypes):\n        keys: a list of dict keys.\n        shapes: a dict mapping keys to shapes.\n        dtypes: a dict mapping keys to dtypes.\n    \"\"\"\n    if isinstance(obs_space, gym.spaces.Dict):\n        assert isinstance(obs_space.spaces, OrderedDict)\n        subspaces = obs_space.spaces\n    else:\n        subspaces = {None: obs_space}\n    keys = []\n    shapes = {}\n    dtypes = {}\n    for key, box in subspaces.items():\n        keys.append(key)\n        shapes[key] = box.shape\n        dtypes[key] = box.dtype\n    return keys, shapes, dtypes", "code_tokens": ["def", "obs_space_info", "(", "obs_space", ")", ":", "if", "isinstance", "(", "obs_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "assert", "isinstance", "(", "obs_space", ".", "spaces", ",", "OrderedDict", ")", "subspaces", "=", "obs_space", ".", "spaces", "else", ":", "subspaces", "=", "{", "None", ":", "obs_space", "}", "keys", "=", "[", "]", "shapes", "=", "{", "}", "dtypes", "=", "{", "}", "for", "key", ",", "box", "in", "subspaces", ".", "items", "(", ")", ":", "keys", ".", "append", "(", "key", ")", "shapes", "[", "key", "]", "=", "box", ".", "shape", "dtypes", "[", "key", "]", "=", "box", ".", "dtype", "return", "keys", ",", "shapes", ",", "dtypes"], "docstring": "Get dict-structured information about a gym.Space.\n\n    Returns:\n      A tuple (keys, shapes, dtypes):\n        keys: a list of dict keys.\n        shapes: a dict mapping keys to shapes.\n        dtypes: a dict mapping keys to dtypes.", "docstring_tokens": ["Get", "dict", "-", "structured", "information", "about", "a", "gym", ".", "Space", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/vec_env/util.py#L28-L50", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/acer/acer.py", "func_name": "q_retrace", "original_string": "def q_retrace(R, D, q_i, v, rho_i, nenvs, nsteps, gamma):\n    \"\"\"\n    Calculates q_retrace targets\n\n    :param R: Rewards\n    :param D: Dones\n    :param q_i: Q values for actions taken\n    :param v: V values\n    :param rho_i: Importance weight for each action\n    :return: Q_retrace values\n    \"\"\"\n    rho_bar = batch_to_seq(tf.minimum(1.0, rho_i), nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    rs = batch_to_seq(R, nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    ds = batch_to_seq(D, nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    q_is = batch_to_seq(q_i, nenvs, nsteps, True)\n    vs = batch_to_seq(v, nenvs, nsteps + 1, True)\n    v_final = vs[-1]\n    qret = v_final\n    qrets = []\n    for i in range(nsteps - 1, -1, -1):\n        check_shape([qret, ds[i], rs[i], rho_bar[i], q_is[i], vs[i]], [[nenvs]] * 6)\n        qret = rs[i] + gamma * qret * (1.0 - ds[i])\n        qrets.append(qret)\n        qret = (rho_bar[i] * (qret - q_is[i])) + vs[i]\n    qrets = qrets[::-1]\n    qret = seq_to_batch(qrets, flat=True)\n    return qret", "language": "python", "code": "def q_retrace(R, D, q_i, v, rho_i, nenvs, nsteps, gamma):\n    \"\"\"\n    Calculates q_retrace targets\n\n    :param R: Rewards\n    :param D: Dones\n    :param q_i: Q values for actions taken\n    :param v: V values\n    :param rho_i: Importance weight for each action\n    :return: Q_retrace values\n    \"\"\"\n    rho_bar = batch_to_seq(tf.minimum(1.0, rho_i), nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    rs = batch_to_seq(R, nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    ds = batch_to_seq(D, nenvs, nsteps, True)  # list of len steps, shape [nenvs]\n    q_is = batch_to_seq(q_i, nenvs, nsteps, True)\n    vs = batch_to_seq(v, nenvs, nsteps + 1, True)\n    v_final = vs[-1]\n    qret = v_final\n    qrets = []\n    for i in range(nsteps - 1, -1, -1):\n        check_shape([qret, ds[i], rs[i], rho_bar[i], q_is[i], vs[i]], [[nenvs]] * 6)\n        qret = rs[i] + gamma * qret * (1.0 - ds[i])\n        qrets.append(qret)\n        qret = (rho_bar[i] * (qret - q_is[i])) + vs[i]\n    qrets = qrets[::-1]\n    qret = seq_to_batch(qrets, flat=True)\n    return qret", "code_tokens": ["def", "q_retrace", "(", "R", ",", "D", ",", "q_i", ",", "v", ",", "rho_i", ",", "nenvs", ",", "nsteps", ",", "gamma", ")", ":", "rho_bar", "=", "batch_to_seq", "(", "tf", ".", "minimum", "(", "1.0", ",", "rho_i", ")", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "rs", "=", "batch_to_seq", "(", "R", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "ds", "=", "batch_to_seq", "(", "D", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "q_is", "=", "batch_to_seq", "(", "q_i", ",", "nenvs", ",", "nsteps", ",", "True", ")", "vs", "=", "batch_to_seq", "(", "v", ",", "nenvs", ",", "nsteps", "+", "1", ",", "True", ")", "v_final", "=", "vs", "[", "-", "1", "]", "qret", "=", "v_final", "qrets", "=", "[", "]", "for", "i", "in", "range", "(", "nsteps", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "check_shape", "(", "[", "qret", ",", "ds", "[", "i", "]", ",", "rs", "[", "i", "]", ",", "rho_bar", "[", "i", "]", ",", "q_is", "[", "i", "]", ",", "vs", "[", "i", "]", "]", ",", "[", "[", "nenvs", "]", "]", "*", "6", ")", "qret", "=", "rs", "[", "i", "]", "+", "gamma", "*", "qret", "*", "(", "1.0", "-", "ds", "[", "i", "]", ")", "qrets", ".", "append", "(", "qret", ")", "qret", "=", "(", "rho_bar", "[", "i", "]", "*", "(", "qret", "-", "q_is", "[", "i", "]", ")", ")", "+", "vs", "[", "i", "]", "qrets", "=", "qrets", "[", ":", ":", "-", "1", "]", "qret", "=", "seq_to_batch", "(", "qrets", ",", "flat", "=", "True", ")", "return", "qret"], "docstring": "Calculates q_retrace targets\n\n    :param R: Rewards\n    :param D: Dones\n    :param q_i: Q values for actions taken\n    :param v: V values\n    :param rho_i: Importance weight for each action\n    :return: Q_retrace values", "docstring_tokens": ["Calculates", "q_retrace", "targets"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/acer/acer.py#L25-L51", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/schedules.py", "func_name": "PiecewiseSchedule.value", "original_string": "def value(self, t):\n        \"\"\"See Schedule.value\"\"\"\n        for (l_t, l), (r_t, r) in zip(self._endpoints[:-1], self._endpoints[1:]):\n            if l_t <= t and t < r_t:\n                alpha = float(t - l_t) / (r_t - l_t)\n                return self._interpolation(l, r, alpha)\n\n        # t does not belong to any of the pieces, so doom.\n        assert self._outside_value is not None\n        return self._outside_value", "language": "python", "code": "def value(self, t):\n        \"\"\"See Schedule.value\"\"\"\n        for (l_t, l), (r_t, r) in zip(self._endpoints[:-1], self._endpoints[1:]):\n            if l_t <= t and t < r_t:\n                alpha = float(t - l_t) / (r_t - l_t)\n                return self._interpolation(l, r, alpha)\n\n        # t does not belong to any of the pieces, so doom.\n        assert self._outside_value is not None\n        return self._outside_value", "code_tokens": ["def", "value", "(", "self", ",", "t", ")", ":", "for", "(", "l_t", ",", "l", ")", ",", "(", "r_t", ",", "r", ")", "in", "zip", "(", "self", ".", "_endpoints", "[", ":", "-", "1", "]", ",", "self", ".", "_endpoints", "[", "1", ":", "]", ")", ":", "if", "l_t", "<=", "t", "and", "t", "<", "r_t", ":", "alpha", "=", "float", "(", "t", "-", "l_t", ")", "/", "(", "r_t", "-", "l_t", ")", "return", "self", ".", "_interpolation", "(", "l", ",", "r", ",", "alpha", ")", "# t does not belong to any of the pieces, so doom.", "assert", "self", ".", "_outside_value", "is", "not", "None", "return", "self", ".", "_outside_value"], "docstring": "See Schedule.value", "docstring_tokens": ["See", "Schedule", ".", "value"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/schedules.py#L64-L73", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/vec_env/shmem_vec_env.py", "func_name": "_subproc_worker", "original_string": "def _subproc_worker(pipe, parent_pipe, env_fn_wrapper, obs_bufs, obs_shapes, obs_dtypes, keys):\n    \"\"\"\n    Control a single environment instance using IPC and\n    shared memory.\n    \"\"\"\n    def _write_obs(maybe_dict_obs):\n        flatdict = obs_to_dict(maybe_dict_obs)\n        for k in keys:\n            dst = obs_bufs[k].get_obj()\n            dst_np = np.frombuffer(dst, dtype=obs_dtypes[k]).reshape(obs_shapes[k])  # pylint: disable=W0212\n            np.copyto(dst_np, flatdict[k])\n\n    env = env_fn_wrapper.x()\n    parent_pipe.close()\n    try:\n        while True:\n            cmd, data = pipe.recv()\n            if cmd == 'reset':\n                pipe.send(_write_obs(env.reset()))\n            elif cmd == 'step':\n                obs, reward, done, info = env.step(data)\n                if done:\n                    obs = env.reset()\n                pipe.send((_write_obs(obs), reward, done, info))\n            elif cmd == 'render':\n                pipe.send(env.render(mode='rgb_array'))\n            elif cmd == 'close':\n                pipe.send(None)\n                break\n            else:\n                raise RuntimeError('Got unrecognized cmd %s' % cmd)\n    except KeyboardInterrupt:\n        print('ShmemVecEnv worker: got KeyboardInterrupt')\n    finally:\n        env.close()", "language": "python", "code": "def _subproc_worker(pipe, parent_pipe, env_fn_wrapper, obs_bufs, obs_shapes, obs_dtypes, keys):\n    \"\"\"\n    Control a single environment instance using IPC and\n    shared memory.\n    \"\"\"\n    def _write_obs(maybe_dict_obs):\n        flatdict = obs_to_dict(maybe_dict_obs)\n        for k in keys:\n            dst = obs_bufs[k].get_obj()\n            dst_np = np.frombuffer(dst, dtype=obs_dtypes[k]).reshape(obs_shapes[k])  # pylint: disable=W0212\n            np.copyto(dst_np, flatdict[k])\n\n    env = env_fn_wrapper.x()\n    parent_pipe.close()\n    try:\n        while True:\n            cmd, data = pipe.recv()\n            if cmd == 'reset':\n                pipe.send(_write_obs(env.reset()))\n            elif cmd == 'step':\n                obs, reward, done, info = env.step(data)\n                if done:\n                    obs = env.reset()\n                pipe.send((_write_obs(obs), reward, done, info))\n            elif cmd == 'render':\n                pipe.send(env.render(mode='rgb_array'))\n            elif cmd == 'close':\n                pipe.send(None)\n                break\n            else:\n                raise RuntimeError('Got unrecognized cmd %s' % cmd)\n    except KeyboardInterrupt:\n        print('ShmemVecEnv worker: got KeyboardInterrupt')\n    finally:\n        env.close()", "code_tokens": ["def", "_subproc_worker", "(", "pipe", ",", "parent_pipe", ",", "env_fn_wrapper", ",", "obs_bufs", ",", "obs_shapes", ",", "obs_dtypes", ",", "keys", ")", ":", "def", "_write_obs", "(", "maybe_dict_obs", ")", ":", "flatdict", "=", "obs_to_dict", "(", "maybe_dict_obs", ")", "for", "k", "in", "keys", ":", "dst", "=", "obs_bufs", "[", "k", "]", ".", "get_obj", "(", ")", "dst_np", "=", "np", ".", "frombuffer", "(", "dst", ",", "dtype", "=", "obs_dtypes", "[", "k", "]", ")", ".", "reshape", "(", "obs_shapes", "[", "k", "]", ")", "# pylint: disable=W0212", "np", ".", "copyto", "(", "dst_np", ",", "flatdict", "[", "k", "]", ")", "env", "=", "env_fn_wrapper", ".", "x", "(", ")", "parent_pipe", ".", "close", "(", ")", "try", ":", "while", "True", ":", "cmd", ",", "data", "=", "pipe", ".", "recv", "(", ")", "if", "cmd", "==", "'reset'", ":", "pipe", ".", "send", "(", "_write_obs", "(", "env", ".", "reset", "(", ")", ")", ")", "elif", "cmd", "==", "'step'", ":", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "if", "done", ":", "obs", "=", "env", ".", "reset", "(", ")", "pipe", ".", "send", "(", "(", "_write_obs", "(", "obs", ")", ",", "reward", ",", "done", ",", "info", ")", ")", "elif", "cmd", "==", "'render'", ":", "pipe", ".", "send", "(", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", ")", "elif", "cmd", "==", "'close'", ":", "pipe", ".", "send", "(", "None", ")", "break", "else", ":", "raise", "RuntimeError", "(", "'Got unrecognized cmd %s'", "%", "cmd", ")", "except", "KeyboardInterrupt", ":", "print", "(", "'ShmemVecEnv worker: got KeyboardInterrupt'", ")", "finally", ":", "env", ".", "close", "(", ")"], "docstring": "Control a single environment instance using IPC and\n    shared memory.", "docstring_tokens": ["Control", "a", "single", "environment", "instance", "using", "IPC", "and", "shared", "memory", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/vec_env/shmem_vec_env.py#L105-L139", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/a2c/a2c.py", "func_name": "learn", "original_string": "def learn(\n    network,\n    env,\n    seed=None,\n    nsteps=5,\n    total_timesteps=int(80e6),\n    vf_coef=0.5,\n    ent_coef=0.01,\n    max_grad_norm=0.5,\n    lr=7e-4,\n    lrschedule='linear',\n    epsilon=1e-5,\n    alpha=0.99,\n    gamma=0.99,\n    log_interval=100,\n    load_path=None,\n    **network_kwargs):\n\n    '''\n    Main entrypoint for A2C algorithm. Train a policy with given network architecture on a given environment using a2c algorithm.\n\n    Parameters:\n    -----------\n\n    network:            policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                        specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                        tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                        neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                        See baselines.common/policies.py/lstm for more details on using recurrent nets in policies\n\n\n    env:                RL environment. Should implement interface similar to VecEnv (baselines.common/vec_env) or be wrapped with DummyVecEnv (baselines.common/vec_env/dummy_vec_env.py)\n\n\n    seed:               seed to make random number sequence in the alorightm reproducible. By default is None which means seed from system noise generator (not reproducible)\n\n    nsteps:             int, number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                        nenv is number of environment copies simulated in parallel)\n\n    total_timesteps:    int, total number of timesteps to train on (default: 80M)\n\n    vf_coef:            float, coefficient in front of value function loss in the total loss function (default: 0.5)\n\n    ent_coef:           float, coeffictiant in front of the policy entropy in the total loss function (default: 0.01)\n\n    max_gradient_norm:  float, gradient is clipped to have global L2 norm no more than this value (default: 0.5)\n\n    lr:                 float, learning rate for RMSProp (current implementation has RMSProp hardcoded in) (default: 7e-4)\n\n    lrschedule:         schedule of learning rate. Can be 'linear', 'constant', or a function [0..1] -> [0..1] that takes fraction of the training progress as input and\n                        returns fraction of the learning rate (specified as lr) as output\n\n    epsilon:            float, RMSProp epsilon (stabilizes square root computation in denominator of RMSProp update) (default: 1e-5)\n\n    alpha:              float, RMSProp decay parameter (default: 0.99)\n\n    gamma:              float, reward discounting parameter (default: 0.99)\n\n    log_interval:       int, specifies how frequently the logs are printed out (default: 100)\n\n    **network_kwargs:   keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                        For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n\n    '''\n\n\n\n    set_global_seeds(seed)\n\n    # Get the nb of env\n    nenvs = env.num_envs\n    policy = build_policy(env, network, **network_kwargs)\n\n    # Instantiate the model object (that creates step_model and train_model)\n    model = Model(policy=policy, env=env, nsteps=nsteps, ent_coef=ent_coef, vf_coef=vf_coef,\n        max_grad_norm=max_grad_norm, lr=lr, alpha=alpha, epsilon=epsilon, total_timesteps=total_timesteps, lrschedule=lrschedule)\n    if load_path is not None:\n        model.load(load_path)\n\n    # Instantiate the runner object\n    runner = Runner(env, model, nsteps=nsteps, gamma=gamma)\n    epinfobuf = deque(maxlen=100)\n\n    # Calculate the batch_size\n    nbatch = nenvs*nsteps\n\n    # Start total timer\n    tstart = time.time()\n\n    for update in range(1, total_timesteps//nbatch+1):\n        # Get mini batch of experiences\n        obs, states, rewards, masks, actions, values, epinfos = runner.run()\n        epinfobuf.extend(epinfos)\n\n        policy_loss, value_loss, policy_entropy = model.train(obs, states, rewards, masks, actions, values)\n        nseconds = time.time()-tstart\n\n        # Calculate the fps (frame per second)\n        fps = int((update*nbatch)/nseconds)\n        if update % log_interval == 0 or update == 1:\n            # Calculates if value function is a good predicator of the returns (ev > 1)\n            # or if it's just worse than predicting nothing (ev =< 0)\n            ev = explained_variance(values, rewards)\n            logger.record_tabular(\"nupdates\", update)\n            logger.record_tabular(\"total_timesteps\", update*nbatch)\n            logger.record_tabular(\"fps\", fps)\n            logger.record_tabular(\"policy_entropy\", float(policy_entropy))\n            logger.record_tabular(\"value_loss\", float(value_loss))\n            logger.record_tabular(\"explained_variance\", float(ev))\n            logger.record_tabular(\"eprewmean\", safemean([epinfo['r'] for epinfo in epinfobuf]))\n            logger.record_tabular(\"eplenmean\", safemean([epinfo['l'] for epinfo in epinfobuf]))\n            logger.dump_tabular()\n    return model", "language": "python", "code": "def learn(\n    network,\n    env,\n    seed=None,\n    nsteps=5,\n    total_timesteps=int(80e6),\n    vf_coef=0.5,\n    ent_coef=0.01,\n    max_grad_norm=0.5,\n    lr=7e-4,\n    lrschedule='linear',\n    epsilon=1e-5,\n    alpha=0.99,\n    gamma=0.99,\n    log_interval=100,\n    load_path=None,\n    **network_kwargs):\n\n    '''\n    Main entrypoint for A2C algorithm. Train a policy with given network architecture on a given environment using a2c algorithm.\n\n    Parameters:\n    -----------\n\n    network:            policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                        specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                        tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                        neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                        See baselines.common/policies.py/lstm for more details on using recurrent nets in policies\n\n\n    env:                RL environment. Should implement interface similar to VecEnv (baselines.common/vec_env) or be wrapped with DummyVecEnv (baselines.common/vec_env/dummy_vec_env.py)\n\n\n    seed:               seed to make random number sequence in the alorightm reproducible. By default is None which means seed from system noise generator (not reproducible)\n\n    nsteps:             int, number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                        nenv is number of environment copies simulated in parallel)\n\n    total_timesteps:    int, total number of timesteps to train on (default: 80M)\n\n    vf_coef:            float, coefficient in front of value function loss in the total loss function (default: 0.5)\n\n    ent_coef:           float, coeffictiant in front of the policy entropy in the total loss function (default: 0.01)\n\n    max_gradient_norm:  float, gradient is clipped to have global L2 norm no more than this value (default: 0.5)\n\n    lr:                 float, learning rate for RMSProp (current implementation has RMSProp hardcoded in) (default: 7e-4)\n\n    lrschedule:         schedule of learning rate. Can be 'linear', 'constant', or a function [0..1] -> [0..1] that takes fraction of the training progress as input and\n                        returns fraction of the learning rate (specified as lr) as output\n\n    epsilon:            float, RMSProp epsilon (stabilizes square root computation in denominator of RMSProp update) (default: 1e-5)\n\n    alpha:              float, RMSProp decay parameter (default: 0.99)\n\n    gamma:              float, reward discounting parameter (default: 0.99)\n\n    log_interval:       int, specifies how frequently the logs are printed out (default: 100)\n\n    **network_kwargs:   keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                        For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n\n    '''\n\n\n\n    set_global_seeds(seed)\n\n    # Get the nb of env\n    nenvs = env.num_envs\n    policy = build_policy(env, network, **network_kwargs)\n\n    # Instantiate the model object (that creates step_model and train_model)\n    model = Model(policy=policy, env=env, nsteps=nsteps, ent_coef=ent_coef, vf_coef=vf_coef,\n        max_grad_norm=max_grad_norm, lr=lr, alpha=alpha, epsilon=epsilon, total_timesteps=total_timesteps, lrschedule=lrschedule)\n    if load_path is not None:\n        model.load(load_path)\n\n    # Instantiate the runner object\n    runner = Runner(env, model, nsteps=nsteps, gamma=gamma)\n    epinfobuf = deque(maxlen=100)\n\n    # Calculate the batch_size\n    nbatch = nenvs*nsteps\n\n    # Start total timer\n    tstart = time.time()\n\n    for update in range(1, total_timesteps//nbatch+1):\n        # Get mini batch of experiences\n        obs, states, rewards, masks, actions, values, epinfos = runner.run()\n        epinfobuf.extend(epinfos)\n\n        policy_loss, value_loss, policy_entropy = model.train(obs, states, rewards, masks, actions, values)\n        nseconds = time.time()-tstart\n\n        # Calculate the fps (frame per second)\n        fps = int((update*nbatch)/nseconds)\n        if update % log_interval == 0 or update == 1:\n            # Calculates if value function is a good predicator of the returns (ev > 1)\n            # or if it's just worse than predicting nothing (ev =< 0)\n            ev = explained_variance(values, rewards)\n            logger.record_tabular(\"nupdates\", update)\n            logger.record_tabular(\"total_timesteps\", update*nbatch)\n            logger.record_tabular(\"fps\", fps)\n            logger.record_tabular(\"policy_entropy\", float(policy_entropy))\n            logger.record_tabular(\"value_loss\", float(value_loss))\n            logger.record_tabular(\"explained_variance\", float(ev))\n            logger.record_tabular(\"eprewmean\", safemean([epinfo['r'] for epinfo in epinfobuf]))\n            logger.record_tabular(\"eplenmean\", safemean([epinfo['l'] for epinfo in epinfobuf]))\n            logger.dump_tabular()\n    return model", "code_tokens": ["def", "learn", "(", "network", ",", "env", ",", "seed", "=", "None", ",", "nsteps", "=", "5", ",", "total_timesteps", "=", "int", "(", "80e6", ")", ",", "vf_coef", "=", "0.5", ",", "ent_coef", "=", "0.01", ",", "max_grad_norm", "=", "0.5", ",", "lr", "=", "7e-4", ",", "lrschedule", "=", "'linear'", ",", "epsilon", "=", "1e-5", ",", "alpha", "=", "0.99", ",", "gamma", "=", "0.99", ",", "log_interval", "=", "100", ",", "load_path", "=", "None", ",", "*", "*", "network_kwargs", ")", ":", "set_global_seeds", "(", "seed", ")", "# Get the nb of env", "nenvs", "=", "env", ".", "num_envs", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "*", "*", "network_kwargs", ")", "# Instantiate the model object (that creates step_model and train_model)", "model", "=", "Model", "(", "policy", "=", "policy", ",", "env", "=", "env", ",", "nsteps", "=", "nsteps", ",", "ent_coef", "=", "ent_coef", ",", "vf_coef", "=", "vf_coef", ",", "max_grad_norm", "=", "max_grad_norm", ",", "lr", "=", "lr", ",", "alpha", "=", "alpha", ",", "epsilon", "=", "epsilon", ",", "total_timesteps", "=", "total_timesteps", ",", "lrschedule", "=", "lrschedule", ")", "if", "load_path", "is", "not", "None", ":", "model", ".", "load", "(", "load_path", ")", "# Instantiate the runner object", "runner", "=", "Runner", "(", "env", ",", "model", ",", "nsteps", "=", "nsteps", ",", "gamma", "=", "gamma", ")", "epinfobuf", "=", "deque", "(", "maxlen", "=", "100", ")", "# Calculate the batch_size", "nbatch", "=", "nenvs", "*", "nsteps", "# Start total timer", "tstart", "=", "time", ".", "time", "(", ")", "for", "update", "in", "range", "(", "1", ",", "total_timesteps", "//", "nbatch", "+", "1", ")", ":", "# Get mini batch of experiences", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ",", "epinfos", "=", "runner", ".", "run", "(", ")", "epinfobuf", ".", "extend", "(", "epinfos", ")", "policy_loss", ",", "value_loss", ",", "policy_entropy", "=", "model", ".", "train", "(", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ")", "nseconds", "=", "time", ".", "time", "(", ")", "-", "tstart", "# Calculate the fps (frame per second)", "fps", "=", "int", "(", "(", "update", "*", "nbatch", ")", "/", "nseconds", ")", "if", "update", "%", "log_interval", "==", "0", "or", "update", "==", "1", ":", "# Calculates if value function is a good predicator of the returns (ev > 1)", "# or if it's just worse than predicting nothing (ev =< 0)", "ev", "=", "explained_variance", "(", "values", ",", "rewards", ")", "logger", ".", "record_tabular", "(", "\"nupdates\"", ",", "update", ")", "logger", ".", "record_tabular", "(", "\"total_timesteps\"", ",", "update", "*", "nbatch", ")", "logger", ".", "record_tabular", "(", "\"fps\"", ",", "fps", ")", "logger", ".", "record_tabular", "(", "\"policy_entropy\"", ",", "float", "(", "policy_entropy", ")", ")", "logger", ".", "record_tabular", "(", "\"value_loss\"", ",", "float", "(", "value_loss", ")", ")", "logger", ".", "record_tabular", "(", "\"explained_variance\"", ",", "float", "(", "ev", ")", ")", "logger", ".", "record_tabular", "(", "\"eprewmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'r'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "logger", ".", "record_tabular", "(", "\"eplenmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'l'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "logger", ".", "dump_tabular", "(", ")", "return", "model"], "docstring": "Main entrypoint for A2C algorithm. Train a policy with given network architecture on a given environment using a2c algorithm.\n\n    Parameters:\n    -----------\n\n    network:            policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                        specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                        tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                        neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                        See baselines.common/policies.py/lstm for more details on using recurrent nets in policies\n\n\n    env:                RL environment. Should implement interface similar to VecEnv (baselines.common/vec_env) or be wrapped with DummyVecEnv (baselines.common/vec_env/dummy_vec_env.py)\n\n\n    seed:               seed to make random number sequence in the alorightm reproducible. By default is None which means seed from system noise generator (not reproducible)\n\n    nsteps:             int, number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                        nenv is number of environment copies simulated in parallel)\n\n    total_timesteps:    int, total number of timesteps to train on (default: 80M)\n\n    vf_coef:            float, coefficient in front of value function loss in the total loss function (default: 0.5)\n\n    ent_coef:           float, coeffictiant in front of the policy entropy in the total loss function (default: 0.01)\n\n    max_gradient_norm:  float, gradient is clipped to have global L2 norm no more than this value (default: 0.5)\n\n    lr:                 float, learning rate for RMSProp (current implementation has RMSProp hardcoded in) (default: 7e-4)\n\n    lrschedule:         schedule of learning rate. Can be 'linear', 'constant', or a function [0..1] -> [0..1] that takes fraction of the training progress as input and\n                        returns fraction of the learning rate (specified as lr) as output\n\n    epsilon:            float, RMSProp epsilon (stabilizes square root computation in denominator of RMSProp update) (default: 1e-5)\n\n    alpha:              float, RMSProp decay parameter (default: 0.99)\n\n    gamma:              float, reward discounting parameter (default: 0.99)\n\n    log_interval:       int, specifies how frequently the logs are printed out (default: 100)\n\n    **network_kwargs:   keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                        For instance, 'mlp' network architecture has arguments num_hidden and num_layers.", "docstring_tokens": ["Main", "entrypoint", "for", "A2C", "algorithm", ".", "Train", "a", "policy", "with", "given", "network", "architecture", "on", "a", "given", "environment", "using", "a2c", "algorithm", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/a2c/a2c.py#L119-L231", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/ppo2/runner.py", "func_name": "sf01", "original_string": "def sf01(arr):\n    \"\"\"\n    swap and then flatten axes 0 and 1\n    \"\"\"\n    s = arr.shape\n    return arr.swapaxes(0, 1).reshape(s[0] * s[1], *s[2:])", "language": "python", "code": "def sf01(arr):\n    \"\"\"\n    swap and then flatten axes 0 and 1\n    \"\"\"\n    s = arr.shape\n    return arr.swapaxes(0, 1).reshape(s[0] * s[1], *s[2:])", "code_tokens": ["def", "sf01", "(", "arr", ")", ":", "s", "=", "arr", ".", "shape", "return", "arr", ".", "swapaxes", "(", "0", ",", "1", ")", ".", "reshape", "(", "s", "[", "0", "]", "*", "s", "[", "1", "]", ",", "*", "s", "[", "2", ":", "]", ")"], "docstring": "swap and then flatten axes 0 and 1", "docstring_tokens": ["swap", "and", "then", "flatten", "axes", "0", "and", "1"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/ppo2/runner.py#L69-L74", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/misc_util.py", "func_name": "pretty_eta", "original_string": "def pretty_eta(seconds_left):\n    \"\"\"Print the number of seconds in human readable format.\n\n    Examples:\n    2 days\n    2 hours and 37 minutes\n    less than a minute\n\n    Paramters\n    ---------\n    seconds_left: int\n        Number of seconds to be converted to the ETA\n    Returns\n    -------\n    eta: str\n        String representing the pretty ETA.\n    \"\"\"\n    minutes_left = seconds_left // 60\n    seconds_left %= 60\n    hours_left = minutes_left // 60\n    minutes_left %= 60\n    days_left = hours_left // 24\n    hours_left %= 24\n\n    def helper(cnt, name):\n        return \"{} {}{}\".format(str(cnt), name, ('s' if cnt > 1 else ''))\n\n    if days_left > 0:\n        msg = helper(days_left, 'day')\n        if hours_left > 0:\n            msg += ' and ' + helper(hours_left, 'hour')\n        return msg\n    if hours_left > 0:\n        msg = helper(hours_left, 'hour')\n        if minutes_left > 0:\n            msg += ' and ' + helper(minutes_left, 'minute')\n        return msg\n    if minutes_left > 0:\n        return helper(minutes_left, 'minute')\n    return 'less than a minute'", "language": "python", "code": "def pretty_eta(seconds_left):\n    \"\"\"Print the number of seconds in human readable format.\n\n    Examples:\n    2 days\n    2 hours and 37 minutes\n    less than a minute\n\n    Paramters\n    ---------\n    seconds_left: int\n        Number of seconds to be converted to the ETA\n    Returns\n    -------\n    eta: str\n        String representing the pretty ETA.\n    \"\"\"\n    minutes_left = seconds_left // 60\n    seconds_left %= 60\n    hours_left = minutes_left // 60\n    minutes_left %= 60\n    days_left = hours_left // 24\n    hours_left %= 24\n\n    def helper(cnt, name):\n        return \"{} {}{}\".format(str(cnt), name, ('s' if cnt > 1 else ''))\n\n    if days_left > 0:\n        msg = helper(days_left, 'day')\n        if hours_left > 0:\n            msg += ' and ' + helper(hours_left, 'hour')\n        return msg\n    if hours_left > 0:\n        msg = helper(hours_left, 'hour')\n        if minutes_left > 0:\n            msg += ' and ' + helper(minutes_left, 'minute')\n        return msg\n    if minutes_left > 0:\n        return helper(minutes_left, 'minute')\n    return 'less than a minute'", "code_tokens": ["def", "pretty_eta", "(", "seconds_left", ")", ":", "minutes_left", "=", "seconds_left", "//", "60", "seconds_left", "%=", "60", "hours_left", "=", "minutes_left", "//", "60", "minutes_left", "%=", "60", "days_left", "=", "hours_left", "//", "24", "hours_left", "%=", "24", "def", "helper", "(", "cnt", ",", "name", ")", ":", "return", "\"{} {}{}\"", ".", "format", "(", "str", "(", "cnt", ")", ",", "name", ",", "(", "'s'", "if", "cnt", ">", "1", "else", "''", ")", ")", "if", "days_left", ">", "0", ":", "msg", "=", "helper", "(", "days_left", ",", "'day'", ")", "if", "hours_left", ">", "0", ":", "msg", "+=", "' and '", "+", "helper", "(", "hours_left", ",", "'hour'", ")", "return", "msg", "if", "hours_left", ">", "0", ":", "msg", "=", "helper", "(", "hours_left", ",", "'hour'", ")", "if", "minutes_left", ">", "0", ":", "msg", "+=", "' and '", "+", "helper", "(", "minutes_left", ",", "'minute'", ")", "return", "msg", "if", "minutes_left", ">", "0", ":", "return", "helper", "(", "minutes_left", ",", "'minute'", ")", "return", "'less than a minute'"], "docstring": "Print the number of seconds in human readable format.\n\n    Examples:\n    2 days\n    2 hours and 37 minutes\n    less than a minute\n\n    Paramters\n    ---------\n    seconds_left: int\n        Number of seconds to be converted to the ETA\n    Returns\n    -------\n    eta: str\n        String representing the pretty ETA.", "docstring_tokens": ["Print", "the", "number", "of", "seconds", "in", "human", "readable", "format", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/misc_util.py#L65-L104", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/misc_util.py", "func_name": "boolean_flag", "original_string": "def boolean_flag(parser, name, default=False, help=None):\n    \"\"\"Add a boolean flag to argparse parser.\n\n    Parameters\n    ----------\n    parser: argparse.Parser\n        parser to add the flag to\n    name: str\n        --<name> will enable the flag, while --no-<name> will disable it\n    default: bool or None\n        default value of the flag\n    help: str\n        help string for the flag\n    \"\"\"\n    dest = name.replace('-', '_')\n    parser.add_argument(\"--\" + name, action=\"store_true\", default=default, dest=dest, help=help)\n    parser.add_argument(\"--no-\" + name, action=\"store_false\", dest=dest)", "language": "python", "code": "def boolean_flag(parser, name, default=False, help=None):\n    \"\"\"Add a boolean flag to argparse parser.\n\n    Parameters\n    ----------\n    parser: argparse.Parser\n        parser to add the flag to\n    name: str\n        --<name> will enable the flag, while --no-<name> will disable it\n    default: bool or None\n        default value of the flag\n    help: str\n        help string for the flag\n    \"\"\"\n    dest = name.replace('-', '_')\n    parser.add_argument(\"--\" + name, action=\"store_true\", default=default, dest=dest, help=help)\n    parser.add_argument(\"--no-\" + name, action=\"store_false\", dest=dest)", "code_tokens": ["def", "boolean_flag", "(", "parser", ",", "name", ",", "default", "=", "False", ",", "help", "=", "None", ")", ":", "dest", "=", "name", ".", "replace", "(", "'-'", ",", "'_'", ")", "parser", ".", "add_argument", "(", "\"--\"", "+", "name", ",", "action", "=", "\"store_true\"", ",", "default", "=", "default", ",", "dest", "=", "dest", ",", "help", "=", "help", ")", "parser", ".", "add_argument", "(", "\"--no-\"", "+", "name", ",", "action", "=", "\"store_false\"", ",", "dest", "=", "dest", ")"], "docstring": "Add a boolean flag to argparse parser.\n\n    Parameters\n    ----------\n    parser: argparse.Parser\n        parser to add the flag to\n    name: str\n        --<name> will enable the flag, while --no-<name> will disable it\n    default: bool or None\n        default value of the flag\n    help: str\n        help string for the flag", "docstring_tokens": ["Add", "a", "boolean", "flag", "to", "argparse", "parser", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/misc_util.py#L140-L156", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/misc_util.py", "func_name": "get_wrapper_by_name", "original_string": "def get_wrapper_by_name(env, classname):\n    \"\"\"Given an a gym environment possibly wrapped multiple times, returns a wrapper\n    of class named classname or raises ValueError if no such wrapper was applied\n\n    Parameters\n    ----------\n    env: gym.Env of gym.Wrapper\n        gym environment\n    classname: str\n        name of the wrapper\n\n    Returns\n    -------\n    wrapper: gym.Wrapper\n        wrapper named classname\n    \"\"\"\n    currentenv = env\n    while True:\n        if classname == currentenv.class_name():\n            return currentenv\n        elif isinstance(currentenv, gym.Wrapper):\n            currentenv = currentenv.env\n        else:\n            raise ValueError(\"Couldn't find wrapper named %s\" % classname)", "language": "python", "code": "def get_wrapper_by_name(env, classname):\n    \"\"\"Given an a gym environment possibly wrapped multiple times, returns a wrapper\n    of class named classname or raises ValueError if no such wrapper was applied\n\n    Parameters\n    ----------\n    env: gym.Env of gym.Wrapper\n        gym environment\n    classname: str\n        name of the wrapper\n\n    Returns\n    -------\n    wrapper: gym.Wrapper\n        wrapper named classname\n    \"\"\"\n    currentenv = env\n    while True:\n        if classname == currentenv.class_name():\n            return currentenv\n        elif isinstance(currentenv, gym.Wrapper):\n            currentenv = currentenv.env\n        else:\n            raise ValueError(\"Couldn't find wrapper named %s\" % classname)", "code_tokens": ["def", "get_wrapper_by_name", "(", "env", ",", "classname", ")", ":", "currentenv", "=", "env", "while", "True", ":", "if", "classname", "==", "currentenv", ".", "class_name", "(", ")", ":", "return", "currentenv", "elif", "isinstance", "(", "currentenv", ",", "gym", ".", "Wrapper", ")", ":", "currentenv", "=", "currentenv", ".", "env", "else", ":", "raise", "ValueError", "(", "\"Couldn't find wrapper named %s\"", "%", "classname", ")"], "docstring": "Given an a gym environment possibly wrapped multiple times, returns a wrapper\n    of class named classname or raises ValueError if no such wrapper was applied\n\n    Parameters\n    ----------\n    env: gym.Env of gym.Wrapper\n        gym environment\n    classname: str\n        name of the wrapper\n\n    Returns\n    -------\n    wrapper: gym.Wrapper\n        wrapper named classname", "docstring_tokens": ["Given", "an", "a", "gym", "environment", "possibly", "wrapped", "multiple", "times", "returns", "a", "wrapper", "of", "class", "named", "classname", "or", "raises", "ValueError", "if", "no", "such", "wrapper", "was", "applied"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/misc_util.py#L159-L182", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/misc_util.py", "func_name": "pickle_load", "original_string": "def pickle_load(path, compression=False):\n    \"\"\"Unpickle a possible compressed pickle.\n\n    Parameters\n    ----------\n    path: str\n        path to the output file\n    compression: bool\n        if true assumes that pickle was compressed when created and attempts decompression.\n\n    Returns\n    -------\n    obj: object\n        the unpickled object\n    \"\"\"\n\n    if compression:\n        with zipfile.ZipFile(path, \"r\", compression=zipfile.ZIP_DEFLATED) as myzip:\n            with myzip.open(\"data\") as f:\n                return pickle.load(f)\n    else:\n        with open(path, \"rb\") as f:\n            return pickle.load(f)", "language": "python", "code": "def pickle_load(path, compression=False):\n    \"\"\"Unpickle a possible compressed pickle.\n\n    Parameters\n    ----------\n    path: str\n        path to the output file\n    compression: bool\n        if true assumes that pickle was compressed when created and attempts decompression.\n\n    Returns\n    -------\n    obj: object\n        the unpickled object\n    \"\"\"\n\n    if compression:\n        with zipfile.ZipFile(path, \"r\", compression=zipfile.ZIP_DEFLATED) as myzip:\n            with myzip.open(\"data\") as f:\n                return pickle.load(f)\n    else:\n        with open(path, \"rb\") as f:\n            return pickle.load(f)", "code_tokens": ["def", "pickle_load", "(", "path", ",", "compression", "=", "False", ")", ":", "if", "compression", ":", "with", "zipfile", ".", "ZipFile", "(", "path", ",", "\"r\"", ",", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "as", "myzip", ":", "with", "myzip", ".", "open", "(", "\"data\"", ")", "as", "f", ":", "return", "pickle", ".", "load", "(", "f", ")", "else", ":", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "return", "pickle", ".", "load", "(", "f", ")"], "docstring": "Unpickle a possible compressed pickle.\n\n    Parameters\n    ----------\n    path: str\n        path to the output file\n    compression: bool\n        if true assumes that pickle was compressed when created and attempts decompression.\n\n    Returns\n    -------\n    obj: object\n        the unpickled object", "docstring_tokens": ["Unpickle", "a", "possible", "compressed", "pickle", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/misc_util.py#L221-L243", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/misc_util.py", "func_name": "RunningAvg.update", "original_string": "def update(self, new_val):\n        \"\"\"Update the estimate.\n\n        Parameters\n        ----------\n        new_val: float\n            new observated value of estimated quantity.\n        \"\"\"\n        if self._value is None:\n            self._value = new_val\n        else:\n            self._value = self._gamma * self._value + (1.0 - self._gamma) * new_val", "language": "python", "code": "def update(self, new_val):\n        \"\"\"Update the estimate.\n\n        Parameters\n        ----------\n        new_val: float\n            new observated value of estimated quantity.\n        \"\"\"\n        if self._value is None:\n            self._value = new_val\n        else:\n            self._value = self._gamma * self._value + (1.0 - self._gamma) * new_val", "code_tokens": ["def", "update", "(", "self", ",", "new_val", ")", ":", "if", "self", ".", "_value", "is", "None", ":", "self", ".", "_value", "=", "new_val", "else", ":", "self", ".", "_value", "=", "self", ".", "_gamma", "*", "self", ".", "_value", "+", "(", "1.0", "-", "self", ".", "_gamma", ")", "*", "new_val"], "docstring": "Update the estimate.\n\n        Parameters\n        ----------\n        new_val: float\n            new observated value of estimated quantity.", "docstring_tokens": ["Update", "the", "estimate", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/misc_util.py#L123-L134", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/util.py", "func_name": "store_args", "original_string": "def store_args(method):\n    \"\"\"Stores provided method args as instance attributes.\n    \"\"\"\n    argspec = inspect.getfullargspec(method)\n    defaults = {}\n    if argspec.defaults is not None:\n        defaults = dict(\n            zip(argspec.args[-len(argspec.defaults):], argspec.defaults))\n    if argspec.kwonlydefaults is not None:\n        defaults.update(argspec.kwonlydefaults)\n    arg_names = argspec.args[1:]\n\n    @functools.wraps(method)\n    def wrapper(*positional_args, **keyword_args):\n        self = positional_args[0]\n        # Get default arg values\n        args = defaults.copy()\n        # Add provided arg values\n        for name, value in zip(arg_names, positional_args[1:]):\n            args[name] = value\n        args.update(keyword_args)\n        self.__dict__.update(args)\n        return method(*positional_args, **keyword_args)\n\n    return wrapper", "language": "python", "code": "def store_args(method):\n    \"\"\"Stores provided method args as instance attributes.\n    \"\"\"\n    argspec = inspect.getfullargspec(method)\n    defaults = {}\n    if argspec.defaults is not None:\n        defaults = dict(\n            zip(argspec.args[-len(argspec.defaults):], argspec.defaults))\n    if argspec.kwonlydefaults is not None:\n        defaults.update(argspec.kwonlydefaults)\n    arg_names = argspec.args[1:]\n\n    @functools.wraps(method)\n    def wrapper(*positional_args, **keyword_args):\n        self = positional_args[0]\n        # Get default arg values\n        args = defaults.copy()\n        # Add provided arg values\n        for name, value in zip(arg_names, positional_args[1:]):\n            args[name] = value\n        args.update(keyword_args)\n        self.__dict__.update(args)\n        return method(*positional_args, **keyword_args)\n\n    return wrapper", "code_tokens": ["def", "store_args", "(", "method", ")", ":", "argspec", "=", "inspect", ".", "getfullargspec", "(", "method", ")", "defaults", "=", "{", "}", "if", "argspec", ".", "defaults", "is", "not", "None", ":", "defaults", "=", "dict", "(", "zip", "(", "argspec", ".", "args", "[", "-", "len", "(", "argspec", ".", "defaults", ")", ":", "]", ",", "argspec", ".", "defaults", ")", ")", "if", "argspec", ".", "kwonlydefaults", "is", "not", "None", ":", "defaults", ".", "update", "(", "argspec", ".", "kwonlydefaults", ")", "arg_names", "=", "argspec", ".", "args", "[", "1", ":", "]", "@", "functools", ".", "wraps", "(", "method", ")", "def", "wrapper", "(", "*", "positional_args", ",", "*", "*", "keyword_args", ")", ":", "self", "=", "positional_args", "[", "0", "]", "# Get default arg values", "args", "=", "defaults", ".", "copy", "(", ")", "# Add provided arg values", "for", "name", ",", "value", "in", "zip", "(", "arg_names", ",", "positional_args", "[", "1", ":", "]", ")", ":", "args", "[", "name", "]", "=", "value", "args", ".", "update", "(", "keyword_args", ")", "self", ".", "__dict__", ".", "update", "(", "args", ")", "return", "method", "(", "*", "positional_args", ",", "*", "*", "keyword_args", ")", "return", "wrapper"], "docstring": "Stores provided method args as instance attributes.", "docstring_tokens": ["Stores", "provided", "method", "args", "as", "instance", "attributes", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/util.py#L14-L38", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/util.py", "func_name": "flatten_grads", "original_string": "def flatten_grads(var_list, grads):\n    \"\"\"Flattens a variables and their gradients.\n    \"\"\"\n    return tf.concat([tf.reshape(grad, [U.numel(v)])\n                      for (v, grad) in zip(var_list, grads)], 0)", "language": "python", "code": "def flatten_grads(var_list, grads):\n    \"\"\"Flattens a variables and their gradients.\n    \"\"\"\n    return tf.concat([tf.reshape(grad, [U.numel(v)])\n                      for (v, grad) in zip(var_list, grads)], 0)", "code_tokens": ["def", "flatten_grads", "(", "var_list", ",", "grads", ")", ":", "return", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "grad", ",", "[", "U", ".", "numel", "(", "v", ")", "]", ")", "for", "(", "v", ",", "grad", ")", "in", "zip", "(", "var_list", ",", "grads", ")", "]", ",", "0", ")"], "docstring": "Flattens a variables and their gradients.", "docstring_tokens": ["Flattens", "a", "variables", "and", "their", "gradients", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/util.py#L50-L54", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/util.py", "func_name": "nn", "original_string": "def nn(input, layers_sizes, reuse=None, flatten=False, name=\"\"):\n    \"\"\"Creates a simple neural network\n    \"\"\"\n    for i, size in enumerate(layers_sizes):\n        activation = tf.nn.relu if i < len(layers_sizes) - 1 else None\n        input = tf.layers.dense(inputs=input,\n                                units=size,\n                                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                reuse=reuse,\n                                name=name + '_' + str(i))\n        if activation:\n            input = activation(input)\n    if flatten:\n        assert layers_sizes[-1] == 1\n        input = tf.reshape(input, [-1])\n    return input", "language": "python", "code": "def nn(input, layers_sizes, reuse=None, flatten=False, name=\"\"):\n    \"\"\"Creates a simple neural network\n    \"\"\"\n    for i, size in enumerate(layers_sizes):\n        activation = tf.nn.relu if i < len(layers_sizes) - 1 else None\n        input = tf.layers.dense(inputs=input,\n                                units=size,\n                                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                reuse=reuse,\n                                name=name + '_' + str(i))\n        if activation:\n            input = activation(input)\n    if flatten:\n        assert layers_sizes[-1] == 1\n        input = tf.reshape(input, [-1])\n    return input", "code_tokens": ["def", "nn", "(", "input", ",", "layers_sizes", ",", "reuse", "=", "None", ",", "flatten", "=", "False", ",", "name", "=", "\"\"", ")", ":", "for", "i", ",", "size", "in", "enumerate", "(", "layers_sizes", ")", ":", "activation", "=", "tf", ".", "nn", ".", "relu", "if", "i", "<", "len", "(", "layers_sizes", ")", "-", "1", "else", "None", "input", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", "=", "input", ",", "units", "=", "size", ",", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "reuse", "=", "reuse", ",", "name", "=", "name", "+", "'_'", "+", "str", "(", "i", ")", ")", "if", "activation", ":", "input", "=", "activation", "(", "input", ")", "if", "flatten", ":", "assert", "layers_sizes", "[", "-", "1", "]", "==", "1", "input", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", "]", ")", "return", "input"], "docstring": "Creates a simple neural network", "docstring_tokens": ["Creates", "a", "simple", "neural", "network"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/util.py#L57-L72", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/util.py", "func_name": "mpi_fork", "original_string": "def mpi_fork(n, extra_mpi_args=[]):\n    \"\"\"Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children\n    \"\"\"\n    if n <= 1:\n        return \"child\"\n    if os.getenv(\"IN_MPI\") is None:\n        env = os.environ.copy()\n        env.update(\n            MKL_NUM_THREADS=\"1\",\n            OMP_NUM_THREADS=\"1\",\n            IN_MPI=\"1\"\n        )\n        # \"-bind-to core\" is crucial for good performance\n        args = [\"mpirun\", \"-np\", str(n)] + \\\n            extra_mpi_args + \\\n            [sys.executable]\n\n        args += sys.argv\n        subprocess.check_call(args, env=env)\n        return \"parent\"\n    else:\n        install_mpi_excepthook()\n        return \"child\"", "language": "python", "code": "def mpi_fork(n, extra_mpi_args=[]):\n    \"\"\"Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children\n    \"\"\"\n    if n <= 1:\n        return \"child\"\n    if os.getenv(\"IN_MPI\") is None:\n        env = os.environ.copy()\n        env.update(\n            MKL_NUM_THREADS=\"1\",\n            OMP_NUM_THREADS=\"1\",\n            IN_MPI=\"1\"\n        )\n        # \"-bind-to core\" is crucial for good performance\n        args = [\"mpirun\", \"-np\", str(n)] + \\\n            extra_mpi_args + \\\n            [sys.executable]\n\n        args += sys.argv\n        subprocess.check_call(args, env=env)\n        return \"parent\"\n    else:\n        install_mpi_excepthook()\n        return \"child\"", "code_tokens": ["def", "mpi_fork", "(", "n", ",", "extra_mpi_args", "=", "[", "]", ")", ":", "if", "n", "<=", "1", ":", "return", "\"child\"", "if", "os", ".", "getenv", "(", "\"IN_MPI\"", ")", "is", "None", ":", "env", "=", "os", ".", "environ", ".", "copy", "(", ")", "env", ".", "update", "(", "MKL_NUM_THREADS", "=", "\"1\"", ",", "OMP_NUM_THREADS", "=", "\"1\"", ",", "IN_MPI", "=", "\"1\"", ")", "# \"-bind-to core\" is crucial for good performance", "args", "=", "[", "\"mpirun\"", ",", "\"-np\"", ",", "str", "(", "n", ")", "]", "+", "extra_mpi_args", "+", "[", "sys", ".", "executable", "]", "args", "+=", "sys", ".", "argv", "subprocess", ".", "check_call", "(", "args", ",", "env", "=", "env", ")", "return", "\"parent\"", "else", ":", "install_mpi_excepthook", "(", ")", "return", "\"child\""], "docstring": "Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children", "docstring_tokens": ["Re", "-", "launches", "the", "current", "script", "with", "workers", "Returns", "parent", "for", "original", "parent", "child", "for", "MPI", "children"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/util.py#L88-L111", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/tf_util.py", "func_name": "get_session", "original_string": "def get_session(config=None):\n    \"\"\"Get default session or create one with a given config\"\"\"\n    sess = tf.get_default_session()\n    if sess is None:\n        sess = make_session(config=config, make_default=True)\n    return sess", "language": "python", "code": "def get_session(config=None):\n    \"\"\"Get default session or create one with a given config\"\"\"\n    sess = tf.get_default_session()\n    if sess is None:\n        sess = make_session(config=config, make_default=True)\n    return sess", "code_tokens": ["def", "get_session", "(", "config", "=", "None", ")", ":", "sess", "=", "tf", ".", "get_default_session", "(", ")", "if", "sess", "is", "None", ":", "sess", "=", "make_session", "(", "config", "=", "config", ",", "make_default", "=", "True", ")", "return", "sess"], "docstring": "Get default session or create one with a given config", "docstring_tokens": ["Get", "default", "session", "or", "create", "one", "with", "a", "given", "config"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/tf_util.py#L51-L56", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/tf_util.py", "func_name": "initialize", "original_string": "def initialize():\n    \"\"\"Initialize all the uninitialized variables in the global scope.\"\"\"\n    new_variables = set(tf.global_variables()) - ALREADY_INITIALIZED\n    get_session().run(tf.variables_initializer(new_variables))\n    ALREADY_INITIALIZED.update(new_variables)", "language": "python", "code": "def initialize():\n    \"\"\"Initialize all the uninitialized variables in the global scope.\"\"\"\n    new_variables = set(tf.global_variables()) - ALREADY_INITIALIZED\n    get_session().run(tf.variables_initializer(new_variables))\n    ALREADY_INITIALIZED.update(new_variables)", "code_tokens": ["def", "initialize", "(", ")", ":", "new_variables", "=", "set", "(", "tf", ".", "global_variables", "(", ")", ")", "-", "ALREADY_INITIALIZED", "get_session", "(", ")", ".", "run", "(", "tf", ".", "variables_initializer", "(", "new_variables", ")", ")", "ALREADY_INITIALIZED", ".", "update", "(", "new_variables", ")"], "docstring": "Initialize all the uninitialized variables in the global scope.", "docstring_tokens": ["Initialize", "all", "the", "uninitialized", "variables", "in", "the", "global", "scope", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/tf_util.py#L87-L91", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/tf_util.py", "func_name": "adjust_shape", "original_string": "def adjust_shape(placeholder, data):\n    '''\n    adjust shape of the data to the shape of the placeholder if possible.\n    If shape is incompatible, AssertionError is thrown\n\n    Parameters:\n        placeholder     tensorflow input placeholder\n\n        data            input data to be (potentially) reshaped to be fed into placeholder\n\n    Returns:\n        reshaped data\n    '''\n\n    if not isinstance(data, np.ndarray) and not isinstance(data, list):\n        return data\n    if isinstance(data, list):\n        data = np.array(data)\n\n    placeholder_shape = [x or -1 for x in placeholder.shape.as_list()]\n\n    assert _check_shape(placeholder_shape, data.shape), \\\n        'Shape of data {} is not compatible with shape of the placeholder {}'.format(data.shape, placeholder_shape)\n\n    return np.reshape(data, placeholder_shape)", "language": "python", "code": "def adjust_shape(placeholder, data):\n    '''\n    adjust shape of the data to the shape of the placeholder if possible.\n    If shape is incompatible, AssertionError is thrown\n\n    Parameters:\n        placeholder     tensorflow input placeholder\n\n        data            input data to be (potentially) reshaped to be fed into placeholder\n\n    Returns:\n        reshaped data\n    '''\n\n    if not isinstance(data, np.ndarray) and not isinstance(data, list):\n        return data\n    if isinstance(data, list):\n        data = np.array(data)\n\n    placeholder_shape = [x or -1 for x in placeholder.shape.as_list()]\n\n    assert _check_shape(placeholder_shape, data.shape), \\\n        'Shape of data {} is not compatible with shape of the placeholder {}'.format(data.shape, placeholder_shape)\n\n    return np.reshape(data, placeholder_shape)", "code_tokens": ["def", "adjust_shape", "(", "placeholder", ",", "data", ")", ":", "if", "not", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", "and", "not", "isinstance", "(", "data", ",", "list", ")", ":", "return", "data", "if", "isinstance", "(", "data", ",", "list", ")", ":", "data", "=", "np", ".", "array", "(", "data", ")", "placeholder_shape", "=", "[", "x", "or", "-", "1", "for", "x", "in", "placeholder", ".", "shape", ".", "as_list", "(", ")", "]", "assert", "_check_shape", "(", "placeholder_shape", ",", "data", ".", "shape", ")", ",", "'Shape of data {} is not compatible with shape of the placeholder {}'", ".", "format", "(", "data", ".", "shape", ",", "placeholder_shape", ")", "return", "np", ".", "reshape", "(", "data", ",", "placeholder_shape", ")"], "docstring": "adjust shape of the data to the shape of the placeholder if possible.\n    If shape is incompatible, AssertionError is thrown\n\n    Parameters:\n        placeholder     tensorflow input placeholder\n\n        data            input data to be (potentially) reshaped to be fed into placeholder\n\n    Returns:\n        reshaped data", "docstring_tokens": ["adjust", "shape", "of", "the", "data", "to", "the", "shape", "of", "the", "placeholder", "if", "possible", ".", "If", "shape", "is", "incompatible", "AssertionError", "is", "thrown"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/tf_util.py#L377-L401", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/atari_wrappers.py", "func_name": "wrap_deepmind", "original_string": "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n    \"\"\"Configure environment for DeepMind-style Atari.\n    \"\"\"\n    if episode_life:\n        env = EpisodicLifeEnv(env)\n    if 'FIRE' in env.unwrapped.get_action_meanings():\n        env = FireResetEnv(env)\n    env = WarpFrame(env)\n    if scale:\n        env = ScaledFloatFrame(env)\n    if clip_rewards:\n        env = ClipRewardEnv(env)\n    if frame_stack:\n        env = FrameStack(env, 4)\n    return env", "language": "python", "code": "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n    \"\"\"Configure environment for DeepMind-style Atari.\n    \"\"\"\n    if episode_life:\n        env = EpisodicLifeEnv(env)\n    if 'FIRE' in env.unwrapped.get_action_meanings():\n        env = FireResetEnv(env)\n    env = WarpFrame(env)\n    if scale:\n        env = ScaledFloatFrame(env)\n    if clip_rewards:\n        env = ClipRewardEnv(env)\n    if frame_stack:\n        env = FrameStack(env, 4)\n    return env", "code_tokens": ["def", "wrap_deepmind", "(", "env", ",", "episode_life", "=", "True", ",", "clip_rewards", "=", "True", ",", "frame_stack", "=", "False", ",", "scale", "=", "False", ")", ":", "if", "episode_life", ":", "env", "=", "EpisodicLifeEnv", "(", "env", ")", "if", "'FIRE'", "in", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ":", "env", "=", "FireResetEnv", "(", "env", ")", "env", "=", "WarpFrame", "(", "env", ")", "if", "scale", ":", "env", "=", "ScaledFloatFrame", "(", "env", ")", "if", "clip_rewards", ":", "env", "=", "ClipRewardEnv", "(", "env", ")", "if", "frame_stack", ":", "env", "=", "FrameStack", "(", "env", ",", "4", ")", "return", "env"], "docstring": "Configure environment for DeepMind-style Atari.", "docstring_tokens": ["Configure", "environment", "for", "DeepMind", "-", "style", "Atari", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/atari_wrappers.py#L235-L249", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/atari_wrappers.py", "func_name": "EpisodicLifeEnv.reset", "original_string": "def reset(self, **kwargs):\n        \"\"\"Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        \"\"\"\n        if self.was_real_done:\n            obs = self.env.reset(**kwargs)\n        else:\n            # no-op step to advance from terminal/lost life state\n            obs, _, _, _ = self.env.step(0)\n        self.lives = self.env.unwrapped.ale.lives()\n        return obs", "language": "python", "code": "def reset(self, **kwargs):\n        \"\"\"Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        \"\"\"\n        if self.was_real_done:\n            obs = self.env.reset(**kwargs)\n        else:\n            # no-op step to advance from terminal/lost life state\n            obs, _, _, _ = self.env.step(0)\n        self.lives = self.env.unwrapped.ale.lives()\n        return obs", "code_tokens": ["def", "reset", "(", "self", ",", "*", "*", "kwargs", ")", ":", "if", "self", ".", "was_real_done", ":", "obs", "=", "self", ".", "env", ".", "reset", "(", "*", "*", "kwargs", ")", "else", ":", "# no-op step to advance from terminal/lost life state", "obs", ",", "_", ",", "_", ",", "_", "=", "self", ".", "env", ".", "step", "(", "0", ")", "self", ".", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "return", "obs"], "docstring": "Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.", "docstring_tokens": ["Reset", "only", "when", "lives", "are", "exhausted", ".", "This", "way", "all", "states", "are", "still", "reachable", "even", "though", "lives", "are", "episodic", "and", "the", "learner", "need", "not", "know", "about", "any", "of", "this", "behind", "-", "the", "-", "scenes", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/atari_wrappers.py#L84-L95", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/mpi_util.py", "func_name": "gpu_count", "original_string": "def gpu_count():\n    \"\"\"\n    Count the GPUs on this machine.\n    \"\"\"\n    if shutil.which('nvidia-smi') is None:\n        return 0\n    output = subprocess.check_output(['nvidia-smi', '--query-gpu=gpu_name', '--format=csv'])\n    return max(0, len(output.split(b'\\n')) - 2)", "language": "python", "code": "def gpu_count():\n    \"\"\"\n    Count the GPUs on this machine.\n    \"\"\"\n    if shutil.which('nvidia-smi') is None:\n        return 0\n    output = subprocess.check_output(['nvidia-smi', '--query-gpu=gpu_name', '--format=csv'])\n    return max(0, len(output.split(b'\\n')) - 2)", "code_tokens": ["def", "gpu_count", "(", ")", ":", "if", "shutil", ".", "which", "(", "'nvidia-smi'", ")", "is", "None", ":", "return", "0", "output", "=", "subprocess", ".", "check_output", "(", "[", "'nvidia-smi'", ",", "'--query-gpu=gpu_name'", ",", "'--format=csv'", "]", ")", "return", "max", "(", "0", ",", "len", "(", "output", ".", "split", "(", "b'\\n'", ")", ")", "-", "2", ")"], "docstring": "Count the GPUs on this machine.", "docstring_tokens": ["Count", "the", "GPUs", "on", "this", "machine", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/mpi_util.py#L28-L35", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/mpi_util.py", "func_name": "setup_mpi_gpus", "original_string": "def setup_mpi_gpus():\n    \"\"\"\n    Set CUDA_VISIBLE_DEVICES to MPI rank if not already set\n    \"\"\"\n    if 'CUDA_VISIBLE_DEVICES' not in os.environ:\n        if sys.platform == 'darwin': # This Assumes if you're on OSX you're just\n            ids = []                 # doing a smoke test and don't want GPUs\n        else:\n            lrank, _lsize = get_local_rank_size(MPI.COMM_WORLD)\n            ids = [lrank]\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, ids))", "language": "python", "code": "def setup_mpi_gpus():\n    \"\"\"\n    Set CUDA_VISIBLE_DEVICES to MPI rank if not already set\n    \"\"\"\n    if 'CUDA_VISIBLE_DEVICES' not in os.environ:\n        if sys.platform == 'darwin': # This Assumes if you're on OSX you're just\n            ids = []                 # doing a smoke test and don't want GPUs\n        else:\n            lrank, _lsize = get_local_rank_size(MPI.COMM_WORLD)\n            ids = [lrank]\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, ids))", "code_tokens": ["def", "setup_mpi_gpus", "(", ")", ":", "if", "'CUDA_VISIBLE_DEVICES'", "not", "in", "os", ".", "environ", ":", "if", "sys", ".", "platform", "==", "'darwin'", ":", "# This Assumes if you're on OSX you're just", "ids", "=", "[", "]", "# doing a smoke test and don't want GPUs", "else", ":", "lrank", ",", "_lsize", "=", "get_local_rank_size", "(", "MPI", ".", "COMM_WORLD", ")", "ids", "=", "[", "lrank", "]", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "ids", ")", ")"], "docstring": "Set CUDA_VISIBLE_DEVICES to MPI rank if not already set", "docstring_tokens": ["Set", "CUDA_VISIBLE_DEVICES", "to", "MPI", "rank", "if", "not", "already", "set"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/mpi_util.py#L37-L47", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/mpi_util.py", "func_name": "get_local_rank_size", "original_string": "def get_local_rank_size(comm):\n    \"\"\"\n    Returns the rank of each process on its machine\n    The processes on a given machine will be assigned ranks\n        0, 1, 2, ..., N-1,\n    where N is the number of processes on this machine.\n\n    Useful if you want to assign one gpu per machine\n    \"\"\"\n    this_node = platform.node()\n    ranks_nodes = comm.allgather((comm.Get_rank(), this_node))\n    node2rankssofar = defaultdict(int)\n    local_rank = None\n    for (rank, node) in ranks_nodes:\n        if rank == comm.Get_rank():\n            local_rank = node2rankssofar[node]\n        node2rankssofar[node] += 1\n    assert local_rank is not None\n    return local_rank, node2rankssofar[this_node]", "language": "python", "code": "def get_local_rank_size(comm):\n    \"\"\"\n    Returns the rank of each process on its machine\n    The processes on a given machine will be assigned ranks\n        0, 1, 2, ..., N-1,\n    where N is the number of processes on this machine.\n\n    Useful if you want to assign one gpu per machine\n    \"\"\"\n    this_node = platform.node()\n    ranks_nodes = comm.allgather((comm.Get_rank(), this_node))\n    node2rankssofar = defaultdict(int)\n    local_rank = None\n    for (rank, node) in ranks_nodes:\n        if rank == comm.Get_rank():\n            local_rank = node2rankssofar[node]\n        node2rankssofar[node] += 1\n    assert local_rank is not None\n    return local_rank, node2rankssofar[this_node]", "code_tokens": ["def", "get_local_rank_size", "(", "comm", ")", ":", "this_node", "=", "platform", ".", "node", "(", ")", "ranks_nodes", "=", "comm", ".", "allgather", "(", "(", "comm", ".", "Get_rank", "(", ")", ",", "this_node", ")", ")", "node2rankssofar", "=", "defaultdict", "(", "int", ")", "local_rank", "=", "None", "for", "(", "rank", ",", "node", ")", "in", "ranks_nodes", ":", "if", "rank", "==", "comm", ".", "Get_rank", "(", ")", ":", "local_rank", "=", "node2rankssofar", "[", "node", "]", "node2rankssofar", "[", "node", "]", "+=", "1", "assert", "local_rank", "is", "not", "None", "return", "local_rank", ",", "node2rankssofar", "[", "this_node", "]"], "docstring": "Returns the rank of each process on its machine\n    The processes on a given machine will be assigned ranks\n        0, 1, 2, ..., N-1,\n    where N is the number of processes on this machine.\n\n    Useful if you want to assign one gpu per machine", "docstring_tokens": ["Returns", "the", "rank", "of", "each", "process", "on", "its", "machine", "The", "processes", "on", "a", "given", "machine", "will", "be", "assigned", "ranks", "0", "1", "2", "...", "N", "-", "1", "where", "N", "is", "the", "number", "of", "processes", "on", "this", "machine", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/mpi_util.py#L49-L67", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/mpi_util.py", "func_name": "share_file", "original_string": "def share_file(comm, path):\n    \"\"\"\n    Copies the file from rank 0 to all other ranks\n    Puts it in the same place on all machines\n    \"\"\"\n    localrank, _ = get_local_rank_size(comm)\n    if comm.Get_rank() == 0:\n        with open(path, 'rb') as fh:\n            data = fh.read()\n        comm.bcast(data)\n    else:\n        data = comm.bcast(None)\n        if localrank == 0:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, 'wb') as fh:\n                fh.write(data)\n    comm.Barrier()", "language": "python", "code": "def share_file(comm, path):\n    \"\"\"\n    Copies the file from rank 0 to all other ranks\n    Puts it in the same place on all machines\n    \"\"\"\n    localrank, _ = get_local_rank_size(comm)\n    if comm.Get_rank() == 0:\n        with open(path, 'rb') as fh:\n            data = fh.read()\n        comm.bcast(data)\n    else:\n        data = comm.bcast(None)\n        if localrank == 0:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, 'wb') as fh:\n                fh.write(data)\n    comm.Barrier()", "code_tokens": ["def", "share_file", "(", "comm", ",", "path", ")", ":", "localrank", ",", "_", "=", "get_local_rank_size", "(", "comm", ")", "if", "comm", ".", "Get_rank", "(", ")", "==", "0", ":", "with", "open", "(", "path", ",", "'rb'", ")", "as", "fh", ":", "data", "=", "fh", ".", "read", "(", ")", "comm", ".", "bcast", "(", "data", ")", "else", ":", "data", "=", "comm", ".", "bcast", "(", "None", ")", "if", "localrank", "==", "0", ":", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ",", "exist_ok", "=", "True", ")", "with", "open", "(", "path", ",", "'wb'", ")", "as", "fh", ":", "fh", ".", "write", "(", "data", ")", "comm", ".", "Barrier", "(", ")"], "docstring": "Copies the file from rank 0 to all other ranks\n    Puts it in the same place on all machines", "docstring_tokens": ["Copies", "the", "file", "from", "rank", "0", "to", "all", "other", "ranks", "Puts", "it", "in", "the", "same", "place", "on", "all", "machines"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/mpi_util.py#L69-L85", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/mpi_util.py", "func_name": "dict_gather", "original_string": "def dict_gather(comm, d, op='mean', assert_all_have_data=True):\n    \"\"\"\n    Perform a reduction operation over dicts\n    \"\"\"\n    if comm is None: return d\n    alldicts = comm.allgather(d)\n    size = comm.size\n    k2li = defaultdict(list)\n    for d in alldicts:\n        for (k,v) in d.items():\n            k2li[k].append(v)\n    result = {}\n    for (k,li) in k2li.items():\n        if assert_all_have_data:\n            assert len(li)==size, \"only %i out of %i MPI workers have sent '%s'\" % (len(li), size, k)\n        if op=='mean':\n            result[k] = np.mean(li, axis=0)\n        elif op=='sum':\n            result[k] = np.sum(li, axis=0)\n        else:\n            assert 0, op\n    return result", "language": "python", "code": "def dict_gather(comm, d, op='mean', assert_all_have_data=True):\n    \"\"\"\n    Perform a reduction operation over dicts\n    \"\"\"\n    if comm is None: return d\n    alldicts = comm.allgather(d)\n    size = comm.size\n    k2li = defaultdict(list)\n    for d in alldicts:\n        for (k,v) in d.items():\n            k2li[k].append(v)\n    result = {}\n    for (k,li) in k2li.items():\n        if assert_all_have_data:\n            assert len(li)==size, \"only %i out of %i MPI workers have sent '%s'\" % (len(li), size, k)\n        if op=='mean':\n            result[k] = np.mean(li, axis=0)\n        elif op=='sum':\n            result[k] = np.sum(li, axis=0)\n        else:\n            assert 0, op\n    return result", "code_tokens": ["def", "dict_gather", "(", "comm", ",", "d", ",", "op", "=", "'mean'", ",", "assert_all_have_data", "=", "True", ")", ":", "if", "comm", "is", "None", ":", "return", "d", "alldicts", "=", "comm", ".", "allgather", "(", "d", ")", "size", "=", "comm", ".", "size", "k2li", "=", "defaultdict", "(", "list", ")", "for", "d", "in", "alldicts", ":", "for", "(", "k", ",", "v", ")", "in", "d", ".", "items", "(", ")", ":", "k2li", "[", "k", "]", ".", "append", "(", "v", ")", "result", "=", "{", "}", "for", "(", "k", ",", "li", ")", "in", "k2li", ".", "items", "(", ")", ":", "if", "assert_all_have_data", ":", "assert", "len", "(", "li", ")", "==", "size", ",", "\"only %i out of %i MPI workers have sent '%s'\"", "%", "(", "len", "(", "li", ")", ",", "size", ",", "k", ")", "if", "op", "==", "'mean'", ":", "result", "[", "k", "]", "=", "np", ".", "mean", "(", "li", ",", "axis", "=", "0", ")", "elif", "op", "==", "'sum'", ":", "result", "[", "k", "]", "=", "np", ".", "sum", "(", "li", ",", "axis", "=", "0", ")", "else", ":", "assert", "0", ",", "op", "return", "result"], "docstring": "Perform a reduction operation over dicts", "docstring_tokens": ["Perform", "a", "reduction", "operation", "over", "dicts"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/mpi_util.py#L87-L108", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/math_util.py", "func_name": "discount", "original_string": "def discount(x, gamma):\n    \"\"\"\n    computes discounted sums along 0th dimension of x.\n\n    inputs\n    ------\n    x: ndarray\n    gamma: float\n\n    outputs\n    -------\n    y: ndarray with same shape as x, satisfying\n\n        y[t] = x[t] + gamma*x[t+1] + gamma^2*x[t+2] + ... + gamma^k x[t+k],\n                where k = len(x) - t - 1\n\n    \"\"\"\n    assert x.ndim >= 1\n    return scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]", "language": "python", "code": "def discount(x, gamma):\n    \"\"\"\n    computes discounted sums along 0th dimension of x.\n\n    inputs\n    ------\n    x: ndarray\n    gamma: float\n\n    outputs\n    -------\n    y: ndarray with same shape as x, satisfying\n\n        y[t] = x[t] + gamma*x[t+1] + gamma^2*x[t+2] + ... + gamma^k x[t+k],\n                where k = len(x) - t - 1\n\n    \"\"\"\n    assert x.ndim >= 1\n    return scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]", "code_tokens": ["def", "discount", "(", "x", ",", "gamma", ")", ":", "assert", "x", ".", "ndim", ">=", "1", "return", "scipy", ".", "signal", ".", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "gamma", "]", ",", "x", "[", ":", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]"], "docstring": "computes discounted sums along 0th dimension of x.\n\n    inputs\n    ------\n    x: ndarray\n    gamma: float\n\n    outputs\n    -------\n    y: ndarray with same shape as x, satisfying\n\n        y[t] = x[t] + gamma*x[t+1] + gamma^2*x[t+2] + ... + gamma^k x[t+k],\n                where k = len(x) - t - 1", "docstring_tokens": ["computes", "discounted", "sums", "along", "0th", "dimension", "of", "x", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/math_util.py#L5-L23", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/deepq/replay_buffer.py", "func_name": "PrioritizedReplayBuffer.add", "original_string": "def add(self, *args, **kwargs):\n        \"\"\"See ReplayBuffer.store_effect\"\"\"\n        idx = self._next_idx\n        super().add(*args, **kwargs)\n        self._it_sum[idx] = self._max_priority ** self._alpha\n        self._it_min[idx] = self._max_priority ** self._alpha", "language": "python", "code": "def add(self, *args, **kwargs):\n        \"\"\"See ReplayBuffer.store_effect\"\"\"\n        idx = self._next_idx\n        super().add(*args, **kwargs)\n        self._it_sum[idx] = self._max_priority ** self._alpha\n        self._it_min[idx] = self._max_priority ** self._alpha", "code_tokens": ["def", "add", "(", "self", ",", "*", "args", ",", "*", "*", "kwargs", ")", ":", "idx", "=", "self", ".", "_next_idx", "super", "(", ")", ".", "add", "(", "*", "args", ",", "*", "*", "kwargs", ")", "self", ".", "_it_sum", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha", "self", ".", "_it_min", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha"], "docstring": "See ReplayBuffer.store_effect", "docstring_tokens": ["See", "ReplayBuffer", ".", "store_effect"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/deepq/replay_buffer.py#L100-L105", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/deepq/replay_buffer.py", "func_name": "PrioritizedReplayBuffer.update_priorities", "original_string": "def update_priorities(self, idxes, priorities):\n        \"\"\"Update priorities of sampled transitions.\n\n        sets priority of transition at index idxes[i] in buffer\n        to priorities[i].\n\n        Parameters\n        ----------\n        idxes: [int]\n            List of idxes of sampled transitions\n        priorities: [float]\n            List of updated priorities corresponding to\n            transitions at the sampled idxes denoted by\n            variable `idxes`.\n        \"\"\"\n        assert len(idxes) == len(priorities)\n        for idx, priority in zip(idxes, priorities):\n            assert priority > 0\n            assert 0 <= idx < len(self._storage)\n            self._it_sum[idx] = priority ** self._alpha\n            self._it_min[idx] = priority ** self._alpha\n\n            self._max_priority = max(self._max_priority, priority)", "language": "python", "code": "def update_priorities(self, idxes, priorities):\n        \"\"\"Update priorities of sampled transitions.\n\n        sets priority of transition at index idxes[i] in buffer\n        to priorities[i].\n\n        Parameters\n        ----------\n        idxes: [int]\n            List of idxes of sampled transitions\n        priorities: [float]\n            List of updated priorities corresponding to\n            transitions at the sampled idxes denoted by\n            variable `idxes`.\n        \"\"\"\n        assert len(idxes) == len(priorities)\n        for idx, priority in zip(idxes, priorities):\n            assert priority > 0\n            assert 0 <= idx < len(self._storage)\n            self._it_sum[idx] = priority ** self._alpha\n            self._it_min[idx] = priority ** self._alpha\n\n            self._max_priority = max(self._max_priority, priority)", "code_tokens": ["def", "update_priorities", "(", "self", ",", "idxes", ",", "priorities", ")", ":", "assert", "len", "(", "idxes", ")", "==", "len", "(", "priorities", ")", "for", "idx", ",", "priority", "in", "zip", "(", "idxes", ",", "priorities", ")", ":", "assert", "priority", ">", "0", "assert", "0", "<=", "idx", "<", "len", "(", "self", ".", "_storage", ")", "self", ".", "_it_sum", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "self", ".", "_it_min", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "self", ".", "_max_priority", "=", "max", "(", "self", ".", "_max_priority", ",", "priority", ")"], "docstring": "Update priorities of sampled transitions.\n\n        sets priority of transition at index idxes[i] in buffer\n        to priorities[i].\n\n        Parameters\n        ----------\n        idxes: [int]\n            List of idxes of sampled transitions\n        priorities: [float]\n            List of updated priorities corresponding to\n            transitions at the sampled idxes denoted by\n            variable `idxes`.", "docstring_tokens": ["Update", "priorities", "of", "sampled", "transitions", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/deepq/replay_buffer.py#L169-L191", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/common/retro_wrappers.py", "func_name": "wrap_deepmind_retro", "original_string": "def wrap_deepmind_retro(env, scale=True, frame_stack=4):\n    \"\"\"\n    Configure environment for retro games, using config similar to DeepMind-style Atari in wrap_deepmind\n    \"\"\"\n    env = WarpFrame(env)\n    env = ClipRewardEnv(env)\n    if frame_stack > 1:\n        env = FrameStack(env, frame_stack)\n    if scale:\n        env = ScaledFloatFrame(env)\n    return env", "language": "python", "code": "def wrap_deepmind_retro(env, scale=True, frame_stack=4):\n    \"\"\"\n    Configure environment for retro games, using config similar to DeepMind-style Atari in wrap_deepmind\n    \"\"\"\n    env = WarpFrame(env)\n    env = ClipRewardEnv(env)\n    if frame_stack > 1:\n        env = FrameStack(env, frame_stack)\n    if scale:\n        env = ScaledFloatFrame(env)\n    return env", "code_tokens": ["def", "wrap_deepmind_retro", "(", "env", ",", "scale", "=", "True", ",", "frame_stack", "=", "4", ")", ":", "env", "=", "WarpFrame", "(", "env", ")", "env", "=", "ClipRewardEnv", "(", "env", ")", "if", "frame_stack", ">", "1", ":", "env", "=", "FrameStack", "(", "env", ",", "frame_stack", ")", "if", "scale", ":", "env", "=", "ScaledFloatFrame", "(", "env", ")", "return", "env"], "docstring": "Configure environment for retro games, using config similar to DeepMind-style Atari in wrap_deepmind", "docstring_tokens": ["Configure", "environment", "for", "retro", "games", "using", "config", "similar", "to", "DeepMind", "-", "style", "Atari", "in", "wrap_deepmind"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/retro_wrappers.py#L212-L222", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/her/her_sampler.py", "func_name": "make_sample_her_transitions", "original_string": "def make_sample_her_transitions(replay_strategy, replay_k, reward_fun):\n    \"\"\"Creates a sample function that can be used for HER experience replay.\n\n    Args:\n        replay_strategy (in ['future', 'none']): the HER replay strategy; if set to 'none',\n            regular DDPG experience replay is used\n        replay_k (int): the ratio between HER replays and regular replays (e.g. k = 4 -> 4 times\n            as many HER replays as regular replays are used)\n        reward_fun (function): function to re-compute the reward with substituted goals\n    \"\"\"\n    if replay_strategy == 'future':\n        future_p = 1 - (1. / (1 + replay_k))\n    else:  # 'replay_strategy' == 'none'\n        future_p = 0\n\n    def _sample_her_transitions(episode_batch, batch_size_in_transitions):\n        \"\"\"episode_batch is {key: array(buffer_size x T x dim_key)}\n        \"\"\"\n        T = episode_batch['u'].shape[1]\n        rollout_batch_size = episode_batch['u'].shape[0]\n        batch_size = batch_size_in_transitions\n\n        # Select which episodes and time steps to use.\n        episode_idxs = np.random.randint(0, rollout_batch_size, batch_size)\n        t_samples = np.random.randint(T, size=batch_size)\n        transitions = {key: episode_batch[key][episode_idxs, t_samples].copy()\n                       for key in episode_batch.keys()}\n\n        # Select future time indexes proportional with probability future_p. These\n        # will be used for HER replay by substituting in future goals.\n        her_indexes = np.where(np.random.uniform(size=batch_size) < future_p)\n        future_offset = np.random.uniform(size=batch_size) * (T - t_samples)\n        future_offset = future_offset.astype(int)\n        future_t = (t_samples + 1 + future_offset)[her_indexes]\n\n        # Replace goal with achieved goal but only for the previously-selected\n        # HER transitions (as defined by her_indexes). For the other transitions,\n        # keep the original goal.\n        future_ag = episode_batch['ag'][episode_idxs[her_indexes], future_t]\n        transitions['g'][her_indexes] = future_ag\n\n        # Reconstruct info dictionary for reward  computation.\n        info = {}\n        for key, value in transitions.items():\n            if key.startswith('info_'):\n                info[key.replace('info_', '')] = value\n\n        # Re-compute reward since we may have substituted the goal.\n        reward_params = {k: transitions[k] for k in ['ag_2', 'g']}\n        reward_params['info'] = info\n        transitions['r'] = reward_fun(**reward_params)\n\n        transitions = {k: transitions[k].reshape(batch_size, *transitions[k].shape[1:])\n                       for k in transitions.keys()}\n\n        assert(transitions['u'].shape[0] == batch_size_in_transitions)\n\n        return transitions\n\n    return _sample_her_transitions", "language": "python", "code": "def make_sample_her_transitions(replay_strategy, replay_k, reward_fun):\n    \"\"\"Creates a sample function that can be used for HER experience replay.\n\n    Args:\n        replay_strategy (in ['future', 'none']): the HER replay strategy; if set to 'none',\n            regular DDPG experience replay is used\n        replay_k (int): the ratio between HER replays and regular replays (e.g. k = 4 -> 4 times\n            as many HER replays as regular replays are used)\n        reward_fun (function): function to re-compute the reward with substituted goals\n    \"\"\"\n    if replay_strategy == 'future':\n        future_p = 1 - (1. / (1 + replay_k))\n    else:  # 'replay_strategy' == 'none'\n        future_p = 0\n\n    def _sample_her_transitions(episode_batch, batch_size_in_transitions):\n        \"\"\"episode_batch is {key: array(buffer_size x T x dim_key)}\n        \"\"\"\n        T = episode_batch['u'].shape[1]\n        rollout_batch_size = episode_batch['u'].shape[0]\n        batch_size = batch_size_in_transitions\n\n        # Select which episodes and time steps to use.\n        episode_idxs = np.random.randint(0, rollout_batch_size, batch_size)\n        t_samples = np.random.randint(T, size=batch_size)\n        transitions = {key: episode_batch[key][episode_idxs, t_samples].copy()\n                       for key in episode_batch.keys()}\n\n        # Select future time indexes proportional with probability future_p. These\n        # will be used for HER replay by substituting in future goals.\n        her_indexes = np.where(np.random.uniform(size=batch_size) < future_p)\n        future_offset = np.random.uniform(size=batch_size) * (T - t_samples)\n        future_offset = future_offset.astype(int)\n        future_t = (t_samples + 1 + future_offset)[her_indexes]\n\n        # Replace goal with achieved goal but only for the previously-selected\n        # HER transitions (as defined by her_indexes). For the other transitions,\n        # keep the original goal.\n        future_ag = episode_batch['ag'][episode_idxs[her_indexes], future_t]\n        transitions['g'][her_indexes] = future_ag\n\n        # Reconstruct info dictionary for reward  computation.\n        info = {}\n        for key, value in transitions.items():\n            if key.startswith('info_'):\n                info[key.replace('info_', '')] = value\n\n        # Re-compute reward since we may have substituted the goal.\n        reward_params = {k: transitions[k] for k in ['ag_2', 'g']}\n        reward_params['info'] = info\n        transitions['r'] = reward_fun(**reward_params)\n\n        transitions = {k: transitions[k].reshape(batch_size, *transitions[k].shape[1:])\n                       for k in transitions.keys()}\n\n        assert(transitions['u'].shape[0] == batch_size_in_transitions)\n\n        return transitions\n\n    return _sample_her_transitions", "code_tokens": ["def", "make_sample_her_transitions", "(", "replay_strategy", ",", "replay_k", ",", "reward_fun", ")", ":", "if", "replay_strategy", "==", "'future'", ":", "future_p", "=", "1", "-", "(", "1.", "/", "(", "1", "+", "replay_k", ")", ")", "else", ":", "# 'replay_strategy' == 'none'", "future_p", "=", "0", "def", "_sample_her_transitions", "(", "episode_batch", ",", "batch_size_in_transitions", ")", ":", "\"\"\"episode_batch is {key: array(buffer_size x T x dim_key)}\n        \"\"\"", "T", "=", "episode_batch", "[", "'u'", "]", ".", "shape", "[", "1", "]", "rollout_batch_size", "=", "episode_batch", "[", "'u'", "]", ".", "shape", "[", "0", "]", "batch_size", "=", "batch_size_in_transitions", "# Select which episodes and time steps to use.", "episode_idxs", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "rollout_batch_size", ",", "batch_size", ")", "t_samples", "=", "np", ".", "random", ".", "randint", "(", "T", ",", "size", "=", "batch_size", ")", "transitions", "=", "{", "key", ":", "episode_batch", "[", "key", "]", "[", "episode_idxs", ",", "t_samples", "]", ".", "copy", "(", ")", "for", "key", "in", "episode_batch", ".", "keys", "(", ")", "}", "# Select future time indexes proportional with probability future_p. These", "# will be used for HER replay by substituting in future goals.", "her_indexes", "=", "np", ".", "where", "(", "np", ".", "random", ".", "uniform", "(", "size", "=", "batch_size", ")", "<", "future_p", ")", "future_offset", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "batch_size", ")", "*", "(", "T", "-", "t_samples", ")", "future_offset", "=", "future_offset", ".", "astype", "(", "int", ")", "future_t", "=", "(", "t_samples", "+", "1", "+", "future_offset", ")", "[", "her_indexes", "]", "# Replace goal with achieved goal but only for the previously-selected", "# HER transitions (as defined by her_indexes). For the other transitions,", "# keep the original goal.", "future_ag", "=", "episode_batch", "[", "'ag'", "]", "[", "episode_idxs", "[", "her_indexes", "]", ",", "future_t", "]", "transitions", "[", "'g'", "]", "[", "her_indexes", "]", "=", "future_ag", "# Reconstruct info dictionary for reward  computation.", "info", "=", "{", "}", "for", "key", ",", "value", "in", "transitions", ".", "items", "(", ")", ":", "if", "key", ".", "startswith", "(", "'info_'", ")", ":", "info", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "]", "=", "value", "# Re-compute reward since we may have substituted the goal.", "reward_params", "=", "{", "k", ":", "transitions", "[", "k", "]", "for", "k", "in", "[", "'ag_2'", ",", "'g'", "]", "}", "reward_params", "[", "'info'", "]", "=", "info", "transitions", "[", "'r'", "]", "=", "reward_fun", "(", "*", "*", "reward_params", ")", "transitions", "=", "{", "k", ":", "transitions", "[", "k", "]", ".", "reshape", "(", "batch_size", ",", "*", "transitions", "[", "k", "]", ".", "shape", "[", "1", ":", "]", ")", "for", "k", "in", "transitions", ".", "keys", "(", ")", "}", "assert", "(", "transitions", "[", "'u'", "]", ".", "shape", "[", "0", "]", "==", "batch_size_in_transitions", ")", "return", "transitions", "return", "_sample_her_transitions"], "docstring": "Creates a sample function that can be used for HER experience replay.\n\n    Args:\n        replay_strategy (in ['future', 'none']): the HER replay strategy; if set to 'none',\n            regular DDPG experience replay is used\n        replay_k (int): the ratio between HER replays and regular replays (e.g. k = 4 -> 4 times\n            as many HER replays as regular replays are used)\n        reward_fun (function): function to re-compute the reward with substituted goals", "docstring_tokens": ["Creates", "a", "sample", "function", "that", "can", "be", "used", "for", "HER", "experience", "replay", "."], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/her/her_sampler.py#L4-L63", "partition": "valid"}
{"repo": "openai/baselines", "path": "baselines/run.py", "func_name": "parse_cmdline_kwargs", "original_string": "def parse_cmdline_kwargs(args):\n    '''\n    convert a list of '='-spaced command-line arguments to a dictionary, evaluating python objects when possible\n    '''\n    def parse(v):\n\n        assert isinstance(v, str)\n        try:\n            return eval(v)\n        except (NameError, SyntaxError):\n            return v\n\n    return {k: parse(v) for k,v in parse_unknown_args(args).items()}", "language": "python", "code": "def parse_cmdline_kwargs(args):\n    '''\n    convert a list of '='-spaced command-line arguments to a dictionary, evaluating python objects when possible\n    '''\n    def parse(v):\n\n        assert isinstance(v, str)\n        try:\n            return eval(v)\n        except (NameError, SyntaxError):\n            return v\n\n    return {k: parse(v) for k,v in parse_unknown_args(args).items()}", "code_tokens": ["def", "parse_cmdline_kwargs", "(", "args", ")", ":", "def", "parse", "(", "v", ")", ":", "assert", "isinstance", "(", "v", ",", "str", ")", "try", ":", "return", "eval", "(", "v", ")", "except", "(", "NameError", ",", "SyntaxError", ")", ":", "return", "v", "return", "{", "k", ":", "parse", "(", "v", ")", "for", "k", ",", "v", "in", "parse_unknown_args", "(", "args", ")", ".", "items", "(", ")", "}"], "docstring": "convert a list of '='-spaced command-line arguments to a dictionary, evaluating python objects when possible", "docstring_tokens": ["convert", "a", "list", "of", "=", "-", "spaced", "command", "-", "line", "arguments", "to", "a", "dictionary", "evaluating", "python", "objects", "when", "possible"], "sha": "3301089b48c42b87b396e246ea3f56fa4bfc9678", "url": "https://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/run.py#L180-L192", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "compute_geometric_median", "original_string": "def compute_geometric_median(X, eps=1e-5):\n    \"\"\"\n    Estimate the geometric median of points in 2D.\n\n    Code from https://stackoverflow.com/a/30305181\n\n    Parameters\n    ----------\n    X : (N,2) ndarray\n        Points in 2D. Second axis must be given in xy-form.\n\n    eps : float, optional\n        Distance threshold when to return the median.\n\n    Returns\n    -------\n    (2,) ndarray\n        Geometric median as xy-coordinate.\n\n    \"\"\"\n    y = np.mean(X, 0)\n\n    while True:\n        D = scipy.spatial.distance.cdist(X, [y])\n        nonzeros = (D != 0)[:, 0]\n\n        Dinv = 1 / D[nonzeros]\n        Dinvs = np.sum(Dinv)\n        W = Dinv / Dinvs\n        T = np.sum(W * X[nonzeros], 0)\n\n        num_zeros = len(X) - np.sum(nonzeros)\n        if num_zeros == 0:\n            y1 = T\n        elif num_zeros == len(X):\n            return y\n        else:\n            R = (T - y) * Dinvs\n            r = np.linalg.norm(R)\n            rinv = 0 if r == 0 else num_zeros/r\n            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n\n        if scipy.spatial.distance.euclidean(y, y1) < eps:\n            return y1\n\n        y = y1", "language": "python", "code": "def compute_geometric_median(X, eps=1e-5):\n    \"\"\"\n    Estimate the geometric median of points in 2D.\n\n    Code from https://stackoverflow.com/a/30305181\n\n    Parameters\n    ----------\n    X : (N,2) ndarray\n        Points in 2D. Second axis must be given in xy-form.\n\n    eps : float, optional\n        Distance threshold when to return the median.\n\n    Returns\n    -------\n    (2,) ndarray\n        Geometric median as xy-coordinate.\n\n    \"\"\"\n    y = np.mean(X, 0)\n\n    while True:\n        D = scipy.spatial.distance.cdist(X, [y])\n        nonzeros = (D != 0)[:, 0]\n\n        Dinv = 1 / D[nonzeros]\n        Dinvs = np.sum(Dinv)\n        W = Dinv / Dinvs\n        T = np.sum(W * X[nonzeros], 0)\n\n        num_zeros = len(X) - np.sum(nonzeros)\n        if num_zeros == 0:\n            y1 = T\n        elif num_zeros == len(X):\n            return y\n        else:\n            R = (T - y) * Dinvs\n            r = np.linalg.norm(R)\n            rinv = 0 if r == 0 else num_zeros/r\n            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n\n        if scipy.spatial.distance.euclidean(y, y1) < eps:\n            return y1\n\n        y = y1", "code_tokens": ["def", "compute_geometric_median", "(", "X", ",", "eps", "=", "1e-5", ")", ":", "y", "=", "np", ".", "mean", "(", "X", ",", "0", ")", "while", "True", ":", "D", "=", "scipy", ".", "spatial", ".", "distance", ".", "cdist", "(", "X", ",", "[", "y", "]", ")", "nonzeros", "=", "(", "D", "!=", "0", ")", "[", ":", ",", "0", "]", "Dinv", "=", "1", "/", "D", "[", "nonzeros", "]", "Dinvs", "=", "np", ".", "sum", "(", "Dinv", ")", "W", "=", "Dinv", "/", "Dinvs", "T", "=", "np", ".", "sum", "(", "W", "*", "X", "[", "nonzeros", "]", ",", "0", ")", "num_zeros", "=", "len", "(", "X", ")", "-", "np", ".", "sum", "(", "nonzeros", ")", "if", "num_zeros", "==", "0", ":", "y1", "=", "T", "elif", "num_zeros", "==", "len", "(", "X", ")", ":", "return", "y", "else", ":", "R", "=", "(", "T", "-", "y", ")", "*", "Dinvs", "r", "=", "np", ".", "linalg", ".", "norm", "(", "R", ")", "rinv", "=", "0", "if", "r", "==", "0", "else", "num_zeros", "/", "r", "y1", "=", "max", "(", "0", ",", "1", "-", "rinv", ")", "*", "T", "+", "min", "(", "1", ",", "rinv", ")", "*", "y", "if", "scipy", ".", "spatial", ".", "distance", ".", "euclidean", "(", "y", ",", "y1", ")", "<", "eps", ":", "return", "y1", "y", "=", "y1"], "docstring": "Estimate the geometric median of points in 2D.\n\n    Code from https://stackoverflow.com/a/30305181\n\n    Parameters\n    ----------\n    X : (N,2) ndarray\n        Points in 2D. Second axis must be given in xy-form.\n\n    eps : float, optional\n        Distance threshold when to return the median.\n\n    Returns\n    -------\n    (2,) ndarray\n        Geometric median as xy-coordinate.", "docstring_tokens": ["Estimate", "the", "geometric", "median", "of", "points", "in", "2D", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L13-L58", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.project", "original_string": "def project(self, from_shape, to_shape):\n        \"\"\"\n        Project the keypoint onto a new position on a new image.\n\n        E.g. if the keypoint is on its original image at x=(10 of 100 pixels)\n        and y=(20 of 100 pixels) and is projected onto a new image with\n        size (width=200, height=200), its new position will be (20, 40).\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.\n\n        \"\"\"\n        xy_proj = project_coords([(self.x, self.y)], from_shape, to_shape)\n        return self.deepcopy(x=xy_proj[0][0], y=xy_proj[0][1])", "language": "python", "code": "def project(self, from_shape, to_shape):\n        \"\"\"\n        Project the keypoint onto a new position on a new image.\n\n        E.g. if the keypoint is on its original image at x=(10 of 100 pixels)\n        and y=(20 of 100 pixels) and is projected onto a new image with\n        size (width=200, height=200), its new position will be (20, 40).\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.\n\n        \"\"\"\n        xy_proj = project_coords([(self.x, self.y)], from_shape, to_shape)\n        return self.deepcopy(x=xy_proj[0][0], y=xy_proj[0][1])", "code_tokens": ["def", "project", "(", "self", ",", "from_shape", ",", "to_shape", ")", ":", "xy_proj", "=", "project_coords", "(", "[", "(", "self", ".", "x", ",", "self", ".", "y", ")", "]", ",", "from_shape", ",", "to_shape", ")", "return", "self", ".", "deepcopy", "(", "x", "=", "xy_proj", "[", "0", "]", "[", "0", "]", ",", "y", "=", "xy_proj", "[", "0", "]", "[", "1", "]", ")"], "docstring": "Project the keypoint onto a new position on a new image.\n\n        E.g. if the keypoint is on its original image at x=(10 of 100 pixels)\n        and y=(20 of 100 pixels) and is projected onto a new image with\n        size (width=200, height=200), its new position will be (20, 40).\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.", "docstring_tokens": ["Project", "the", "keypoint", "onto", "a", "new", "position", "on", "a", "new", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L105-L131", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.shift", "original_string": "def shift(self, x=0, y=0):\n        \"\"\"\n        Move the keypoint around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move by this value on the x axis.\n\n        y : number, optional\n            Move by this value on the y axis.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.\n\n        \"\"\"\n        return self.deepcopy(self.x + x, self.y + y)", "language": "python", "code": "def shift(self, x=0, y=0):\n        \"\"\"\n        Move the keypoint around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move by this value on the x axis.\n\n        y : number, optional\n            Move by this value on the y axis.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.\n\n        \"\"\"\n        return self.deepcopy(self.x + x, self.y + y)", "code_tokens": ["def", "shift", "(", "self", ",", "x", "=", "0", ",", "y", "=", "0", ")", ":", "return", "self", ".", "deepcopy", "(", "self", ".", "x", "+", "x", ",", "self", ".", "y", "+", "y", ")"], "docstring": "Move the keypoint around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move by this value on the x axis.\n\n        y : number, optional\n            Move by this value on the y axis.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Keypoint object with new coordinates.", "docstring_tokens": ["Move", "the", "keypoint", "around", "on", "an", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L133-L151", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.draw_on_image", "original_string": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=3,\n                      copy=True, raise_if_out_of_image=False):\n        \"\"\"\n        Draw the keypoint onto a given image.\n\n        The keypoint is drawn as a square.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoint.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of the keypoint. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of the keypoint. If set to ``S``, each square will have\n            size ``S x S``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the keypoint.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if the keypoint is outside of the\n            image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoint.\n\n        \"\"\"\n        if copy:\n            image = np.copy(image)\n\n        if image.ndim == 2:\n            assert ia.is_single_number(color), (\n                \"Got a 2D image. Expected then 'color' to be a single number, \"\n                \"but got %s.\" % (str(color),))\n        elif image.ndim == 3 and ia.is_single_number(color):\n            color = [color] * image.shape[-1]\n\n        input_dtype = image.dtype\n        alpha_color = color\n        if alpha < 0.01:\n            # keypoint invisible, nothing to do\n            return image\n        elif alpha > 0.99:\n            alpha = 1\n        else:\n            image = image.astype(np.float32, copy=False)\n            alpha_color = alpha * np.array(color)\n\n        height, width = image.shape[0:2]\n\n        y, x = self.y_int, self.x_int\n\n        x1 = max(x - size//2, 0)\n        x2 = min(x + 1 + size//2, width)\n        y1 = max(y - size//2, 0)\n        y2 = min(y + 1 + size//2, height)\n\n        x1_clipped, x2_clipped = np.clip([x1, x2], 0, width)\n        y1_clipped, y2_clipped = np.clip([y1, y2], 0, height)\n\n        x1_clipped_ooi = (x1_clipped < 0 or x1_clipped >= width)\n        x2_clipped_ooi = (x2_clipped < 0 or x2_clipped >= width+1)\n        y1_clipped_ooi = (y1_clipped < 0 or y1_clipped >= height)\n        y2_clipped_ooi = (y2_clipped < 0 or y2_clipped >= height+1)\n        x_ooi = (x1_clipped_ooi and x2_clipped_ooi)\n        y_ooi = (y1_clipped_ooi and y2_clipped_ooi)\n        x_zero_size = (x2_clipped - x1_clipped) < 1  # min size is 1px\n        y_zero_size = (y2_clipped - y1_clipped) < 1\n        if not x_ooi and not y_ooi and not x_zero_size and not y_zero_size:\n            if alpha == 1:\n                image[y1_clipped:y2_clipped, x1_clipped:x2_clipped] = color\n            else:\n                image[y1_clipped:y2_clipped, x1_clipped:x2_clipped] = (\n                        (1 - alpha)\n                        * image[y1_clipped:y2_clipped, x1_clipped:x2_clipped]\n                        + alpha_color\n                )\n        else:\n            if raise_if_out_of_image:\n                raise Exception(\n                    \"Cannot draw keypoint x=%.8f, y=%.8f on image with \"\n                    \"shape %s.\" % (y, x, image.shape))\n\n        if image.dtype.name != input_dtype.name:\n            if input_dtype.name == \"uint8\":\n                image = np.clip(image, 0, 255, out=image)\n            image = image.astype(input_dtype, copy=False)\n        return image", "language": "python", "code": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=3,\n                      copy=True, raise_if_out_of_image=False):\n        \"\"\"\n        Draw the keypoint onto a given image.\n\n        The keypoint is drawn as a square.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoint.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of the keypoint. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of the keypoint. If set to ``S``, each square will have\n            size ``S x S``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the keypoint.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if the keypoint is outside of the\n            image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoint.\n\n        \"\"\"\n        if copy:\n            image = np.copy(image)\n\n        if image.ndim == 2:\n            assert ia.is_single_number(color), (\n                \"Got a 2D image. Expected then 'color' to be a single number, \"\n                \"but got %s.\" % (str(color),))\n        elif image.ndim == 3 and ia.is_single_number(color):\n            color = [color] * image.shape[-1]\n\n        input_dtype = image.dtype\n        alpha_color = color\n        if alpha < 0.01:\n            # keypoint invisible, nothing to do\n            return image\n        elif alpha > 0.99:\n            alpha = 1\n        else:\n            image = image.astype(np.float32, copy=False)\n            alpha_color = alpha * np.array(color)\n\n        height, width = image.shape[0:2]\n\n        y, x = self.y_int, self.x_int\n\n        x1 = max(x - size//2, 0)\n        x2 = min(x + 1 + size//2, width)\n        y1 = max(y - size//2, 0)\n        y2 = min(y + 1 + size//2, height)\n\n        x1_clipped, x2_clipped = np.clip([x1, x2], 0, width)\n        y1_clipped, y2_clipped = np.clip([y1, y2], 0, height)\n\n        x1_clipped_ooi = (x1_clipped < 0 or x1_clipped >= width)\n        x2_clipped_ooi = (x2_clipped < 0 or x2_clipped >= width+1)\n        y1_clipped_ooi = (y1_clipped < 0 or y1_clipped >= height)\n        y2_clipped_ooi = (y2_clipped < 0 or y2_clipped >= height+1)\n        x_ooi = (x1_clipped_ooi and x2_clipped_ooi)\n        y_ooi = (y1_clipped_ooi and y2_clipped_ooi)\n        x_zero_size = (x2_clipped - x1_clipped) < 1  # min size is 1px\n        y_zero_size = (y2_clipped - y1_clipped) < 1\n        if not x_ooi and not y_ooi and not x_zero_size and not y_zero_size:\n            if alpha == 1:\n                image[y1_clipped:y2_clipped, x1_clipped:x2_clipped] = color\n            else:\n                image[y1_clipped:y2_clipped, x1_clipped:x2_clipped] = (\n                        (1 - alpha)\n                        * image[y1_clipped:y2_clipped, x1_clipped:x2_clipped]\n                        + alpha_color\n                )\n        else:\n            if raise_if_out_of_image:\n                raise Exception(\n                    \"Cannot draw keypoint x=%.8f, y=%.8f on image with \"\n                    \"shape %s.\" % (y, x, image.shape))\n\n        if image.dtype.name != input_dtype.name:\n            if input_dtype.name == \"uint8\":\n                image = np.clip(image, 0, 255, out=image)\n            image = image.astype(input_dtype, copy=False)\n        return image", "code_tokens": ["def", "draw_on_image", "(", "self", ",", "image", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "alpha", "=", "1.0", ",", "size", "=", "3", ",", "copy", "=", "True", ",", "raise_if_out_of_image", "=", "False", ")", ":", "if", "copy", ":", "image", "=", "np", ".", "copy", "(", "image", ")", "if", "image", ".", "ndim", "==", "2", ":", "assert", "ia", ".", "is_single_number", "(", "color", ")", ",", "(", "\"Got a 2D image. Expected then 'color' to be a single number, \"", "\"but got %s.\"", "%", "(", "str", "(", "color", ")", ",", ")", ")", "elif", "image", ".", "ndim", "==", "3", "and", "ia", ".", "is_single_number", "(", "color", ")", ":", "color", "=", "[", "color", "]", "*", "image", ".", "shape", "[", "-", "1", "]", "input_dtype", "=", "image", ".", "dtype", "alpha_color", "=", "color", "if", "alpha", "<", "0.01", ":", "# keypoint invisible, nothing to do", "return", "image", "elif", "alpha", ">", "0.99", ":", "alpha", "=", "1", "else", ":", "image", "=", "image", ".", "astype", "(", "np", ".", "float32", ",", "copy", "=", "False", ")", "alpha_color", "=", "alpha", "*", "np", ".", "array", "(", "color", ")", "height", ",", "width", "=", "image", ".", "shape", "[", "0", ":", "2", "]", "y", ",", "x", "=", "self", ".", "y_int", ",", "self", ".", "x_int", "x1", "=", "max", "(", "x", "-", "size", "//", "2", ",", "0", ")", "x2", "=", "min", "(", "x", "+", "1", "+", "size", "//", "2", ",", "width", ")", "y1", "=", "max", "(", "y", "-", "size", "//", "2", ",", "0", ")", "y2", "=", "min", "(", "y", "+", "1", "+", "size", "//", "2", ",", "height", ")", "x1_clipped", ",", "x2_clipped", "=", "np", ".", "clip", "(", "[", "x1", ",", "x2", "]", ",", "0", ",", "width", ")", "y1_clipped", ",", "y2_clipped", "=", "np", ".", "clip", "(", "[", "y1", ",", "y2", "]", ",", "0", ",", "height", ")", "x1_clipped_ooi", "=", "(", "x1_clipped", "<", "0", "or", "x1_clipped", ">=", "width", ")", "x2_clipped_ooi", "=", "(", "x2_clipped", "<", "0", "or", "x2_clipped", ">=", "width", "+", "1", ")", "y1_clipped_ooi", "=", "(", "y1_clipped", "<", "0", "or", "y1_clipped", ">=", "height", ")", "y2_clipped_ooi", "=", "(", "y2_clipped", "<", "0", "or", "y2_clipped", ">=", "height", "+", "1", ")", "x_ooi", "=", "(", "x1_clipped_ooi", "and", "x2_clipped_ooi", ")", "y_ooi", "=", "(", "y1_clipped_ooi", "and", "y2_clipped_ooi", ")", "x_zero_size", "=", "(", "x2_clipped", "-", "x1_clipped", ")", "<", "1", "# min size is 1px", "y_zero_size", "=", "(", "y2_clipped", "-", "y1_clipped", ")", "<", "1", "if", "not", "x_ooi", "and", "not", "y_ooi", "and", "not", "x_zero_size", "and", "not", "y_zero_size", ":", "if", "alpha", "==", "1", ":", "image", "[", "y1_clipped", ":", "y2_clipped", ",", "x1_clipped", ":", "x2_clipped", "]", "=", "color", "else", ":", "image", "[", "y1_clipped", ":", "y2_clipped", ",", "x1_clipped", ":", "x2_clipped", "]", "=", "(", "(", "1", "-", "alpha", ")", "*", "image", "[", "y1_clipped", ":", "y2_clipped", ",", "x1_clipped", ":", "x2_clipped", "]", "+", "alpha_color", ")", "else", ":", "if", "raise_if_out_of_image", ":", "raise", "Exception", "(", "\"Cannot draw keypoint x=%.8f, y=%.8f on image with \"", "\"shape %s.\"", "%", "(", "y", ",", "x", ",", "image", ".", "shape", ")", ")", "if", "image", ".", "dtype", ".", "name", "!=", "input_dtype", ".", "name", ":", "if", "input_dtype", ".", "name", "==", "\"uint8\"", ":", "image", "=", "np", ".", "clip", "(", "image", ",", "0", ",", "255", ",", "out", "=", "image", ")", "image", "=", "image", ".", "astype", "(", "input_dtype", ",", "copy", "=", "False", ")", "return", "image"], "docstring": "Draw the keypoint onto a given image.\n\n        The keypoint is drawn as a square.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoint.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of the keypoint. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of the keypoint. If set to ``S``, each square will have\n            size ``S x S``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the keypoint.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if the keypoint is outside of the\n            image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoint.", "docstring_tokens": ["Draw", "the", "keypoint", "onto", "a", "given", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L153-L250", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.generate_similar_points_manhattan", "original_string": "def generate_similar_points_manhattan(self, nb_steps, step_size, return_array=False):\n        \"\"\"\n        Generate nearby points to this keypoint based on manhattan distance.\n\n        To generate the first neighbouring points, a distance of S (step size) is moved from the\n        center point (this keypoint) to the top, right, bottom and left, resulting in four new\n        points. From these new points, the pattern is repeated. Overlapping points are ignored.\n\n        The resulting points have a shape similar to a square rotated by 45 degrees.\n\n        Parameters\n        ----------\n        nb_steps : int\n            The number of steps to move from the center point. nb_steps=1 results in a total of\n            5 output points (1 center point + 4 neighbours).\n\n        step_size : number\n            The step size to move from every point to its neighbours.\n\n        return_array : bool, optional\n            Whether to return the generated points as a list of keypoints or an array\n            of shape ``(N,2)``, where ``N`` is the number of generated points and the second axis contains\n            the x- (first value) and y- (second value) coordinates.\n\n        Returns\n        -------\n        points : list of imgaug.Keypoint or (N,2) ndarray\n            If return_array was False, then a list of Keypoint.\n            Otherwise a numpy array of shape ``(N,2)``, where ``N`` is the number of generated points and\n            the second axis contains the x- (first value) and y- (second value) coordinates.\n            The center keypoint (the one on which this function was called) is always included.\n\n        \"\"\"\n        # TODO add test\n        # Points generates in manhattan style with S steps have a shape similar to a 45deg rotated\n        # square. The center line with the origin point has S+1+S = 1+2*S points (S to the left,\n        # S to the right). The lines above contain (S+1+S)-2 + (S+1+S)-2-2 + ... + 1 points. E.g.\n        # for S=2 it would be 3+1=4 and for S=3 it would be 5+3+1=9. Same for the lines below the\n        # center. Hence the total number of points is S+1+S + 2*(S^2).\n        points = np.zeros((nb_steps + 1 + nb_steps + 2*(nb_steps**2), 2), dtype=np.float32)\n\n        # we start at the bottom-most line and move towards the top-most line\n        yy = np.linspace(self.y - nb_steps * step_size, self.y + nb_steps * step_size, nb_steps + 1 + nb_steps)\n\n        # bottom-most line contains only one point\n        width = 1\n\n        nth_point = 0\n        for i_y, y in enumerate(yy):\n            if width == 1:\n                xx = [self.x]\n            else:\n                xx = np.linspace(self.x - (width-1)//2 * step_size, self.x + (width-1)//2 * step_size, width)\n            for x in xx:\n                points[nth_point] = [x, y]\n                nth_point += 1\n            if i_y < nb_steps:\n                width += 2\n            else:\n                width -= 2\n\n        if return_array:\n            return points\n        return [self.deepcopy(x=points[i, 0], y=points[i, 1]) for i in sm.xrange(points.shape[0])]", "language": "python", "code": "def generate_similar_points_manhattan(self, nb_steps, step_size, return_array=False):\n        \"\"\"\n        Generate nearby points to this keypoint based on manhattan distance.\n\n        To generate the first neighbouring points, a distance of S (step size) is moved from the\n        center point (this keypoint) to the top, right, bottom and left, resulting in four new\n        points. From these new points, the pattern is repeated. Overlapping points are ignored.\n\n        The resulting points have a shape similar to a square rotated by 45 degrees.\n\n        Parameters\n        ----------\n        nb_steps : int\n            The number of steps to move from the center point. nb_steps=1 results in a total of\n            5 output points (1 center point + 4 neighbours).\n\n        step_size : number\n            The step size to move from every point to its neighbours.\n\n        return_array : bool, optional\n            Whether to return the generated points as a list of keypoints or an array\n            of shape ``(N,2)``, where ``N`` is the number of generated points and the second axis contains\n            the x- (first value) and y- (second value) coordinates.\n\n        Returns\n        -------\n        points : list of imgaug.Keypoint or (N,2) ndarray\n            If return_array was False, then a list of Keypoint.\n            Otherwise a numpy array of shape ``(N,2)``, where ``N`` is the number of generated points and\n            the second axis contains the x- (first value) and y- (second value) coordinates.\n            The center keypoint (the one on which this function was called) is always included.\n\n        \"\"\"\n        # TODO add test\n        # Points generates in manhattan style with S steps have a shape similar to a 45deg rotated\n        # square. The center line with the origin point has S+1+S = 1+2*S points (S to the left,\n        # S to the right). The lines above contain (S+1+S)-2 + (S+1+S)-2-2 + ... + 1 points. E.g.\n        # for S=2 it would be 3+1=4 and for S=3 it would be 5+3+1=9. Same for the lines below the\n        # center. Hence the total number of points is S+1+S + 2*(S^2).\n        points = np.zeros((nb_steps + 1 + nb_steps + 2*(nb_steps**2), 2), dtype=np.float32)\n\n        # we start at the bottom-most line and move towards the top-most line\n        yy = np.linspace(self.y - nb_steps * step_size, self.y + nb_steps * step_size, nb_steps + 1 + nb_steps)\n\n        # bottom-most line contains only one point\n        width = 1\n\n        nth_point = 0\n        for i_y, y in enumerate(yy):\n            if width == 1:\n                xx = [self.x]\n            else:\n                xx = np.linspace(self.x - (width-1)//2 * step_size, self.x + (width-1)//2 * step_size, width)\n            for x in xx:\n                points[nth_point] = [x, y]\n                nth_point += 1\n            if i_y < nb_steps:\n                width += 2\n            else:\n                width -= 2\n\n        if return_array:\n            return points\n        return [self.deepcopy(x=points[i, 0], y=points[i, 1]) for i in sm.xrange(points.shape[0])]", "code_tokens": ["def", "generate_similar_points_manhattan", "(", "self", ",", "nb_steps", ",", "step_size", ",", "return_array", "=", "False", ")", ":", "# TODO add test", "# Points generates in manhattan style with S steps have a shape similar to a 45deg rotated", "# square. The center line with the origin point has S+1+S = 1+2*S points (S to the left,", "# S to the right). The lines above contain (S+1+S)-2 + (S+1+S)-2-2 + ... + 1 points. E.g.", "# for S=2 it would be 3+1=4 and for S=3 it would be 5+3+1=9. Same for the lines below the", "# center. Hence the total number of points is S+1+S + 2*(S^2).", "points", "=", "np", ".", "zeros", "(", "(", "nb_steps", "+", "1", "+", "nb_steps", "+", "2", "*", "(", "nb_steps", "**", "2", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "# we start at the bottom-most line and move towards the top-most line", "yy", "=", "np", ".", "linspace", "(", "self", ".", "y", "-", "nb_steps", "*", "step_size", ",", "self", ".", "y", "+", "nb_steps", "*", "step_size", ",", "nb_steps", "+", "1", "+", "nb_steps", ")", "# bottom-most line contains only one point", "width", "=", "1", "nth_point", "=", "0", "for", "i_y", ",", "y", "in", "enumerate", "(", "yy", ")", ":", "if", "width", "==", "1", ":", "xx", "=", "[", "self", ".", "x", "]", "else", ":", "xx", "=", "np", ".", "linspace", "(", "self", ".", "x", "-", "(", "width", "-", "1", ")", "//", "2", "*", "step_size", ",", "self", ".", "x", "+", "(", "width", "-", "1", ")", "//", "2", "*", "step_size", ",", "width", ")", "for", "x", "in", "xx", ":", "points", "[", "nth_point", "]", "=", "[", "x", ",", "y", "]", "nth_point", "+=", "1", "if", "i_y", "<", "nb_steps", ":", "width", "+=", "2", "else", ":", "width", "-=", "2", "if", "return_array", ":", "return", "points", "return", "[", "self", ".", "deepcopy", "(", "x", "=", "points", "[", "i", ",", "0", "]", ",", "y", "=", "points", "[", "i", ",", "1", "]", ")", "for", "i", "in", "sm", ".", "xrange", "(", "points", ".", "shape", "[", "0", "]", ")", "]"], "docstring": "Generate nearby points to this keypoint based on manhattan distance.\n\n        To generate the first neighbouring points, a distance of S (step size) is moved from the\n        center point (this keypoint) to the top, right, bottom and left, resulting in four new\n        points. From these new points, the pattern is repeated. Overlapping points are ignored.\n\n        The resulting points have a shape similar to a square rotated by 45 degrees.\n\n        Parameters\n        ----------\n        nb_steps : int\n            The number of steps to move from the center point. nb_steps=1 results in a total of\n            5 output points (1 center point + 4 neighbours).\n\n        step_size : number\n            The step size to move from every point to its neighbours.\n\n        return_array : bool, optional\n            Whether to return the generated points as a list of keypoints or an array\n            of shape ``(N,2)``, where ``N`` is the number of generated points and the second axis contains\n            the x- (first value) and y- (second value) coordinates.\n\n        Returns\n        -------\n        points : list of imgaug.Keypoint or (N,2) ndarray\n            If return_array was False, then a list of Keypoint.\n            Otherwise a numpy array of shape ``(N,2)``, where ``N`` is the number of generated points and\n            the second axis contains the x- (first value) and y- (second value) coordinates.\n            The center keypoint (the one on which this function was called) is always included.", "docstring_tokens": ["Generate", "nearby", "points", "to", "this", "keypoint", "based", "on", "manhattan", "distance", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L252-L315", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.copy", "original_string": "def copy(self, x=None, y=None):\n        \"\"\"\n        Create a shallow copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Shallow copy.\n\n        \"\"\"\n        return self.deepcopy(x=x, y=y)", "language": "python", "code": "def copy(self, x=None, y=None):\n        \"\"\"\n        Create a shallow copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Shallow copy.\n\n        \"\"\"\n        return self.deepcopy(x=x, y=y)", "code_tokens": ["def", "copy", "(", "self", ",", "x", "=", "None", ",", "y", "=", "None", ")", ":", "return", "self", ".", "deepcopy", "(", "x", "=", "x", ",", "y", "=", "y", ")"], "docstring": "Create a shallow copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Shallow copy.", "docstring_tokens": ["Create", "a", "shallow", "copy", "of", "the", "Keypoint", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L317-L337", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "Keypoint.deepcopy", "original_string": "def deepcopy(self, x=None, y=None):\n        \"\"\"\n        Create a deep copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Deep copy.\n\n        \"\"\"\n        x = self.x if x is None else x\n        y = self.y if y is None else y\n        return Keypoint(x=x, y=y)", "language": "python", "code": "def deepcopy(self, x=None, y=None):\n        \"\"\"\n        Create a deep copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Deep copy.\n\n        \"\"\"\n        x = self.x if x is None else x\n        y = self.y if y is None else y\n        return Keypoint(x=x, y=y)", "code_tokens": ["def", "deepcopy", "(", "self", ",", "x", "=", "None", ",", "y", "=", "None", ")", ":", "x", "=", "self", ".", "x", "if", "x", "is", "None", "else", "x", "y", "=", "self", ".", "y", "if", "y", "is", "None", "else", "y", "return", "Keypoint", "(", "x", "=", "x", ",", "y", "=", "y", ")"], "docstring": "Create a deep copy of the Keypoint object.\n\n        Parameters\n        ----------\n        x : None or number, optional\n            Coordinate of the keypoint on the x axis.\n            If ``None``, the instance's value will be copied.\n\n        y : None or number, optional\n            Coordinate of the keypoint on the y axis.\n            If ``None``, the instance's value will be copied.\n\n        Returns\n        -------\n        imgaug.Keypoint\n            Deep copy.", "docstring_tokens": ["Create", "a", "deep", "copy", "of", "the", "Keypoint", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L339-L361", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "KeypointsOnImage.on", "original_string": "def on(self, image):\n        \"\"\"\n        Project keypoints from one image to a new one.\n\n        Parameters\n        ----------\n        image : ndarray or tuple of int\n            New image onto which the keypoints are to be projected.\n            May also simply be that new image's shape tuple.\n\n        Returns\n        -------\n        keypoints : imgaug.KeypointsOnImage\n            Object containing all projected keypoints.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        if shape[0:2] == self.shape[0:2]:\n            return self.deepcopy()\n        else:\n            keypoints = [kp.project(self.shape, shape) for kp in self.keypoints]\n            return self.deepcopy(keypoints, shape)", "language": "python", "code": "def on(self, image):\n        \"\"\"\n        Project keypoints from one image to a new one.\n\n        Parameters\n        ----------\n        image : ndarray or tuple of int\n            New image onto which the keypoints are to be projected.\n            May also simply be that new image's shape tuple.\n\n        Returns\n        -------\n        keypoints : imgaug.KeypointsOnImage\n            Object containing all projected keypoints.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        if shape[0:2] == self.shape[0:2]:\n            return self.deepcopy()\n        else:\n            keypoints = [kp.project(self.shape, shape) for kp in self.keypoints]\n            return self.deepcopy(keypoints, shape)", "code_tokens": ["def", "on", "(", "self", ",", "image", ")", ":", "shape", "=", "normalize_shape", "(", "image", ")", "if", "shape", "[", "0", ":", "2", "]", "==", "self", ".", "shape", "[", "0", ":", "2", "]", ":", "return", "self", ".", "deepcopy", "(", ")", "else", ":", "keypoints", "=", "[", "kp", ".", "project", "(", "self", ".", "shape", ",", "shape", ")", "for", "kp", "in", "self", ".", "keypoints", "]", "return", "self", ".", "deepcopy", "(", "keypoints", ",", "shape", ")"], "docstring": "Project keypoints from one image to a new one.\n\n        Parameters\n        ----------\n        image : ndarray or tuple of int\n            New image onto which the keypoints are to be projected.\n            May also simply be that new image's shape tuple.\n\n        Returns\n        -------\n        keypoints : imgaug.KeypointsOnImage\n            Object containing all projected keypoints.", "docstring_tokens": ["Project", "keypoints", "from", "one", "image", "to", "a", "new", "one", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L414-L435", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "KeypointsOnImage.draw_on_image", "original_string": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=3,\n                      copy=True, raise_if_out_of_image=False):\n        \"\"\"\n        Draw all keypoints onto a given image.\n\n        Each keypoint is marked by a square of a chosen color and size.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoints.\n            This image should usually have the same shape as\n            set in KeypointsOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all keypoints. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of each point. If set to ``C``, each square will have\n            size ``C x C``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the points.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any keypoint is outside of the image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoints.\n\n        \"\"\"\n        image = np.copy(image) if copy else image\n        for keypoint in self.keypoints:\n            image = keypoint.draw_on_image(\n                image, color=color, alpha=alpha, size=size, copy=False,\n                raise_if_out_of_image=raise_if_out_of_image)\n        return image", "language": "python", "code": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=3,\n                      copy=True, raise_if_out_of_image=False):\n        \"\"\"\n        Draw all keypoints onto a given image.\n\n        Each keypoint is marked by a square of a chosen color and size.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoints.\n            This image should usually have the same shape as\n            set in KeypointsOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all keypoints. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of each point. If set to ``C``, each square will have\n            size ``C x C``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the points.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any keypoint is outside of the image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoints.\n\n        \"\"\"\n        image = np.copy(image) if copy else image\n        for keypoint in self.keypoints:\n            image = keypoint.draw_on_image(\n                image, color=color, alpha=alpha, size=size, copy=False,\n                raise_if_out_of_image=raise_if_out_of_image)\n        return image", "code_tokens": ["def", "draw_on_image", "(", "self", ",", "image", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "alpha", "=", "1.0", ",", "size", "=", "3", ",", "copy", "=", "True", ",", "raise_if_out_of_image", "=", "False", ")", ":", "image", "=", "np", ".", "copy", "(", "image", ")", "if", "copy", "else", "image", "for", "keypoint", "in", "self", ".", "keypoints", ":", "image", "=", "keypoint", ".", "draw_on_image", "(", "image", ",", "color", "=", "color", ",", "alpha", "=", "alpha", ",", "size", "=", "size", ",", "copy", "=", "False", ",", "raise_if_out_of_image", "=", "raise_if_out_of_image", ")", "return", "image"], "docstring": "Draw all keypoints onto a given image.\n\n        Each keypoint is marked by a square of a chosen color and size.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the keypoints.\n            This image should usually have the same shape as\n            set in KeypointsOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all keypoints. If a single int ``C``, then that is\n            equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            The opacity of the drawn keypoint, where ``1.0`` denotes a fully\n            visible keypoint and ``0.0`` an invisible one.\n\n        size : int, optional\n            The size of each point. If set to ``C``, each square will have\n            size ``C x C``.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the points.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any keypoint is outside of the image.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn keypoints.", "docstring_tokens": ["Draw", "all", "keypoints", "onto", "a", "given", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L437-L480", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "KeypointsOnImage.shift", "original_string": "def shift(self, x=0, y=0):\n        \"\"\"\n        Move the keypoints around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move each keypoint by this value on the x axis.\n\n        y : number, optional\n            Move each keypoint by this value on the y axis.\n\n        Returns\n        -------\n        out : KeypointsOnImage\n            Keypoints after moving them.\n\n        \"\"\"\n        keypoints = [keypoint.shift(x=x, y=y) for keypoint in self.keypoints]\n        return self.deepcopy(keypoints)", "language": "python", "code": "def shift(self, x=0, y=0):\n        \"\"\"\n        Move the keypoints around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move each keypoint by this value on the x axis.\n\n        y : number, optional\n            Move each keypoint by this value on the y axis.\n\n        Returns\n        -------\n        out : KeypointsOnImage\n            Keypoints after moving them.\n\n        \"\"\"\n        keypoints = [keypoint.shift(x=x, y=y) for keypoint in self.keypoints]\n        return self.deepcopy(keypoints)", "code_tokens": ["def", "shift", "(", "self", ",", "x", "=", "0", ",", "y", "=", "0", ")", ":", "keypoints", "=", "[", "keypoint", ".", "shift", "(", "x", "=", "x", ",", "y", "=", "y", ")", "for", "keypoint", "in", "self", ".", "keypoints", "]", "return", "self", ".", "deepcopy", "(", "keypoints", ")"], "docstring": "Move the keypoints around on an image.\n\n        Parameters\n        ----------\n        x : number, optional\n            Move each keypoint by this value on the x axis.\n\n        y : number, optional\n            Move each keypoint by this value on the y axis.\n\n        Returns\n        -------\n        out : KeypointsOnImage\n            Keypoints after moving them.", "docstring_tokens": ["Move", "the", "keypoints", "around", "on", "an", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L482-L501", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "KeypointsOnImage.copy", "original_string": "def copy(self, keypoints=None, shape=None):\n        \"\"\"\n        Create a shallow copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Shallow copy.\n\n        \"\"\"\n        result = copy.copy(self)\n        if keypoints is not None:\n            result.keypoints = keypoints\n        if shape is not None:\n            result.shape = shape\n        return result", "language": "python", "code": "def copy(self, keypoints=None, shape=None):\n        \"\"\"\n        Create a shallow copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Shallow copy.\n\n        \"\"\"\n        result = copy.copy(self)\n        if keypoints is not None:\n            result.keypoints = keypoints\n        if shape is not None:\n            result.shape = shape\n        return result", "code_tokens": ["def", "copy", "(", "self", ",", "keypoints", "=", "None", ",", "shape", "=", "None", ")", ":", "result", "=", "copy", ".", "copy", "(", "self", ")", "if", "keypoints", "is", "not", "None", ":", "result", ".", "keypoints", "=", "keypoints", "if", "shape", "is", "not", "None", ":", "result", ".", "shape", "=", "shape", "return", "result"], "docstring": "Create a shallow copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Shallow copy.", "docstring_tokens": ["Create", "a", "shallow", "copy", "of", "the", "KeypointsOnImage", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L825-L850", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/kps.py", "func_name": "KeypointsOnImage.deepcopy", "original_string": "def deepcopy(self, keypoints=None, shape=None):\n        \"\"\"\n        Create a deep copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Deep copy.\n\n        \"\"\"\n        # for some reason deepcopy is way slower here than manual copy\n        if keypoints is None:\n            keypoints = [kp.deepcopy() for kp in self.keypoints]\n        if shape is None:\n            shape = tuple(self.shape)\n        return KeypointsOnImage(keypoints, shape)", "language": "python", "code": "def deepcopy(self, keypoints=None, shape=None):\n        \"\"\"\n        Create a deep copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Deep copy.\n\n        \"\"\"\n        # for some reason deepcopy is way slower here than manual copy\n        if keypoints is None:\n            keypoints = [kp.deepcopy() for kp in self.keypoints]\n        if shape is None:\n            shape = tuple(self.shape)\n        return KeypointsOnImage(keypoints, shape)", "code_tokens": ["def", "deepcopy", "(", "self", ",", "keypoints", "=", "None", ",", "shape", "=", "None", ")", ":", "# for some reason deepcopy is way slower here than manual copy", "if", "keypoints", "is", "None", ":", "keypoints", "=", "[", "kp", ".", "deepcopy", "(", ")", "for", "kp", "in", "self", ".", "keypoints", "]", "if", "shape", "is", "None", ":", "shape", "=", "tuple", "(", "self", ".", "shape", ")", "return", "KeypointsOnImage", "(", "keypoints", ",", "shape", ")"], "docstring": "Create a deep copy of the KeypointsOnImage object.\n\n        Parameters\n        ----------\n        keypoints : None or list of imgaug.Keypoint, optional\n            List of keypoints on the image. If ``None``, the instance's\n            keypoints will be copied.\n\n        shape : tuple of int, optional\n            The shape of the image on which the keypoints are placed.\n            If ``None``, the instance's shape will be copied.\n\n        Returns\n        -------\n        imgaug.KeypointsOnImage\n            Deep copy.", "docstring_tokens": ["Create", "a", "deep", "copy", "of", "the", "KeypointsOnImage", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/kps.py#L852-L877", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.project", "original_string": "def project(self, from_shape, to_shape):\n        \"\"\"\n        Project the bounding box onto a differently shaped image.\n\n        E.g. if the bounding box is on its original image at\n        x1=(10 of 100 pixels) and y1=(20 of 100 pixels) and is projected onto\n        a new image with size (width=200, height=200), its new position will\n        be (x1=20, y1=40). (Analogous for x2/y2.)\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int or ndarray\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int or ndarray\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        out : imgaug.BoundingBox\n            BoundingBox object with new coordinates.\n\n        \"\"\"\n        coords_proj = project_coords([(self.x1, self.y1), (self.x2, self.y2)],\n                                     from_shape, to_shape)\n        return self.copy(\n            x1=coords_proj[0][0],\n            y1=coords_proj[0][1],\n            x2=coords_proj[1][0],\n            y2=coords_proj[1][1],\n            label=self.label)", "language": "python", "code": "def project(self, from_shape, to_shape):\n        \"\"\"\n        Project the bounding box onto a differently shaped image.\n\n        E.g. if the bounding box is on its original image at\n        x1=(10 of 100 pixels) and y1=(20 of 100 pixels) and is projected onto\n        a new image with size (width=200, height=200), its new position will\n        be (x1=20, y1=40). (Analogous for x2/y2.)\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int or ndarray\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int or ndarray\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        out : imgaug.BoundingBox\n            BoundingBox object with new coordinates.\n\n        \"\"\"\n        coords_proj = project_coords([(self.x1, self.y1), (self.x2, self.y2)],\n                                     from_shape, to_shape)\n        return self.copy(\n            x1=coords_proj[0][0],\n            y1=coords_proj[0][1],\n            x2=coords_proj[1][0],\n            y2=coords_proj[1][1],\n            label=self.label)", "code_tokens": ["def", "project", "(", "self", ",", "from_shape", ",", "to_shape", ")", ":", "coords_proj", "=", "project_coords", "(", "[", "(", "self", ".", "x1", ",", "self", ".", "y1", ")", ",", "(", "self", ".", "x2", ",", "self", ".", "y2", ")", "]", ",", "from_shape", ",", "to_shape", ")", "return", "self", ".", "copy", "(", "x1", "=", "coords_proj", "[", "0", "]", "[", "0", "]", ",", "y1", "=", "coords_proj", "[", "0", "]", "[", "1", "]", ",", "x2", "=", "coords_proj", "[", "1", "]", "[", "0", "]", ",", "y2", "=", "coords_proj", "[", "1", "]", "[", "1", "]", ",", "label", "=", "self", ".", "label", ")"], "docstring": "Project the bounding box onto a differently shaped image.\n\n        E.g. if the bounding box is on its original image at\n        x1=(10 of 100 pixels) and y1=(20 of 100 pixels) and is projected onto\n        a new image with size (width=200, height=200), its new position will\n        be (x1=20, y1=40). (Analogous for x2/y2.)\n\n        This is intended for cases where the original image is resized.\n        It cannot be used for more complex changes (e.g. padding, cropping).\n\n        Parameters\n        ----------\n        from_shape : tuple of int or ndarray\n            Shape of the original image. (Before resize.)\n\n        to_shape : tuple of int or ndarray\n            Shape of the new image. (After resize.)\n\n        Returns\n        -------\n        out : imgaug.BoundingBox\n            BoundingBox object with new coordinates.", "docstring_tokens": ["Project", "the", "bounding", "box", "onto", "a", "differently", "shaped", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L198-L231", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.extend", "original_string": "def extend(self, all_sides=0, top=0, right=0, bottom=0, left=0):\n        \"\"\"\n        Extend the size of the bounding box along its sides.\n\n        Parameters\n        ----------\n        all_sides : number, optional\n            Value by which to extend the bounding box size along all sides.\n\n        top : number, optional\n            Value by which to extend the bounding box size along its top side.\n\n        right : number, optional\n            Value by which to extend the bounding box size along its right side.\n\n        bottom : number, optional\n            Value by which to extend the bounding box size along its bottom side.\n\n        left : number, optional\n            Value by which to extend the bounding box size along its left side.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Extended bounding box.\n\n        \"\"\"\n        return BoundingBox(\n            x1=self.x1 - all_sides - left,\n            x2=self.x2 + all_sides + right,\n            y1=self.y1 - all_sides - top,\n            y2=self.y2 + all_sides + bottom\n        )", "language": "python", "code": "def extend(self, all_sides=0, top=0, right=0, bottom=0, left=0):\n        \"\"\"\n        Extend the size of the bounding box along its sides.\n\n        Parameters\n        ----------\n        all_sides : number, optional\n            Value by which to extend the bounding box size along all sides.\n\n        top : number, optional\n            Value by which to extend the bounding box size along its top side.\n\n        right : number, optional\n            Value by which to extend the bounding box size along its right side.\n\n        bottom : number, optional\n            Value by which to extend the bounding box size along its bottom side.\n\n        left : number, optional\n            Value by which to extend the bounding box size along its left side.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Extended bounding box.\n\n        \"\"\"\n        return BoundingBox(\n            x1=self.x1 - all_sides - left,\n            x2=self.x2 + all_sides + right,\n            y1=self.y1 - all_sides - top,\n            y2=self.y2 + all_sides + bottom\n        )", "code_tokens": ["def", "extend", "(", "self", ",", "all_sides", "=", "0", ",", "top", "=", "0", ",", "right", "=", "0", ",", "bottom", "=", "0", ",", "left", "=", "0", ")", ":", "return", "BoundingBox", "(", "x1", "=", "self", ".", "x1", "-", "all_sides", "-", "left", ",", "x2", "=", "self", ".", "x2", "+", "all_sides", "+", "right", ",", "y1", "=", "self", ".", "y1", "-", "all_sides", "-", "top", ",", "y2", "=", "self", ".", "y2", "+", "all_sides", "+", "bottom", ")"], "docstring": "Extend the size of the bounding box along its sides.\n\n        Parameters\n        ----------\n        all_sides : number, optional\n            Value by which to extend the bounding box size along all sides.\n\n        top : number, optional\n            Value by which to extend the bounding box size along its top side.\n\n        right : number, optional\n            Value by which to extend the bounding box size along its right side.\n\n        bottom : number, optional\n            Value by which to extend the bounding box size along its bottom side.\n\n        left : number, optional\n            Value by which to extend the bounding box size along its left side.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Extended bounding box.", "docstring_tokens": ["Extend", "the", "size", "of", "the", "bounding", "box", "along", "its", "sides", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L233-L265", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.intersection", "original_string": "def intersection(self, other, default=None):\n        \"\"\"\n        Compute the intersection bounding box of this bounding box and another one.\n\n        Note that in extreme cases, the intersection can be a single point, meaning that the intersection bounding box\n        will exist, but then also has a height and width of zero.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the intersection.\n\n        default : any, optional\n            Default value to return if there is no intersection.\n\n        Returns\n        -------\n        imgaug.BoundingBox or any\n            Intersection bounding box of the two bounding boxes if there is an intersection.\n            If there is no intersection, the default value will be returned, which can by anything.\n\n        \"\"\"\n        x1_i = max(self.x1, other.x1)\n        y1_i = max(self.y1, other.y1)\n        x2_i = min(self.x2, other.x2)\n        y2_i = min(self.y2, other.y2)\n        if x1_i > x2_i or y1_i > y2_i:\n            return default\n        else:\n            return BoundingBox(x1=x1_i, y1=y1_i, x2=x2_i, y2=y2_i)", "language": "python", "code": "def intersection(self, other, default=None):\n        \"\"\"\n        Compute the intersection bounding box of this bounding box and another one.\n\n        Note that in extreme cases, the intersection can be a single point, meaning that the intersection bounding box\n        will exist, but then also has a height and width of zero.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the intersection.\n\n        default : any, optional\n            Default value to return if there is no intersection.\n\n        Returns\n        -------\n        imgaug.BoundingBox or any\n            Intersection bounding box of the two bounding boxes if there is an intersection.\n            If there is no intersection, the default value will be returned, which can by anything.\n\n        \"\"\"\n        x1_i = max(self.x1, other.x1)\n        y1_i = max(self.y1, other.y1)\n        x2_i = min(self.x2, other.x2)\n        y2_i = min(self.y2, other.y2)\n        if x1_i > x2_i or y1_i > y2_i:\n            return default\n        else:\n            return BoundingBox(x1=x1_i, y1=y1_i, x2=x2_i, y2=y2_i)", "code_tokens": ["def", "intersection", "(", "self", ",", "other", ",", "default", "=", "None", ")", ":", "x1_i", "=", "max", "(", "self", ".", "x1", ",", "other", ".", "x1", ")", "y1_i", "=", "max", "(", "self", ".", "y1", ",", "other", ".", "y1", ")", "x2_i", "=", "min", "(", "self", ".", "x2", ",", "other", ".", "x2", ")", "y2_i", "=", "min", "(", "self", ".", "y2", ",", "other", ".", "y2", ")", "if", "x1_i", ">", "x2_i", "or", "y1_i", ">", "y2_i", ":", "return", "default", "else", ":", "return", "BoundingBox", "(", "x1", "=", "x1_i", ",", "y1", "=", "y1_i", ",", "x2", "=", "x2_i", ",", "y2", "=", "y2_i", ")"], "docstring": "Compute the intersection bounding box of this bounding box and another one.\n\n        Note that in extreme cases, the intersection can be a single point, meaning that the intersection bounding box\n        will exist, but then also has a height and width of zero.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the intersection.\n\n        default : any, optional\n            Default value to return if there is no intersection.\n\n        Returns\n        -------\n        imgaug.BoundingBox or any\n            Intersection bounding box of the two bounding boxes if there is an intersection.\n            If there is no intersection, the default value will be returned, which can by anything.", "docstring_tokens": ["Compute", "the", "intersection", "bounding", "box", "of", "this", "bounding", "box", "and", "another", "one", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L267-L296", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.union", "original_string": "def union(self, other):\n        \"\"\"\n        Compute the union bounding box of this bounding box and another one.\n\n        This is equivalent to drawing a bounding box around all corners points of both\n        bounding boxes.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the union.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Union bounding box of the two bounding boxes.\n\n        \"\"\"\n        return BoundingBox(\n            x1=min(self.x1, other.x1),\n            y1=min(self.y1, other.y1),\n            x2=max(self.x2, other.x2),\n            y2=max(self.y2, other.y2),\n        )", "language": "python", "code": "def union(self, other):\n        \"\"\"\n        Compute the union bounding box of this bounding box and another one.\n\n        This is equivalent to drawing a bounding box around all corners points of both\n        bounding boxes.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the union.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Union bounding box of the two bounding boxes.\n\n        \"\"\"\n        return BoundingBox(\n            x1=min(self.x1, other.x1),\n            y1=min(self.y1, other.y1),\n            x2=max(self.x2, other.x2),\n            y2=max(self.y2, other.y2),\n        )", "code_tokens": ["def", "union", "(", "self", ",", "other", ")", ":", "return", "BoundingBox", "(", "x1", "=", "min", "(", "self", ".", "x1", ",", "other", ".", "x1", ")", ",", "y1", "=", "min", "(", "self", ".", "y1", ",", "other", ".", "y1", ")", ",", "x2", "=", "max", "(", "self", ".", "x2", ",", "other", ".", "x2", ")", ",", "y2", "=", "max", "(", "self", ".", "y2", ",", "other", ".", "y2", ")", ",", ")"], "docstring": "Compute the union bounding box of this bounding box and another one.\n\n        This is equivalent to drawing a bounding box around all corners points of both\n        bounding boxes.\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to generate the union.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Union bounding box of the two bounding boxes.", "docstring_tokens": ["Compute", "the", "union", "bounding", "box", "of", "this", "bounding", "box", "and", "another", "one", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L298-L321", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.iou", "original_string": "def iou(self, other):\n        \"\"\"\n        Compute the IoU of this bounding box with another one.\n\n        IoU is the intersection over union, defined as::\n\n            ``area(intersection(A, B)) / area(union(A, B))``\n            ``= area(intersection(A, B)) / (area(A) + area(B) - area(intersection(A, B)))``\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to compare.\n\n        Returns\n        -------\n        float\n            IoU between the two bounding boxes.\n\n        \"\"\"\n        inters = self.intersection(other)\n        if inters is None:\n            return 0.0\n        else:\n            area_union = self.area + other.area - inters.area\n            return inters.area / area_union if area_union > 0 else 0.0", "language": "python", "code": "def iou(self, other):\n        \"\"\"\n        Compute the IoU of this bounding box with another one.\n\n        IoU is the intersection over union, defined as::\n\n            ``area(intersection(A, B)) / area(union(A, B))``\n            ``= area(intersection(A, B)) / (area(A) + area(B) - area(intersection(A, B)))``\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to compare.\n\n        Returns\n        -------\n        float\n            IoU between the two bounding boxes.\n\n        \"\"\"\n        inters = self.intersection(other)\n        if inters is None:\n            return 0.0\n        else:\n            area_union = self.area + other.area - inters.area\n            return inters.area / area_union if area_union > 0 else 0.0", "code_tokens": ["def", "iou", "(", "self", ",", "other", ")", ":", "inters", "=", "self", ".", "intersection", "(", "other", ")", "if", "inters", "is", "None", ":", "return", "0.0", "else", ":", "area_union", "=", "self", ".", "area", "+", "other", ".", "area", "-", "inters", ".", "area", "return", "inters", ".", "area", "/", "area_union", "if", "area_union", ">", "0", "else", "0.0"], "docstring": "Compute the IoU of this bounding box with another one.\n\n        IoU is the intersection over union, defined as::\n\n            ``area(intersection(A, B)) / area(union(A, B))``\n            ``= area(intersection(A, B)) / (area(A) + area(B) - area(intersection(A, B)))``\n\n        Parameters\n        ----------\n        other : imgaug.BoundingBox\n            Other bounding box with which to compare.\n\n        Returns\n        -------\n        float\n            IoU between the two bounding boxes.", "docstring_tokens": ["Compute", "the", "IoU", "of", "this", "bounding", "box", "with", "another", "one", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L323-L348", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.is_fully_within_image", "original_string": "def is_fully_within_image(self, image):\n        \"\"\"\n        Estimate whether the bounding box is fully inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is fully inside the image area. False otherwise.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        height, width = shape[0:2]\n        return self.x1 >= 0 and self.x2 < width and self.y1 >= 0 and self.y2 < height", "language": "python", "code": "def is_fully_within_image(self, image):\n        \"\"\"\n        Estimate whether the bounding box is fully inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is fully inside the image area. False otherwise.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        height, width = shape[0:2]\n        return self.x1 >= 0 and self.x2 < width and self.y1 >= 0 and self.y2 < height", "code_tokens": ["def", "is_fully_within_image", "(", "self", ",", "image", ")", ":", "shape", "=", "normalize_shape", "(", "image", ")", "height", ",", "width", "=", "shape", "[", "0", ":", "2", "]", "return", "self", ".", "x1", ">=", "0", "and", "self", ".", "x2", "<", "width", "and", "self", ".", "y1", ">=", "0", "and", "self", ".", "y2", "<", "height"], "docstring": "Estimate whether the bounding box is fully inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is fully inside the image area. False otherwise.", "docstring_tokens": ["Estimate", "whether", "the", "bounding", "box", "is", "fully", "inside", "the", "image", "area", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L350-L370", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.is_partly_within_image", "original_string": "def is_partly_within_image(self, image):\n        \"\"\"\n        Estimate whether the bounding box is at least partially inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is at least partially inside the image area. False otherwise.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        height, width = shape[0:2]\n        eps = np.finfo(np.float32).eps\n        img_bb = BoundingBox(x1=0, x2=width-eps, y1=0, y2=height-eps)\n        return self.intersection(img_bb) is not None", "language": "python", "code": "def is_partly_within_image(self, image):\n        \"\"\"\n        Estimate whether the bounding box is at least partially inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is at least partially inside the image area. False otherwise.\n\n        \"\"\"\n        shape = normalize_shape(image)\n        height, width = shape[0:2]\n        eps = np.finfo(np.float32).eps\n        img_bb = BoundingBox(x1=0, x2=width-eps, y1=0, y2=height-eps)\n        return self.intersection(img_bb) is not None", "code_tokens": ["def", "is_partly_within_image", "(", "self", ",", "image", ")", ":", "shape", "=", "normalize_shape", "(", "image", ")", "height", ",", "width", "=", "shape", "[", "0", ":", "2", "]", "eps", "=", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", "img_bb", "=", "BoundingBox", "(", "x1", "=", "0", ",", "x2", "=", "width", "-", "eps", ",", "y1", "=", "0", ",", "y2", "=", "height", "-", "eps", ")", "return", "self", ".", "intersection", "(", "img_bb", ")", "is", "not", "None"], "docstring": "Estimate whether the bounding box is at least partially inside the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape\n            and must contain at least two integers.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is at least partially inside the image area. False otherwise.", "docstring_tokens": ["Estimate", "whether", "the", "bounding", "box", "is", "at", "least", "partially", "inside", "the", "image", "area", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L372-L394", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.is_out_of_image", "original_string": "def is_out_of_image(self, image, fully=True, partly=False):\n        \"\"\"\n        Estimate whether the bounding box is partially or fully outside of the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use. If an ndarray, its shape will be used. If a tuple, it is\n            assumed to represent the image shape and must contain at least two integers.\n\n        fully : bool, optional\n            Whether to return True if the bounding box is fully outside fo the image area.\n\n        partly : bool, optional\n            Whether to return True if the bounding box is at least partially outside fo the\n            image area.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is partially/fully outside of the image area, depending\n            on defined parameters. False otherwise.\n\n        \"\"\"\n        if self.is_fully_within_image(image):\n            return False\n        elif self.is_partly_within_image(image):\n            return partly\n        else:\n            return fully", "language": "python", "code": "def is_out_of_image(self, image, fully=True, partly=False):\n        \"\"\"\n        Estimate whether the bounding box is partially or fully outside of the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use. If an ndarray, its shape will be used. If a tuple, it is\n            assumed to represent the image shape and must contain at least two integers.\n\n        fully : bool, optional\n            Whether to return True if the bounding box is fully outside fo the image area.\n\n        partly : bool, optional\n            Whether to return True if the bounding box is at least partially outside fo the\n            image area.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is partially/fully outside of the image area, depending\n            on defined parameters. False otherwise.\n\n        \"\"\"\n        if self.is_fully_within_image(image):\n            return False\n        elif self.is_partly_within_image(image):\n            return partly\n        else:\n            return fully", "code_tokens": ["def", "is_out_of_image", "(", "self", ",", "image", ",", "fully", "=", "True", ",", "partly", "=", "False", ")", ":", "if", "self", ".", "is_fully_within_image", "(", "image", ")", ":", "return", "False", "elif", "self", ".", "is_partly_within_image", "(", "image", ")", ":", "return", "partly", "else", ":", "return", "fully"], "docstring": "Estimate whether the bounding box is partially or fully outside of the image area.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use. If an ndarray, its shape will be used. If a tuple, it is\n            assumed to represent the image shape and must contain at least two integers.\n\n        fully : bool, optional\n            Whether to return True if the bounding box is fully outside fo the image area.\n\n        partly : bool, optional\n            Whether to return True if the bounding box is at least partially outside fo the\n            image area.\n\n        Returns\n        -------\n        bool\n            True if the bounding box is partially/fully outside of the image area, depending\n            on defined parameters. False otherwise.", "docstring_tokens": ["Estimate", "whether", "the", "bounding", "box", "is", "partially", "or", "fully", "outside", "of", "the", "image", "area", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L396-L425", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.clip_out_of_image", "original_string": "def clip_out_of_image(self, image):\n        \"\"\"\n        Clip off all parts of the bounding box that are outside of the image.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use for the clipping of the bounding box.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape and must contain at least two integers.\n\n        Returns\n        -------\n        result : imgaug.BoundingBox\n            Bounding box, clipped to fall within the image dimensions.\n\n        \"\"\"\n        shape = normalize_shape(image)\n\n        height, width = shape[0:2]\n        ia.do_assert(height > 0)\n        ia.do_assert(width > 0)\n\n        eps = np.finfo(np.float32).eps\n        x1 = np.clip(self.x1, 0, width - eps)\n        x2 = np.clip(self.x2, 0, width - eps)\n        y1 = np.clip(self.y1, 0, height - eps)\n        y2 = np.clip(self.y2, 0, height - eps)\n\n        return self.copy(\n            x1=x1,\n            y1=y1,\n            x2=x2,\n            y2=y2,\n            label=self.label\n        )", "language": "python", "code": "def clip_out_of_image(self, image):\n        \"\"\"\n        Clip off all parts of the bounding box that are outside of the image.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use for the clipping of the bounding box.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape and must contain at least two integers.\n\n        Returns\n        -------\n        result : imgaug.BoundingBox\n            Bounding box, clipped to fall within the image dimensions.\n\n        \"\"\"\n        shape = normalize_shape(image)\n\n        height, width = shape[0:2]\n        ia.do_assert(height > 0)\n        ia.do_assert(width > 0)\n\n        eps = np.finfo(np.float32).eps\n        x1 = np.clip(self.x1, 0, width - eps)\n        x2 = np.clip(self.x2, 0, width - eps)\n        y1 = np.clip(self.y1, 0, height - eps)\n        y2 = np.clip(self.y2, 0, height - eps)\n\n        return self.copy(\n            x1=x1,\n            y1=y1,\n            x2=x2,\n            y2=y2,\n            label=self.label\n        )", "code_tokens": ["def", "clip_out_of_image", "(", "self", ",", "image", ")", ":", "shape", "=", "normalize_shape", "(", "image", ")", "height", ",", "width", "=", "shape", "[", "0", ":", "2", "]", "ia", ".", "do_assert", "(", "height", ">", "0", ")", "ia", ".", "do_assert", "(", "width", ">", "0", ")", "eps", "=", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", "x1", "=", "np", ".", "clip", "(", "self", ".", "x1", ",", "0", ",", "width", "-", "eps", ")", "x2", "=", "np", ".", "clip", "(", "self", ".", "x2", ",", "0", ",", "width", "-", "eps", ")", "y1", "=", "np", ".", "clip", "(", "self", ".", "y1", ",", "0", ",", "height", "-", "eps", ")", "y2", "=", "np", ".", "clip", "(", "self", ".", "y2", ",", "0", ",", "height", "-", "eps", ")", "return", "self", ".", "copy", "(", "x1", "=", "x1", ",", "y1", "=", "y1", ",", "x2", "=", "x2", ",", "y2", "=", "y2", ",", "label", "=", "self", ".", "label", ")"], "docstring": "Clip off all parts of the bounding box that are outside of the image.\n\n        Parameters\n        ----------\n        image : (H,W,...) ndarray or tuple of int\n            Image dimensions to use for the clipping of the bounding box.\n            If an ndarray, its shape will be used.\n            If a tuple, it is assumed to represent the image shape and must contain at least two integers.\n\n        Returns\n        -------\n        result : imgaug.BoundingBox\n            Bounding box, clipped to fall within the image dimensions.", "docstring_tokens": ["Clip", "off", "all", "parts", "of", "the", "bounding", "box", "that", "are", "outside", "of", "the", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L433-L468", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.draw_on_image", "original_string": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=1,\n                      copy=True, raise_if_out_of_image=False, thickness=None):\n        \"\"\"\n        Draw the bounding box on an image.\n\n        Parameters\n        ----------\n        image : (H,W,C) ndarray(uint8)\n            The image onto which to draw the bounding box.\n\n        color : iterable of int, optional\n            The color to use, corresponding to the channel layout of the image. Usually RGB.\n\n        alpha : float, optional\n            The transparency of the drawn bounding box, where 1.0 denotes no transparency and\n            0.0 is invisible.\n\n        size : int, optional\n            The thickness of the bounding box in pixels. If the value is larger than 1, then\n            additional pixels will be added around the bounding box (i.e. extension towards the\n            outside).\n\n        copy : bool, optional\n            Whether to copy the input image or change it in-place.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an error if the bounding box is fully outside of the\n            image. If set to False, no error will be raised and only the parts inside the image\n            will be drawn.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        result : (H,W,C) ndarray(uint8)\n            Image with bounding box drawn on it.\n\n        \"\"\"\n        if thickness is not None:\n            ia.warn_deprecated(\n                \"Usage of argument 'thickness' in BoundingBox.draw_on_image() \"\n                \"is deprecated. The argument was renamed to 'size'.\"\n            )\n            size = thickness\n\n        if raise_if_out_of_image and self.is_out_of_image(image):\n            raise Exception(\"Cannot draw bounding box x1=%.8f, y1=%.8f, x2=%.8f, y2=%.8f on image with shape %s.\" % (\n                self.x1, self.y1, self.x2, self.y2, image.shape))\n\n        result = np.copy(image) if copy else image\n\n        if isinstance(color, (tuple, list)):\n            color = np.uint8(color)\n\n        for i in range(size):\n            y1, y2, x1, x2 = self.y1_int, self.y2_int, self.x1_int, self.x2_int\n\n            # When y values get into the range (H-0.5, H), the *_int functions round them to H.\n            # That is technically sensible, but in the case of drawing means that the border lies\n            # just barely outside of the image, making the border disappear, even though the BB\n            # is fully inside the image. Here we correct for that because of beauty reasons.\n            # Same is the case for x coordinates.\n            if self.is_fully_within_image(image):\n                y1 = np.clip(y1, 0, image.shape[0]-1)\n                y2 = np.clip(y2, 0, image.shape[0]-1)\n                x1 = np.clip(x1, 0, image.shape[1]-1)\n                x2 = np.clip(x2, 0, image.shape[1]-1)\n\n            y = [y1-i, y1-i, y2+i, y2+i]\n            x = [x1-i, x2+i, x2+i, x1-i]\n            rr, cc = skimage.draw.polygon_perimeter(y, x, shape=result.shape)\n            if alpha >= 0.99:\n                result[rr, cc, :] = color\n            else:\n                if ia.is_float_array(result):\n                    result[rr, cc, :] = (1 - alpha) * result[rr, cc, :] + alpha * color\n                    result = np.clip(result, 0, 255)\n                else:\n                    input_dtype = result.dtype\n                    result = result.astype(np.float32)\n                    result[rr, cc, :] = (1 - alpha) * result[rr, cc, :] + alpha * color\n                    result = np.clip(result, 0, 255).astype(input_dtype)\n\n        return result", "language": "python", "code": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=1,\n                      copy=True, raise_if_out_of_image=False, thickness=None):\n        \"\"\"\n        Draw the bounding box on an image.\n\n        Parameters\n        ----------\n        image : (H,W,C) ndarray(uint8)\n            The image onto which to draw the bounding box.\n\n        color : iterable of int, optional\n            The color to use, corresponding to the channel layout of the image. Usually RGB.\n\n        alpha : float, optional\n            The transparency of the drawn bounding box, where 1.0 denotes no transparency and\n            0.0 is invisible.\n\n        size : int, optional\n            The thickness of the bounding box in pixels. If the value is larger than 1, then\n            additional pixels will be added around the bounding box (i.e. extension towards the\n            outside).\n\n        copy : bool, optional\n            Whether to copy the input image or change it in-place.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an error if the bounding box is fully outside of the\n            image. If set to False, no error will be raised and only the parts inside the image\n            will be drawn.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        result : (H,W,C) ndarray(uint8)\n            Image with bounding box drawn on it.\n\n        \"\"\"\n        if thickness is not None:\n            ia.warn_deprecated(\n                \"Usage of argument 'thickness' in BoundingBox.draw_on_image() \"\n                \"is deprecated. The argument was renamed to 'size'.\"\n            )\n            size = thickness\n\n        if raise_if_out_of_image and self.is_out_of_image(image):\n            raise Exception(\"Cannot draw bounding box x1=%.8f, y1=%.8f, x2=%.8f, y2=%.8f on image with shape %s.\" % (\n                self.x1, self.y1, self.x2, self.y2, image.shape))\n\n        result = np.copy(image) if copy else image\n\n        if isinstance(color, (tuple, list)):\n            color = np.uint8(color)\n\n        for i in range(size):\n            y1, y2, x1, x2 = self.y1_int, self.y2_int, self.x1_int, self.x2_int\n\n            # When y values get into the range (H-0.5, H), the *_int functions round them to H.\n            # That is technically sensible, but in the case of drawing means that the border lies\n            # just barely outside of the image, making the border disappear, even though the BB\n            # is fully inside the image. Here we correct for that because of beauty reasons.\n            # Same is the case for x coordinates.\n            if self.is_fully_within_image(image):\n                y1 = np.clip(y1, 0, image.shape[0]-1)\n                y2 = np.clip(y2, 0, image.shape[0]-1)\n                x1 = np.clip(x1, 0, image.shape[1]-1)\n                x2 = np.clip(x2, 0, image.shape[1]-1)\n\n            y = [y1-i, y1-i, y2+i, y2+i]\n            x = [x1-i, x2+i, x2+i, x1-i]\n            rr, cc = skimage.draw.polygon_perimeter(y, x, shape=result.shape)\n            if alpha >= 0.99:\n                result[rr, cc, :] = color\n            else:\n                if ia.is_float_array(result):\n                    result[rr, cc, :] = (1 - alpha) * result[rr, cc, :] + alpha * color\n                    result = np.clip(result, 0, 255)\n                else:\n                    input_dtype = result.dtype\n                    result = result.astype(np.float32)\n                    result[rr, cc, :] = (1 - alpha) * result[rr, cc, :] + alpha * color\n                    result = np.clip(result, 0, 255).astype(input_dtype)\n\n        return result", "code_tokens": ["def", "draw_on_image", "(", "self", ",", "image", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "alpha", "=", "1.0", ",", "size", "=", "1", ",", "copy", "=", "True", ",", "raise_if_out_of_image", "=", "False", ",", "thickness", "=", "None", ")", ":", "if", "thickness", "is", "not", "None", ":", "ia", ".", "warn_deprecated", "(", "\"Usage of argument 'thickness' in BoundingBox.draw_on_image() \"", "\"is deprecated. The argument was renamed to 'size'.\"", ")", "size", "=", "thickness", "if", "raise_if_out_of_image", "and", "self", ".", "is_out_of_image", "(", "image", ")", ":", "raise", "Exception", "(", "\"Cannot draw bounding box x1=%.8f, y1=%.8f, x2=%.8f, y2=%.8f on image with shape %s.\"", "%", "(", "self", ".", "x1", ",", "self", ".", "y1", ",", "self", ".", "x2", ",", "self", ".", "y2", ",", "image", ".", "shape", ")", ")", "result", "=", "np", ".", "copy", "(", "image", ")", "if", "copy", "else", "image", "if", "isinstance", "(", "color", ",", "(", "tuple", ",", "list", ")", ")", ":", "color", "=", "np", ".", "uint8", "(", "color", ")", "for", "i", "in", "range", "(", "size", ")", ":", "y1", ",", "y2", ",", "x1", ",", "x2", "=", "self", ".", "y1_int", ",", "self", ".", "y2_int", ",", "self", ".", "x1_int", ",", "self", ".", "x2_int", "# When y values get into the range (H-0.5, H), the *_int functions round them to H.", "# That is technically sensible, but in the case of drawing means that the border lies", "# just barely outside of the image, making the border disappear, even though the BB", "# is fully inside the image. Here we correct for that because of beauty reasons.", "# Same is the case for x coordinates.", "if", "self", ".", "is_fully_within_image", "(", "image", ")", ":", "y1", "=", "np", ".", "clip", "(", "y1", ",", "0", ",", "image", ".", "shape", "[", "0", "]", "-", "1", ")", "y2", "=", "np", ".", "clip", "(", "y2", ",", "0", ",", "image", ".", "shape", "[", "0", "]", "-", "1", ")", "x1", "=", "np", ".", "clip", "(", "x1", ",", "0", ",", "image", ".", "shape", "[", "1", "]", "-", "1", ")", "x2", "=", "np", ".", "clip", "(", "x2", ",", "0", ",", "image", ".", "shape", "[", "1", "]", "-", "1", ")", "y", "=", "[", "y1", "-", "i", ",", "y1", "-", "i", ",", "y2", "+", "i", ",", "y2", "+", "i", "]", "x", "=", "[", "x1", "-", "i", ",", "x2", "+", "i", ",", "x2", "+", "i", ",", "x1", "-", "i", "]", "rr", ",", "cc", "=", "skimage", ".", "draw", ".", "polygon_perimeter", "(", "y", ",", "x", ",", "shape", "=", "result", ".", "shape", ")", "if", "alpha", ">=", "0.99", ":", "result", "[", "rr", ",", "cc", ",", ":", "]", "=", "color", "else", ":", "if", "ia", ".", "is_float_array", "(", "result", ")", ":", "result", "[", "rr", ",", "cc", ",", ":", "]", "=", "(", "1", "-", "alpha", ")", "*", "result", "[", "rr", ",", "cc", ",", ":", "]", "+", "alpha", "*", "color", "result", "=", "np", ".", "clip", "(", "result", ",", "0", ",", "255", ")", "else", ":", "input_dtype", "=", "result", ".", "dtype", "result", "=", "result", ".", "astype", "(", "np", ".", "float32", ")", "result", "[", "rr", ",", "cc", ",", ":", "]", "=", "(", "1", "-", "alpha", ")", "*", "result", "[", "rr", ",", "cc", ",", ":", "]", "+", "alpha", "*", "color", "result", "=", "np", ".", "clip", "(", "result", ",", "0", ",", "255", ")", ".", "astype", "(", "input_dtype", ")", "return", "result"], "docstring": "Draw the bounding box on an image.\n\n        Parameters\n        ----------\n        image : (H,W,C) ndarray(uint8)\n            The image onto which to draw the bounding box.\n\n        color : iterable of int, optional\n            The color to use, corresponding to the channel layout of the image. Usually RGB.\n\n        alpha : float, optional\n            The transparency of the drawn bounding box, where 1.0 denotes no transparency and\n            0.0 is invisible.\n\n        size : int, optional\n            The thickness of the bounding box in pixels. If the value is larger than 1, then\n            additional pixels will be added around the bounding box (i.e. extension towards the\n            outside).\n\n        copy : bool, optional\n            Whether to copy the input image or change it in-place.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an error if the bounding box is fully outside of the\n            image. If set to False, no error will be raised and only the parts inside the image\n            will be drawn.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        result : (H,W,C) ndarray(uint8)\n            Image with bounding box drawn on it.", "docstring_tokens": ["Draw", "the", "bounding", "box", "on", "an", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L507-L591", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.extract_from_image", "original_string": "def extract_from_image(self, image, pad=True, pad_max=None,\n                           prevent_zero_size=True):\n        \"\"\"\n        Extract the image pixels within the bounding box.\n\n        This function will zero-pad the image if the bounding box is partially/fully outside of\n        the image.\n\n        Parameters\n        ----------\n        image : (H,W) ndarray or (H,W,C) ndarray\n            The image from which to extract the pixels within the bounding box.\n\n        pad : bool, optional\n            Whether to zero-pad the image if the object is partially/fully\n            outside of it.\n\n        pad_max : None or int, optional\n            The maximum number of pixels that may be zero-paded on any side,\n            i.e. if this has value ``N`` the total maximum of added pixels\n            is ``4*N``.\n            This option exists to prevent extremely large images as a result of\n            single points being moved very far away during augmentation.\n\n        prevent_zero_size : bool, optional\n            Whether to prevent height or width of the extracted image from becoming zero.\n            If this is set to True and height or width of the bounding box is below 1, the height/width will\n            be increased to 1. This can be useful to prevent problems, e.g. with image saving or plotting.\n            If it is set to False, images will be returned as ``(H', W')`` or ``(H', W', 3)`` with ``H`` or\n            ``W`` potentially being 0.\n\n        Returns\n        -------\n        image : (H',W') ndarray or (H',W',C) ndarray\n            Pixels within the bounding box. Zero-padded if the bounding box is partially/fully\n            outside of the image. If prevent_zero_size is activated, it is guarantueed that ``H'>0``\n            and ``W'>0``, otherwise only ``H'>=0`` and ``W'>=0``.\n\n        \"\"\"\n        pad_top = 0\n        pad_right = 0\n        pad_bottom = 0\n        pad_left = 0\n\n        height, width = image.shape[0], image.shape[1]\n        x1, x2, y1, y2 = self.x1_int, self.x2_int, self.y1_int, self.y2_int\n\n        # When y values get into the range (H-0.5, H), the *_int functions round them to H.\n        # That is technically sensible, but in the case of extraction leads to a black border,\n        # which is both ugly and unexpected after calling cut_out_of_image(). Here we correct for\n        # that because of beauty reasons.\n        # Same is the case for x coordinates.\n        fully_within = self.is_fully_within_image(image)\n        if fully_within:\n            y1, y2 = np.clip([y1, y2], 0, height-1)\n            x1, x2 = np.clip([x1, x2], 0, width-1)\n\n        # TODO add test\n        if prevent_zero_size:\n            if abs(x2 - x1) < 1:\n                x2 = x1 + 1\n            if abs(y2 - y1) < 1:\n                y2 = y1 + 1\n\n        if pad:\n            # if the bb is outside of the image area, the following pads the image\n            # first with black pixels until the bb is inside the image\n            # and only then extracts the image area\n            # TODO probably more efficient to initialize an array of zeros\n            # and copy only the portions of the bb into that array that are\n            # natively inside the image area\n            if x1 < 0:\n                pad_left = abs(x1)\n                x2 = x2 + pad_left\n                width = width + pad_left\n                x1 = 0\n            if y1 < 0:\n                pad_top = abs(y1)\n                y2 = y2 + pad_top\n                height = height + pad_top\n                y1 = 0\n            if x2 >= width:\n                pad_right = x2 - width\n            if y2 >= height:\n                pad_bottom = y2 - height\n\n            paddings = [pad_top, pad_right, pad_bottom, pad_left]\n            any_padded = any([val > 0 for val in paddings])\n            if any_padded:\n                if pad_max is None:\n                    pad_max = max(paddings)\n\n                image = ia.pad(\n                    image,\n                    top=min(pad_top, pad_max),\n                    right=min(pad_right, pad_max),\n                    bottom=min(pad_bottom, pad_max),\n                    left=min(pad_left, pad_max)\n                )\n            return image[y1:y2, x1:x2]\n        else:\n            within_image = (\n                (0, 0, 0, 0)\n                <= (x1, y1, x2, y2)\n                < (width, height, width, height)\n            )\n            out_height, out_width = (y2 - y1), (x2 - x1)\n            nonzero_height = (out_height > 0)\n            nonzero_width = (out_width > 0)\n            if within_image and nonzero_height and nonzero_width:\n                return image[y1:y2, x1:x2]\n            if prevent_zero_size:\n                out_height = 1\n                out_width = 1\n            else:\n                out_height = 0\n                out_width = 0\n            if image.ndim == 2:\n                return np.zeros((out_height, out_width), dtype=image.dtype)\n            return np.zeros((out_height, out_width, image.shape[-1]),\n                            dtype=image.dtype)", "language": "python", "code": "def extract_from_image(self, image, pad=True, pad_max=None,\n                           prevent_zero_size=True):\n        \"\"\"\n        Extract the image pixels within the bounding box.\n\n        This function will zero-pad the image if the bounding box is partially/fully outside of\n        the image.\n\n        Parameters\n        ----------\n        image : (H,W) ndarray or (H,W,C) ndarray\n            The image from which to extract the pixels within the bounding box.\n\n        pad : bool, optional\n            Whether to zero-pad the image if the object is partially/fully\n            outside of it.\n\n        pad_max : None or int, optional\n            The maximum number of pixels that may be zero-paded on any side,\n            i.e. if this has value ``N`` the total maximum of added pixels\n            is ``4*N``.\n            This option exists to prevent extremely large images as a result of\n            single points being moved very far away during augmentation.\n\n        prevent_zero_size : bool, optional\n            Whether to prevent height or width of the extracted image from becoming zero.\n            If this is set to True and height or width of the bounding box is below 1, the height/width will\n            be increased to 1. This can be useful to prevent problems, e.g. with image saving or plotting.\n            If it is set to False, images will be returned as ``(H', W')`` or ``(H', W', 3)`` with ``H`` or\n            ``W`` potentially being 0.\n\n        Returns\n        -------\n        image : (H',W') ndarray or (H',W',C) ndarray\n            Pixels within the bounding box. Zero-padded if the bounding box is partially/fully\n            outside of the image. If prevent_zero_size is activated, it is guarantueed that ``H'>0``\n            and ``W'>0``, otherwise only ``H'>=0`` and ``W'>=0``.\n\n        \"\"\"\n        pad_top = 0\n        pad_right = 0\n        pad_bottom = 0\n        pad_left = 0\n\n        height, width = image.shape[0], image.shape[1]\n        x1, x2, y1, y2 = self.x1_int, self.x2_int, self.y1_int, self.y2_int\n\n        # When y values get into the range (H-0.5, H), the *_int functions round them to H.\n        # That is technically sensible, but in the case of extraction leads to a black border,\n        # which is both ugly and unexpected after calling cut_out_of_image(). Here we correct for\n        # that because of beauty reasons.\n        # Same is the case for x coordinates.\n        fully_within = self.is_fully_within_image(image)\n        if fully_within:\n            y1, y2 = np.clip([y1, y2], 0, height-1)\n            x1, x2 = np.clip([x1, x2], 0, width-1)\n\n        # TODO add test\n        if prevent_zero_size:\n            if abs(x2 - x1) < 1:\n                x2 = x1 + 1\n            if abs(y2 - y1) < 1:\n                y2 = y1 + 1\n\n        if pad:\n            # if the bb is outside of the image area, the following pads the image\n            # first with black pixels until the bb is inside the image\n            # and only then extracts the image area\n            # TODO probably more efficient to initialize an array of zeros\n            # and copy only the portions of the bb into that array that are\n            # natively inside the image area\n            if x1 < 0:\n                pad_left = abs(x1)\n                x2 = x2 + pad_left\n                width = width + pad_left\n                x1 = 0\n            if y1 < 0:\n                pad_top = abs(y1)\n                y2 = y2 + pad_top\n                height = height + pad_top\n                y1 = 0\n            if x2 >= width:\n                pad_right = x2 - width\n            if y2 >= height:\n                pad_bottom = y2 - height\n\n            paddings = [pad_top, pad_right, pad_bottom, pad_left]\n            any_padded = any([val > 0 for val in paddings])\n            if any_padded:\n                if pad_max is None:\n                    pad_max = max(paddings)\n\n                image = ia.pad(\n                    image,\n                    top=min(pad_top, pad_max),\n                    right=min(pad_right, pad_max),\n                    bottom=min(pad_bottom, pad_max),\n                    left=min(pad_left, pad_max)\n                )\n            return image[y1:y2, x1:x2]\n        else:\n            within_image = (\n                (0, 0, 0, 0)\n                <= (x1, y1, x2, y2)\n                < (width, height, width, height)\n            )\n            out_height, out_width = (y2 - y1), (x2 - x1)\n            nonzero_height = (out_height > 0)\n            nonzero_width = (out_width > 0)\n            if within_image and nonzero_height and nonzero_width:\n                return image[y1:y2, x1:x2]\n            if prevent_zero_size:\n                out_height = 1\n                out_width = 1\n            else:\n                out_height = 0\n                out_width = 0\n            if image.ndim == 2:\n                return np.zeros((out_height, out_width), dtype=image.dtype)\n            return np.zeros((out_height, out_width, image.shape[-1]),\n                            dtype=image.dtype)", "code_tokens": ["def", "extract_from_image", "(", "self", ",", "image", ",", "pad", "=", "True", ",", "pad_max", "=", "None", ",", "prevent_zero_size", "=", "True", ")", ":", "pad_top", "=", "0", "pad_right", "=", "0", "pad_bottom", "=", "0", "pad_left", "=", "0", "height", ",", "width", "=", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", "x1", ",", "x2", ",", "y1", ",", "y2", "=", "self", ".", "x1_int", ",", "self", ".", "x2_int", ",", "self", ".", "y1_int", ",", "self", ".", "y2_int", "# When y values get into the range (H-0.5, H), the *_int functions round them to H.", "# That is technically sensible, but in the case of extraction leads to a black border,", "# which is both ugly and unexpected after calling cut_out_of_image(). Here we correct for", "# that because of beauty reasons.", "# Same is the case for x coordinates.", "fully_within", "=", "self", ".", "is_fully_within_image", "(", "image", ")", "if", "fully_within", ":", "y1", ",", "y2", "=", "np", ".", "clip", "(", "[", "y1", ",", "y2", "]", ",", "0", ",", "height", "-", "1", ")", "x1", ",", "x2", "=", "np", ".", "clip", "(", "[", "x1", ",", "x2", "]", ",", "0", ",", "width", "-", "1", ")", "# TODO add test", "if", "prevent_zero_size", ":", "if", "abs", "(", "x2", "-", "x1", ")", "<", "1", ":", "x2", "=", "x1", "+", "1", "if", "abs", "(", "y2", "-", "y1", ")", "<", "1", ":", "y2", "=", "y1", "+", "1", "if", "pad", ":", "# if the bb is outside of the image area, the following pads the image", "# first with black pixels until the bb is inside the image", "# and only then extracts the image area", "# TODO probably more efficient to initialize an array of zeros", "# and copy only the portions of the bb into that array that are", "# natively inside the image area", "if", "x1", "<", "0", ":", "pad_left", "=", "abs", "(", "x1", ")", "x2", "=", "x2", "+", "pad_left", "width", "=", "width", "+", "pad_left", "x1", "=", "0", "if", "y1", "<", "0", ":", "pad_top", "=", "abs", "(", "y1", ")", "y2", "=", "y2", "+", "pad_top", "height", "=", "height", "+", "pad_top", "y1", "=", "0", "if", "x2", ">=", "width", ":", "pad_right", "=", "x2", "-", "width", "if", "y2", ">=", "height", ":", "pad_bottom", "=", "y2", "-", "height", "paddings", "=", "[", "pad_top", ",", "pad_right", ",", "pad_bottom", ",", "pad_left", "]", "any_padded", "=", "any", "(", "[", "val", ">", "0", "for", "val", "in", "paddings", "]", ")", "if", "any_padded", ":", "if", "pad_max", "is", "None", ":", "pad_max", "=", "max", "(", "paddings", ")", "image", "=", "ia", ".", "pad", "(", "image", ",", "top", "=", "min", "(", "pad_top", ",", "pad_max", ")", ",", "right", "=", "min", "(", "pad_right", ",", "pad_max", ")", ",", "bottom", "=", "min", "(", "pad_bottom", ",", "pad_max", ")", ",", "left", "=", "min", "(", "pad_left", ",", "pad_max", ")", ")", "return", "image", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "else", ":", "within_image", "=", "(", "(", "0", ",", "0", ",", "0", ",", "0", ")", "<=", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", "<", "(", "width", ",", "height", ",", "width", ",", "height", ")", ")", "out_height", ",", "out_width", "=", "(", "y2", "-", "y1", ")", ",", "(", "x2", "-", "x1", ")", "nonzero_height", "=", "(", "out_height", ">", "0", ")", "nonzero_width", "=", "(", "out_width", ">", "0", ")", "if", "within_image", "and", "nonzero_height", "and", "nonzero_width", ":", "return", "image", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "if", "prevent_zero_size", ":", "out_height", "=", "1", "out_width", "=", "1", "else", ":", "out_height", "=", "0", "out_width", "=", "0", "if", "image", ".", "ndim", "==", "2", ":", "return", "np", ".", "zeros", "(", "(", "out_height", ",", "out_width", ")", ",", "dtype", "=", "image", ".", "dtype", ")", "return", "np", ".", "zeros", "(", "(", "out_height", ",", "out_width", ",", "image", ".", "shape", "[", "-", "1", "]", ")", ",", "dtype", "=", "image", ".", "dtype", ")"], "docstring": "Extract the image pixels within the bounding box.\n\n        This function will zero-pad the image if the bounding box is partially/fully outside of\n        the image.\n\n        Parameters\n        ----------\n        image : (H,W) ndarray or (H,W,C) ndarray\n            The image from which to extract the pixels within the bounding box.\n\n        pad : bool, optional\n            Whether to zero-pad the image if the object is partially/fully\n            outside of it.\n\n        pad_max : None or int, optional\n            The maximum number of pixels that may be zero-paded on any side,\n            i.e. if this has value ``N`` the total maximum of added pixels\n            is ``4*N``.\n            This option exists to prevent extremely large images as a result of\n            single points being moved very far away during augmentation.\n\n        prevent_zero_size : bool, optional\n            Whether to prevent height or width of the extracted image from becoming zero.\n            If this is set to True and height or width of the bounding box is below 1, the height/width will\n            be increased to 1. This can be useful to prevent problems, e.g. with image saving or plotting.\n            If it is set to False, images will be returned as ``(H', W')`` or ``(H', W', 3)`` with ``H`` or\n            ``W`` potentially being 0.\n\n        Returns\n        -------\n        image : (H',W') ndarray or (H',W',C) ndarray\n            Pixels within the bounding box. Zero-padded if the bounding box is partially/fully\n            outside of the image. If prevent_zero_size is activated, it is guarantueed that ``H'>0``\n            and ``W'>0``, otherwise only ``H'>=0`` and ``W'>=0``.", "docstring_tokens": ["Extract", "the", "image", "pixels", "within", "the", "bounding", "box", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L594-L714", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBox.copy", "original_string": "def copy(self, x1=None, y1=None, x2=None, y2=None, label=None):\n        \"\"\"\n        Create a shallow copy of the BoundingBox object.\n\n        Parameters\n        ----------\n        x1 : None or number\n            If not None, then the x1 coordinate of the copied object will be set to this value.\n\n        y1 : None or number\n            If not None, then the y1 coordinate of the copied object will be set to this value.\n\n        x2 : None or number\n            If not None, then the x2 coordinate of the copied object will be set to this value.\n\n        y2 : None or number\n            If not None, then the y2 coordinate of the copied object will be set to this value.\n\n        label : None or string\n            If not None, then the label of the copied object will be set to this value.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Shallow copy.\n\n        \"\"\"\n        return BoundingBox(\n            x1=self.x1 if x1 is None else x1,\n            x2=self.x2 if x2 is None else x2,\n            y1=self.y1 if y1 is None else y1,\n            y2=self.y2 if y2 is None else y2,\n            label=self.label if label is None else label\n        )", "language": "python", "code": "def copy(self, x1=None, y1=None, x2=None, y2=None, label=None):\n        \"\"\"\n        Create a shallow copy of the BoundingBox object.\n\n        Parameters\n        ----------\n        x1 : None or number\n            If not None, then the x1 coordinate of the copied object will be set to this value.\n\n        y1 : None or number\n            If not None, then the y1 coordinate of the copied object will be set to this value.\n\n        x2 : None or number\n            If not None, then the x2 coordinate of the copied object will be set to this value.\n\n        y2 : None or number\n            If not None, then the y2 coordinate of the copied object will be set to this value.\n\n        label : None or string\n            If not None, then the label of the copied object will be set to this value.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Shallow copy.\n\n        \"\"\"\n        return BoundingBox(\n            x1=self.x1 if x1 is None else x1,\n            x2=self.x2 if x2 is None else x2,\n            y1=self.y1 if y1 is None else y1,\n            y2=self.y2 if y2 is None else y2,\n            label=self.label if label is None else label\n        )", "code_tokens": ["def", "copy", "(", "self", ",", "x1", "=", "None", ",", "y1", "=", "None", ",", "x2", "=", "None", ",", "y2", "=", "None", ",", "label", "=", "None", ")", ":", "return", "BoundingBox", "(", "x1", "=", "self", ".", "x1", "if", "x1", "is", "None", "else", "x1", ",", "x2", "=", "self", ".", "x2", "if", "x2", "is", "None", "else", "x2", ",", "y1", "=", "self", ".", "y1", "if", "y1", "is", "None", "else", "y1", ",", "y2", "=", "self", ".", "y2", "if", "y2", "is", "None", "else", "y2", ",", "label", "=", "self", ".", "label", "if", "label", "is", "None", "else", "label", ")"], "docstring": "Create a shallow copy of the BoundingBox object.\n\n        Parameters\n        ----------\n        x1 : None or number\n            If not None, then the x1 coordinate of the copied object will be set to this value.\n\n        y1 : None or number\n            If not None, then the y1 coordinate of the copied object will be set to this value.\n\n        x2 : None or number\n            If not None, then the x2 coordinate of the copied object will be set to this value.\n\n        y2 : None or number\n            If not None, then the y2 coordinate of the copied object will be set to this value.\n\n        label : None or string\n            If not None, then the label of the copied object will be set to this value.\n\n        Returns\n        -------\n        imgaug.BoundingBox\n            Shallow copy.", "docstring_tokens": ["Create", "a", "shallow", "copy", "of", "the", "BoundingBox", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L738-L771", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBoxesOnImage.draw_on_image", "original_string": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=1,\n                      copy=True, raise_if_out_of_image=False, thickness=None):\n        \"\"\"\n        Draw all bounding boxes onto a given image.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the bounding boxes.\n            This image should usually have the same shape as\n            set in BoundingBoxesOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all bounding boxes. If a single int ``C``, then\n            that is equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            Alpha/transparency of the bounding box.\n\n        size : int, optional\n            Thickness in pixels.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the bounding boxes.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any bounding box is outside of the\n            image.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn bounding boxes.\n\n        \"\"\"\n        image = np.copy(image) if copy else image\n\n        for bb in self.bounding_boxes:\n            image = bb.draw_on_image(\n                image,\n                color=color,\n                alpha=alpha,\n                size=size,\n                copy=False,\n                raise_if_out_of_image=raise_if_out_of_image,\n                thickness=thickness\n            )\n\n        return image", "language": "python", "code": "def draw_on_image(self, image, color=(0, 255, 0), alpha=1.0, size=1,\n                      copy=True, raise_if_out_of_image=False, thickness=None):\n        \"\"\"\n        Draw all bounding boxes onto a given image.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the bounding boxes.\n            This image should usually have the same shape as\n            set in BoundingBoxesOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all bounding boxes. If a single int ``C``, then\n            that is equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            Alpha/transparency of the bounding box.\n\n        size : int, optional\n            Thickness in pixels.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the bounding boxes.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any bounding box is outside of the\n            image.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn bounding boxes.\n\n        \"\"\"\n        image = np.copy(image) if copy else image\n\n        for bb in self.bounding_boxes:\n            image = bb.draw_on_image(\n                image,\n                color=color,\n                alpha=alpha,\n                size=size,\n                copy=False,\n                raise_if_out_of_image=raise_if_out_of_image,\n                thickness=thickness\n            )\n\n        return image", "code_tokens": ["def", "draw_on_image", "(", "self", ",", "image", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "alpha", "=", "1.0", ",", "size", "=", "1", ",", "copy", "=", "True", ",", "raise_if_out_of_image", "=", "False", ",", "thickness", "=", "None", ")", ":", "image", "=", "np", ".", "copy", "(", "image", ")", "if", "copy", "else", "image", "for", "bb", "in", "self", ".", "bounding_boxes", ":", "image", "=", "bb", ".", "draw_on_image", "(", "image", ",", "color", "=", "color", ",", "alpha", "=", "alpha", ",", "size", "=", "size", ",", "copy", "=", "False", ",", "raise_if_out_of_image", "=", "raise_if_out_of_image", ",", "thickness", "=", "thickness", ")", "return", "image"], "docstring": "Draw all bounding boxes onto a given image.\n\n        Parameters\n        ----------\n        image : (H,W,3) ndarray\n            The image onto which to draw the bounding boxes.\n            This image should usually have the same shape as\n            set in BoundingBoxesOnImage.shape.\n\n        color : int or list of int or tuple of int or (3,) ndarray, optional\n            The RGB color of all bounding boxes. If a single int ``C``, then\n            that is equivalent to ``(C,C,C)``.\n\n        alpha : float, optional\n            Alpha/transparency of the bounding box.\n\n        size : int, optional\n            Thickness in pixels.\n\n        copy : bool, optional\n            Whether to copy the image before drawing the bounding boxes.\n\n        raise_if_out_of_image : bool, optional\n            Whether to raise an exception if any bounding box is outside of the\n            image.\n\n        thickness : None or int, optional\n            Deprecated.\n\n        Returns\n        -------\n        image : (H,W,3) ndarray\n            Image with drawn bounding boxes.", "docstring_tokens": ["Draw", "all", "bounding", "boxes", "onto", "a", "given", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L954-L1005", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBoxesOnImage.remove_out_of_image", "original_string": "def remove_out_of_image(self, fully=True, partly=False):\n        \"\"\"\n        Remove all bounding boxes that are fully or partially outside of the image.\n\n        Parameters\n        ----------\n        fully : bool, optional\n            Whether to remove bounding boxes that are fully outside of the image.\n\n        partly : bool, optional\n            Whether to remove bounding boxes that are partially outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Reduced set of bounding boxes, with those that were fully/partially outside of\n            the image removed.\n\n        \"\"\"\n        bbs_clean = [bb for bb in self.bounding_boxes\n                     if not bb.is_out_of_image(self.shape, fully=fully, partly=partly)]\n        return BoundingBoxesOnImage(bbs_clean, shape=self.shape)", "language": "python", "code": "def remove_out_of_image(self, fully=True, partly=False):\n        \"\"\"\n        Remove all bounding boxes that are fully or partially outside of the image.\n\n        Parameters\n        ----------\n        fully : bool, optional\n            Whether to remove bounding boxes that are fully outside of the image.\n\n        partly : bool, optional\n            Whether to remove bounding boxes that are partially outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Reduced set of bounding boxes, with those that were fully/partially outside of\n            the image removed.\n\n        \"\"\"\n        bbs_clean = [bb for bb in self.bounding_boxes\n                     if not bb.is_out_of_image(self.shape, fully=fully, partly=partly)]\n        return BoundingBoxesOnImage(bbs_clean, shape=self.shape)", "code_tokens": ["def", "remove_out_of_image", "(", "self", ",", "fully", "=", "True", ",", "partly", "=", "False", ")", ":", "bbs_clean", "=", "[", "bb", "for", "bb", "in", "self", ".", "bounding_boxes", "if", "not", "bb", ".", "is_out_of_image", "(", "self", ".", "shape", ",", "fully", "=", "fully", ",", "partly", "=", "partly", ")", "]", "return", "BoundingBoxesOnImage", "(", "bbs_clean", ",", "shape", "=", "self", ".", "shape", ")"], "docstring": "Remove all bounding boxes that are fully or partially outside of the image.\n\n        Parameters\n        ----------\n        fully : bool, optional\n            Whether to remove bounding boxes that are fully outside of the image.\n\n        partly : bool, optional\n            Whether to remove bounding boxes that are partially outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Reduced set of bounding boxes, with those that were fully/partially outside of\n            the image removed.", "docstring_tokens": ["Remove", "all", "bounding", "boxes", "that", "are", "fully", "or", "partially", "outside", "of", "the", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L1007-L1028", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBoxesOnImage.clip_out_of_image", "original_string": "def clip_out_of_image(self):\n        \"\"\"\n        Clip off all parts from all bounding boxes that are outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Bounding boxes, clipped to fall within the image dimensions.\n\n        \"\"\"\n        bbs_cut = [bb.clip_out_of_image(self.shape)\n                   for bb in self.bounding_boxes if bb.is_partly_within_image(self.shape)]\n        return BoundingBoxesOnImage(bbs_cut, shape=self.shape)", "language": "python", "code": "def clip_out_of_image(self):\n        \"\"\"\n        Clip off all parts from all bounding boxes that are outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Bounding boxes, clipped to fall within the image dimensions.\n\n        \"\"\"\n        bbs_cut = [bb.clip_out_of_image(self.shape)\n                   for bb in self.bounding_boxes if bb.is_partly_within_image(self.shape)]\n        return BoundingBoxesOnImage(bbs_cut, shape=self.shape)", "code_tokens": ["def", "clip_out_of_image", "(", "self", ")", ":", "bbs_cut", "=", "[", "bb", ".", "clip_out_of_image", "(", "self", ".", "shape", ")", "for", "bb", "in", "self", ".", "bounding_boxes", "if", "bb", ".", "is_partly_within_image", "(", "self", ".", "shape", ")", "]", "return", "BoundingBoxesOnImage", "(", "bbs_cut", ",", "shape", "=", "self", ".", "shape", ")"], "docstring": "Clip off all parts from all bounding boxes that are outside of the image.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Bounding boxes, clipped to fall within the image dimensions.", "docstring_tokens": ["Clip", "off", "all", "parts", "from", "all", "bounding", "boxes", "that", "are", "outside", "of", "the", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L1036-L1048", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/bbs.py", "func_name": "BoundingBoxesOnImage.deepcopy", "original_string": "def deepcopy(self):\n        \"\"\"\n        Create a deep copy of the BoundingBoxesOnImage object.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Deep copy.\n\n        \"\"\"\n        # Manual copy is far faster than deepcopy for BoundingBoxesOnImage,\n        # so use manual copy here too\n        bbs = [bb.deepcopy() for bb in self.bounding_boxes]\n        return BoundingBoxesOnImage(bbs, tuple(self.shape))", "language": "python", "code": "def deepcopy(self):\n        \"\"\"\n        Create a deep copy of the BoundingBoxesOnImage object.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Deep copy.\n\n        \"\"\"\n        # Manual copy is far faster than deepcopy for BoundingBoxesOnImage,\n        # so use manual copy here too\n        bbs = [bb.deepcopy() for bb in self.bounding_boxes]\n        return BoundingBoxesOnImage(bbs, tuple(self.shape))", "code_tokens": ["def", "deepcopy", "(", "self", ")", ":", "# Manual copy is far faster than deepcopy for BoundingBoxesOnImage,", "# so use manual copy here too", "bbs", "=", "[", "bb", ".", "deepcopy", "(", ")", "for", "bb", "in", "self", ".", "bounding_boxes", "]", "return", "BoundingBoxesOnImage", "(", "bbs", ",", "tuple", "(", "self", ".", "shape", ")", ")"], "docstring": "Create a deep copy of the BoundingBoxesOnImage object.\n\n        Returns\n        -------\n        imgaug.BoundingBoxesOnImage\n            Deep copy.", "docstring_tokens": ["Create", "a", "deep", "copy", "of", "the", "BoundingBoxesOnImage", "object", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/bbs.py#L1089-L1102", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/convolutional.py", "func_name": "Emboss", "original_string": "def Emboss(alpha=0, strength=1, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that embosses images and overlays the result with the original\n    image.\n\n    The embossed version pronounces highlights and shadows,\n    letting the image look as if it was recreated on a metal plate (\"embossed\").\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    strength : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Parameter that controls the strength of the embossing.\n        Sane values are somewhere in the range ``(0, 2)`` with 1 being the standard\n        embossing effect. Default value is 1.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = Emboss(alpha=(0.0, 1.0), strength=(0.5, 1.5))\n\n    embosses an image with a variable strength in the range ``0.5 <= x <= 1.5``\n    and overlays the result with a variable alpha in the range ``0.0 <= a <= 1.0``\n    over the old image.\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n    strength_param = iap.handle_continuous_param(strength, \"strength\", value_range=(0, None), tuple_to_uniform=True,\n                                                 list_to_choice=True)\n\n    def create_matrices(image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        strength_sample = strength_param.draw_sample(random_state=random_state_func)\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        matrix_effect = np.array([\n            [-1-strength_sample, 0-strength_sample, 0],\n            [0-strength_sample, 1, 0+strength_sample],\n            [0, 0+strength_sample, 1+strength_sample]\n        ], dtype=np.float32)\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "language": "python", "code": "def Emboss(alpha=0, strength=1, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that embosses images and overlays the result with the original\n    image.\n\n    The embossed version pronounces highlights and shadows,\n    letting the image look as if it was recreated on a metal plate (\"embossed\").\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    strength : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Parameter that controls the strength of the embossing.\n        Sane values are somewhere in the range ``(0, 2)`` with 1 being the standard\n        embossing effect. Default value is 1.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = Emboss(alpha=(0.0, 1.0), strength=(0.5, 1.5))\n\n    embosses an image with a variable strength in the range ``0.5 <= x <= 1.5``\n    and overlays the result with a variable alpha in the range ``0.0 <= a <= 1.0``\n    over the old image.\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n    strength_param = iap.handle_continuous_param(strength, \"strength\", value_range=(0, None), tuple_to_uniform=True,\n                                                 list_to_choice=True)\n\n    def create_matrices(image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        strength_sample = strength_param.draw_sample(random_state=random_state_func)\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        matrix_effect = np.array([\n            [-1-strength_sample, 0-strength_sample, 0],\n            [0-strength_sample, 1, 0+strength_sample],\n            [0, 0+strength_sample, 1+strength_sample]\n        ], dtype=np.float32)\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "code_tokens": ["def", "Emboss", "(", "alpha", "=", "0", ",", "strength", "=", "1", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "alpha_param", "=", "iap", ".", "handle_continuous_param", "(", "alpha", ",", "\"alpha\"", ",", "value_range", "=", "(", "0", ",", "1.0", ")", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "strength_param", "=", "iap", ".", "handle_continuous_param", "(", "strength", ",", "\"strength\"", ",", "value_range", "=", "(", "0", ",", "None", ")", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "def", "create_matrices", "(", "image", ",", "nb_channels", ",", "random_state_func", ")", ":", "alpha_sample", "=", "alpha_param", ".", "draw_sample", "(", "random_state", "=", "random_state_func", ")", "ia", ".", "do_assert", "(", "0", "<=", "alpha_sample", "<=", "1.0", ")", "strength_sample", "=", "strength_param", ".", "draw_sample", "(", "random_state", "=", "random_state_func", ")", "matrix_nochange", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "matrix_effect", "=", "np", ".", "array", "(", "[", "[", "-", "1", "-", "strength_sample", ",", "0", "-", "strength_sample", ",", "0", "]", ",", "[", "0", "-", "strength_sample", ",", "1", ",", "0", "+", "strength_sample", "]", ",", "[", "0", ",", "0", "+", "strength_sample", ",", "1", "+", "strength_sample", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "matrix", "=", "(", "1", "-", "alpha_sample", ")", "*", "matrix_nochange", "+", "alpha_sample", "*", "matrix_effect", "return", "[", "matrix", "]", "*", "nb_channels", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "Convolve", "(", "create_matrices", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that embosses images and overlays the result with the original\n    image.\n\n    The embossed version pronounces highlights and shadows,\n    letting the image look as if it was recreated on a metal plate (\"embossed\").\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    strength : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Parameter that controls the strength of the embossing.\n        Sane values are somewhere in the range ``(0, 2)`` with 1 being the standard\n        embossing effect. Default value is 1.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = Emboss(alpha=(0.0, 1.0), strength=(0.5, 1.5))\n\n    embosses an image with a variable strength in the range ``0.5 <= x <= 1.5``\n    and overlays the result with a variable alpha in the range ``0.0 <= a <= 1.0``\n    over the old image.", "docstring_tokens": ["Augmenter", "that", "embosses", "images", "and", "overlays", "the", "result", "with", "the", "original", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/convolutional.py#L296-L378", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/convolutional.py", "func_name": "EdgeDetect", "original_string": "def EdgeDetect(alpha=0, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that detects all edges in images, marks them in\n    a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = EdgeDetect(alpha=(0.0, 1.0))\n\n    detects edges in an image  and overlays the result with a variable alpha\n    in the range ``0.0 <= a <= 1.0`` over the old image.\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n\n    def create_matrices(_image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        matrix_effect = np.array([\n            [0, 1, 0],\n            [1, -4, 1],\n            [0, 1, 0]\n        ], dtype=np.float32)\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "language": "python", "code": "def EdgeDetect(alpha=0, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that detects all edges in images, marks them in\n    a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = EdgeDetect(alpha=(0.0, 1.0))\n\n    detects edges in an image  and overlays the result with a variable alpha\n    in the range ``0.0 <= a <= 1.0`` over the old image.\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n\n    def create_matrices(_image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        matrix_effect = np.array([\n            [0, 1, 0],\n            [1, -4, 1],\n            [0, 1, 0]\n        ], dtype=np.float32)\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "code_tokens": ["def", "EdgeDetect", "(", "alpha", "=", "0", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "alpha_param", "=", "iap", ".", "handle_continuous_param", "(", "alpha", ",", "\"alpha\"", ",", "value_range", "=", "(", "0", ",", "1.0", ")", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "def", "create_matrices", "(", "_image", ",", "nb_channels", ",", "random_state_func", ")", ":", "alpha_sample", "=", "alpha_param", ".", "draw_sample", "(", "random_state", "=", "random_state_func", ")", "ia", ".", "do_assert", "(", "0", "<=", "alpha_sample", "<=", "1.0", ")", "matrix_nochange", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "matrix_effect", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "0", "]", ",", "[", "1", ",", "-", "4", ",", "1", "]", ",", "[", "0", ",", "1", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "matrix", "=", "(", "1", "-", "alpha_sample", ")", "*", "matrix_nochange", "+", "alpha_sample", "*", "matrix_effect", "return", "[", "matrix", "]", "*", "nb_channels", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "Convolve", "(", "create_matrices", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that detects all edges in images, marks them in\n    a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = EdgeDetect(alpha=(0.0, 1.0))\n\n    detects edges in an image  and overlays the result with a variable alpha\n    in the range ``0.0 <= a <= 1.0`` over the old image.", "docstring_tokens": ["Augmenter", "that", "detects", "all", "edges", "in", "images", "marks", "them", "in", "a", "black", "and", "white", "image", "and", "then", "overlays", "the", "result", "with", "the", "original", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/convolutional.py#L382-L445", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/convolutional.py", "func_name": "DirectedEdgeDetect", "original_string": "def DirectedEdgeDetect(alpha=0, direction=(0.0, 1.0), name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that detects edges that have certain directions and marks them\n    in a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    direction : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Angle of edges to pronounce, where 0 represents 0 degrees and 1.0\n        represents 360 degrees (both clockwise, starting at the top).\n        Default value is ``(0.0, 1.0)``, i.e. pick a random angle per image.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=0)\n\n    turns input images into edge images in which edges are detected from\n    top side of the image (i.e. the top sides of horizontal edges are\n    added to the output).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=90/360)\n\n    same as before, but detecting edges from the right (right side of each\n    vertical edge).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=(0.0, 1.0))\n\n    same as before, but detecting edges from a variable direction (anything\n    between 0 and 1.0, i.e. 0 degrees and 360 degrees, starting from the\n    top and moving clockwise).\n\n    >>> aug = DirectedEdgeDetect(alpha=(0.0, 0.3), direction=0)\n\n    generates edge images (edges detected from the top) and overlays them\n    with the input images by a variable amount between 0 and 30 percent\n    (e.g. for 0.3 then ``0.7*old_image + 0.3*edge_image``).\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n    direction_param = iap.handle_continuous_param(direction, \"direction\", value_range=None, tuple_to_uniform=True,\n                                                  list_to_choice=True)\n\n    def create_matrices(_image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        direction_sample = direction_param.draw_sample(random_state=random_state_func)\n\n        deg = int(direction_sample * 360) % 360\n        rad = np.deg2rad(deg)\n        x = np.cos(rad - 0.5*np.pi)\n        y = np.sin(rad - 0.5*np.pi)\n        direction_vector = np.array([x, y])\n\n        matrix_effect = np.array([\n            [0, 0, 0],\n            [0, 0, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        for x in [-1, 0, 1]:\n            for y in [-1, 0, 1]:\n                if (x, y) != (0, 0):\n                    cell_vector = np.array([x, y])\n                    distance_deg = np.rad2deg(ia.angle_between_vectors(cell_vector, direction_vector))\n                    distance = distance_deg / 180\n                    similarity = (1 - distance)**4\n                    matrix_effect[y+1, x+1] = similarity\n        matrix_effect = matrix_effect / np.sum(matrix_effect)\n        matrix_effect = matrix_effect * (-1)\n        matrix_effect[1, 1] = 1\n\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "language": "python", "code": "def DirectedEdgeDetect(alpha=0, direction=(0.0, 1.0), name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that detects edges that have certain directions and marks them\n    in a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    direction : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Angle of edges to pronounce, where 0 represents 0 degrees and 1.0\n        represents 360 degrees (both clockwise, starting at the top).\n        Default value is ``(0.0, 1.0)``, i.e. pick a random angle per image.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=0)\n\n    turns input images into edge images in which edges are detected from\n    top side of the image (i.e. the top sides of horizontal edges are\n    added to the output).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=90/360)\n\n    same as before, but detecting edges from the right (right side of each\n    vertical edge).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=(0.0, 1.0))\n\n    same as before, but detecting edges from a variable direction (anything\n    between 0 and 1.0, i.e. 0 degrees and 360 degrees, starting from the\n    top and moving clockwise).\n\n    >>> aug = DirectedEdgeDetect(alpha=(0.0, 0.3), direction=0)\n\n    generates edge images (edges detected from the top) and overlays them\n    with the input images by a variable amount between 0 and 30 percent\n    (e.g. for 0.3 then ``0.7*old_image + 0.3*edge_image``).\n\n    \"\"\"\n    alpha_param = iap.handle_continuous_param(alpha, \"alpha\", value_range=(0, 1.0), tuple_to_uniform=True,\n                                              list_to_choice=True)\n    direction_param = iap.handle_continuous_param(direction, \"direction\", value_range=None, tuple_to_uniform=True,\n                                                  list_to_choice=True)\n\n    def create_matrices(_image, nb_channels, random_state_func):\n        alpha_sample = alpha_param.draw_sample(random_state=random_state_func)\n        ia.do_assert(0 <= alpha_sample <= 1.0)\n        direction_sample = direction_param.draw_sample(random_state=random_state_func)\n\n        deg = int(direction_sample * 360) % 360\n        rad = np.deg2rad(deg)\n        x = np.cos(rad - 0.5*np.pi)\n        y = np.sin(rad - 0.5*np.pi)\n        direction_vector = np.array([x, y])\n\n        matrix_effect = np.array([\n            [0, 0, 0],\n            [0, 0, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n        for x in [-1, 0, 1]:\n            for y in [-1, 0, 1]:\n                if (x, y) != (0, 0):\n                    cell_vector = np.array([x, y])\n                    distance_deg = np.rad2deg(ia.angle_between_vectors(cell_vector, direction_vector))\n                    distance = distance_deg / 180\n                    similarity = (1 - distance)**4\n                    matrix_effect[y+1, x+1] = similarity\n        matrix_effect = matrix_effect / np.sum(matrix_effect)\n        matrix_effect = matrix_effect * (-1)\n        matrix_effect[1, 1] = 1\n\n        matrix_nochange = np.array([\n            [0, 0, 0],\n            [0, 1, 0],\n            [0, 0, 0]\n        ], dtype=np.float32)\n\n        matrix = (1-alpha_sample) * matrix_nochange + alpha_sample * matrix_effect\n\n        return [matrix] * nb_channels\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return Convolve(create_matrices, name=name, deterministic=deterministic, random_state=random_state)", "code_tokens": ["def", "DirectedEdgeDetect", "(", "alpha", "=", "0", ",", "direction", "=", "(", "0.0", ",", "1.0", ")", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "alpha_param", "=", "iap", ".", "handle_continuous_param", "(", "alpha", ",", "\"alpha\"", ",", "value_range", "=", "(", "0", ",", "1.0", ")", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "direction_param", "=", "iap", ".", "handle_continuous_param", "(", "direction", ",", "\"direction\"", ",", "value_range", "=", "None", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "def", "create_matrices", "(", "_image", ",", "nb_channels", ",", "random_state_func", ")", ":", "alpha_sample", "=", "alpha_param", ".", "draw_sample", "(", "random_state", "=", "random_state_func", ")", "ia", ".", "do_assert", "(", "0", "<=", "alpha_sample", "<=", "1.0", ")", "direction_sample", "=", "direction_param", ".", "draw_sample", "(", "random_state", "=", "random_state_func", ")", "deg", "=", "int", "(", "direction_sample", "*", "360", ")", "%", "360", "rad", "=", "np", ".", "deg2rad", "(", "deg", ")", "x", "=", "np", ".", "cos", "(", "rad", "-", "0.5", "*", "np", ".", "pi", ")", "y", "=", "np", ".", "sin", "(", "rad", "-", "0.5", "*", "np", ".", "pi", ")", "direction_vector", "=", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", "matrix_effect", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "for", "x", "in", "[", "-", "1", ",", "0", ",", "1", "]", ":", "for", "y", "in", "[", "-", "1", ",", "0", ",", "1", "]", ":", "if", "(", "x", ",", "y", ")", "!=", "(", "0", ",", "0", ")", ":", "cell_vector", "=", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", "distance_deg", "=", "np", ".", "rad2deg", "(", "ia", ".", "angle_between_vectors", "(", "cell_vector", ",", "direction_vector", ")", ")", "distance", "=", "distance_deg", "/", "180", "similarity", "=", "(", "1", "-", "distance", ")", "**", "4", "matrix_effect", "[", "y", "+", "1", ",", "x", "+", "1", "]", "=", "similarity", "matrix_effect", "=", "matrix_effect", "/", "np", ".", "sum", "(", "matrix_effect", ")", "matrix_effect", "=", "matrix_effect", "*", "(", "-", "1", ")", "matrix_effect", "[", "1", ",", "1", "]", "=", "1", "matrix_nochange", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "matrix", "=", "(", "1", "-", "alpha_sample", ")", "*", "matrix_nochange", "+", "alpha_sample", "*", "matrix_effect", "return", "[", "matrix", "]", "*", "nb_channels", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "Convolve", "(", "create_matrices", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that detects edges that have certain directions and marks them\n    in a black and white image and then overlays the result with the original\n    image.\n\n    dtype support::\n\n        See ``imgaug.augmenters.convolutional.Convolve``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Visibility of the sharpened image. At 0, only the original image is\n        visible, at 1.0 only its sharpened version is visible.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    direction : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Angle of edges to pronounce, where 0 represents 0 degrees and 1.0\n        represents 360 degrees (both clockwise, starting at the top).\n        Default value is ``(0.0, 1.0)``, i.e. pick a random angle per image.\n\n            * If an int or float, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=0)\n\n    turns input images into edge images in which edges are detected from\n    top side of the image (i.e. the top sides of horizontal edges are\n    added to the output).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=90/360)\n\n    same as before, but detecting edges from the right (right side of each\n    vertical edge).\n\n    >>> aug = DirectedEdgeDetect(alpha=1.0, direction=(0.0, 1.0))\n\n    same as before, but detecting edges from a variable direction (anything\n    between 0 and 1.0, i.e. 0 degrees and 360 degrees, starting from the\n    top and moving clockwise).\n\n    >>> aug = DirectedEdgeDetect(alpha=(0.0, 0.3), direction=0)\n\n    generates edge images (edges detected from the top) and overlays them\n    with the input images by a variable amount between 0 and 30 percent\n    (e.g. for 0.3 then ``0.7*old_image + 0.3*edge_image``).", "docstring_tokens": ["Augmenter", "that", "detects", "edges", "that", "have", "certain", "directions", "and", "marks", "them", "in", "a", "black", "and", "white", "image", "and", "then", "overlays", "the", "result", "with", "the", "original", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/convolutional.py#L450-L568", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/utils.py", "func_name": "normalize_shape", "original_string": "def normalize_shape(shape):\n    \"\"\"\n    Normalize a shape tuple or array to a shape tuple.\n\n    Parameters\n    ----------\n    shape : tuple of int or ndarray\n        The input to normalize. May optionally be an array.\n\n    Returns\n    -------\n    tuple of int\n        Shape tuple.\n\n    \"\"\"\n    if isinstance(shape, tuple):\n        return shape\n    assert ia.is_np_array(shape), (\n        \"Expected tuple of ints or array, got %s.\" % (type(shape),))\n    return shape.shape", "language": "python", "code": "def normalize_shape(shape):\n    \"\"\"\n    Normalize a shape tuple or array to a shape tuple.\n\n    Parameters\n    ----------\n    shape : tuple of int or ndarray\n        The input to normalize. May optionally be an array.\n\n    Returns\n    -------\n    tuple of int\n        Shape tuple.\n\n    \"\"\"\n    if isinstance(shape, tuple):\n        return shape\n    assert ia.is_np_array(shape), (\n        \"Expected tuple of ints or array, got %s.\" % (type(shape),))\n    return shape.shape", "code_tokens": ["def", "normalize_shape", "(", "shape", ")", ":", "if", "isinstance", "(", "shape", ",", "tuple", ")", ":", "return", "shape", "assert", "ia", ".", "is_np_array", "(", "shape", ")", ",", "(", "\"Expected tuple of ints or array, got %s.\"", "%", "(", "type", "(", "shape", ")", ",", ")", ")", "return", "shape", ".", "shape"], "docstring": "Normalize a shape tuple or array to a shape tuple.\n\n    Parameters\n    ----------\n    shape : tuple of int or ndarray\n        The input to normalize. May optionally be an array.\n\n    Returns\n    -------\n    tuple of int\n        Shape tuple.", "docstring_tokens": ["Normalize", "a", "shape", "tuple", "or", "array", "to", "a", "shape", "tuple", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/utils.py#L8-L27", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmentables/utils.py", "func_name": "project_coords", "original_string": "def project_coords(coords, from_shape, to_shape):\n    \"\"\"\n    Project coordinates from one image shape to another.\n\n    This performs a relative projection, e.g. a point at 60% of the old\n    image width will be at 60% of the new image width after projection.\n\n    Parameters\n    ----------\n    coords : ndarray or tuple of number\n        Coordinates to project. Either a ``(N,2)`` numpy array or a tuple\n        of `(x,y)` coordinates.\n\n    from_shape : tuple of int or ndarray\n        Old image shape.\n\n    to_shape : tuple of int or ndarray\n        New image shape.\n\n    Returns\n    -------\n    ndarray\n        Projected coordinates as ``(N,2)`` ``float32`` numpy array.\n\n    \"\"\"\n    from_shape = normalize_shape(from_shape)\n    to_shape = normalize_shape(to_shape)\n    if from_shape[0:2] == to_shape[0:2]:\n        return coords\n\n    from_height, from_width = from_shape[0:2]\n    to_height, to_width = to_shape[0:2]\n    assert all([v > 0 for v in [from_height, from_width, to_height, to_width]])\n\n    # make sure to not just call np.float32(coords) here as the following lines\n    # perform in-place changes and np.float32(.) only copies if the input\n    # was *not* a float32 array\n    coords_proj = np.array(coords).astype(np.float32)\n    coords_proj[:, 0] = (coords_proj[:, 0] / from_width) * to_width\n    coords_proj[:, 1] = (coords_proj[:, 1] / from_height) * to_height\n    return coords_proj", "language": "python", "code": "def project_coords(coords, from_shape, to_shape):\n    \"\"\"\n    Project coordinates from one image shape to another.\n\n    This performs a relative projection, e.g. a point at 60% of the old\n    image width will be at 60% of the new image width after projection.\n\n    Parameters\n    ----------\n    coords : ndarray or tuple of number\n        Coordinates to project. Either a ``(N,2)`` numpy array or a tuple\n        of `(x,y)` coordinates.\n\n    from_shape : tuple of int or ndarray\n        Old image shape.\n\n    to_shape : tuple of int or ndarray\n        New image shape.\n\n    Returns\n    -------\n    ndarray\n        Projected coordinates as ``(N,2)`` ``float32`` numpy array.\n\n    \"\"\"\n    from_shape = normalize_shape(from_shape)\n    to_shape = normalize_shape(to_shape)\n    if from_shape[0:2] == to_shape[0:2]:\n        return coords\n\n    from_height, from_width = from_shape[0:2]\n    to_height, to_width = to_shape[0:2]\n    assert all([v > 0 for v in [from_height, from_width, to_height, to_width]])\n\n    # make sure to not just call np.float32(coords) here as the following lines\n    # perform in-place changes and np.float32(.) only copies if the input\n    # was *not* a float32 array\n    coords_proj = np.array(coords).astype(np.float32)\n    coords_proj[:, 0] = (coords_proj[:, 0] / from_width) * to_width\n    coords_proj[:, 1] = (coords_proj[:, 1] / from_height) * to_height\n    return coords_proj", "code_tokens": ["def", "project_coords", "(", "coords", ",", "from_shape", ",", "to_shape", ")", ":", "from_shape", "=", "normalize_shape", "(", "from_shape", ")", "to_shape", "=", "normalize_shape", "(", "to_shape", ")", "if", "from_shape", "[", "0", ":", "2", "]", "==", "to_shape", "[", "0", ":", "2", "]", ":", "return", "coords", "from_height", ",", "from_width", "=", "from_shape", "[", "0", ":", "2", "]", "to_height", ",", "to_width", "=", "to_shape", "[", "0", ":", "2", "]", "assert", "all", "(", "[", "v", ">", "0", "for", "v", "in", "[", "from_height", ",", "from_width", ",", "to_height", ",", "to_width", "]", "]", ")", "# make sure to not just call np.float32(coords) here as the following lines", "# perform in-place changes and np.float32(.) only copies if the input", "# was *not* a float32 array", "coords_proj", "=", "np", ".", "array", "(", "coords", ")", ".", "astype", "(", "np", ".", "float32", ")", "coords_proj", "[", ":", ",", "0", "]", "=", "(", "coords_proj", "[", ":", ",", "0", "]", "/", "from_width", ")", "*", "to_width", "coords_proj", "[", ":", ",", "1", "]", "=", "(", "coords_proj", "[", ":", ",", "1", "]", "/", "from_height", ")", "*", "to_height", "return", "coords_proj"], "docstring": "Project coordinates from one image shape to another.\n\n    This performs a relative projection, e.g. a point at 60% of the old\n    image width will be at 60% of the new image width after projection.\n\n    Parameters\n    ----------\n    coords : ndarray or tuple of number\n        Coordinates to project. Either a ``(N,2)`` numpy array or a tuple\n        of `(x,y)` coordinates.\n\n    from_shape : tuple of int or ndarray\n        Old image shape.\n\n    to_shape : tuple of int or ndarray\n        New image shape.\n\n    Returns\n    -------\n    ndarray\n        Projected coordinates as ``(N,2)`` ``float32`` numpy array.", "docstring_tokens": ["Project", "coordinates", "from", "one", "image", "shape", "to", "another", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmentables/utils.py#L31-L71", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "AdditivePoissonNoise", "original_string": "def AdditivePoissonNoise(lam=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Create an augmenter to add poisson noise to images.\n\n    Poisson noise is comparable to gaussian noise as in ``AdditiveGaussianNoise``, but the values are sampled from\n    a poisson distribution instead of a gaussian distribution. As poisson distributions produce only positive numbers,\n    the sign of the sampled values are here randomly flipped.\n\n    Values of around ``10.0`` for `lam` lead to visible noise (for uint8).\n    Values of around ``20.0`` for `lam` lead to very visible noise (for uint8).\n    It is recommended to usually set `per_channel` to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.AddElementwise``.\n\n    Parameters\n    ----------\n    lam : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Lambda parameter of the poisson distribution. Recommended values are around ``0.0`` to ``10.0``.\n\n            * If a number, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same noise value per pixel for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0))\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images, where ``x`` is randomly sampled per image from the\n    interval ``[0.0, 10.0]``.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0, per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images,\n    where the values are different per pixel *and* channel (e.g. a\n    different one for red, green and blue channels for the same pixel).\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0), per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images,\n    with ``x`` being sampled from ``uniform(0.0, 10.0)`` per image, pixel and channel.\n    This is the *recommended* configuration.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=2, per_channel=0.5)\n\n    Adds poisson noise sampled from the distribution ``Poisson(2)`` to images,\n    where the values are sometimes (50 percent of all cases) the same\n    per pixel for all channels and sometimes different (other 50 percent).\n\n    \"\"\"\n    lam2 = iap.handle_continuous_param(lam, \"lam\", value_range=(0, None), tuple_to_uniform=True,\n                                       list_to_choice=True)\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return AddElementwise(iap.RandomSign(iap.Poisson(lam=lam2)), per_channel=per_channel, name=name,\n                          deterministic=deterministic, random_state=random_state)", "language": "python", "code": "def AdditivePoissonNoise(lam=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Create an augmenter to add poisson noise to images.\n\n    Poisson noise is comparable to gaussian noise as in ``AdditiveGaussianNoise``, but the values are sampled from\n    a poisson distribution instead of a gaussian distribution. As poisson distributions produce only positive numbers,\n    the sign of the sampled values are here randomly flipped.\n\n    Values of around ``10.0`` for `lam` lead to visible noise (for uint8).\n    Values of around ``20.0`` for `lam` lead to very visible noise (for uint8).\n    It is recommended to usually set `per_channel` to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.AddElementwise``.\n\n    Parameters\n    ----------\n    lam : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Lambda parameter of the poisson distribution. Recommended values are around ``0.0`` to ``10.0``.\n\n            * If a number, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same noise value per pixel for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0))\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images, where ``x`` is randomly sampled per image from the\n    interval ``[0.0, 10.0]``.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0, per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images,\n    where the values are different per pixel *and* channel (e.g. a\n    different one for red, green and blue channels for the same pixel).\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0), per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images,\n    with ``x`` being sampled from ``uniform(0.0, 10.0)`` per image, pixel and channel.\n    This is the *recommended* configuration.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=2, per_channel=0.5)\n\n    Adds poisson noise sampled from the distribution ``Poisson(2)`` to images,\n    where the values are sometimes (50 percent of all cases) the same\n    per pixel for all channels and sometimes different (other 50 percent).\n\n    \"\"\"\n    lam2 = iap.handle_continuous_param(lam, \"lam\", value_range=(0, None), tuple_to_uniform=True,\n                                       list_to_choice=True)\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return AddElementwise(iap.RandomSign(iap.Poisson(lam=lam2)), per_channel=per_channel, name=name,\n                          deterministic=deterministic, random_state=random_state)", "code_tokens": ["def", "AdditivePoissonNoise", "(", "lam", "=", "0", ",", "per_channel", "=", "False", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "lam2", "=", "iap", ".", "handle_continuous_param", "(", "lam", ",", "\"lam\"", ",", "value_range", "=", "(", "0", ",", "None", ")", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "AddElementwise", "(", "iap", ".", "RandomSign", "(", "iap", ".", "Poisson", "(", "lam", "=", "lam2", ")", ")", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Create an augmenter to add poisson noise to images.\n\n    Poisson noise is comparable to gaussian noise as in ``AdditiveGaussianNoise``, but the values are sampled from\n    a poisson distribution instead of a gaussian distribution. As poisson distributions produce only positive numbers,\n    the sign of the sampled values are here randomly flipped.\n\n    Values of around ``10.0`` for `lam` lead to visible noise (for uint8).\n    Values of around ``20.0`` for `lam` lead to very visible noise (for uint8).\n    It is recommended to usually set `per_channel` to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.AddElementwise``.\n\n    Parameters\n    ----------\n    lam : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Lambda parameter of the poisson distribution. Recommended values are around ``0.0`` to ``10.0``.\n\n            * If a number, exactly that value will be used.\n            * If a tuple ``(a, b)``, a random value from the range ``a <= x <= b`` will\n              be sampled per image.\n            * If a list, then a random value will be sampled from that list per image.\n            * If a StochasticParameter, a value will be sampled from the\n              parameter per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same noise value per pixel for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0))\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images, where ``x`` is randomly sampled per image from the\n    interval ``[0.0, 10.0]``.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=5.0, per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(5.0)`` to images,\n    where the values are different per pixel *and* channel (e.g. a\n    different one for red, green and blue channels for the same pixel).\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=(0.0, 10.0), per_channel=True)\n\n    Adds poisson noise sampled from ``Poisson(x)`` to images,\n    with ``x`` being sampled from ``uniform(0.0, 10.0)`` per image, pixel and channel.\n    This is the *recommended* configuration.\n\n    >>> aug = iaa.AdditivePoissonNoise(lam=2, per_channel=0.5)\n\n    Adds poisson noise sampled from the distribution ``Poisson(2)`` to images,\n    where the values are sometimes (50 percent of all cases) the same\n    per pixel for all channels and sometimes different (other 50 percent).", "docstring_tokens": ["Create", "an", "augmenter", "to", "add", "poisson", "noise", "to", "images", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L546-L626", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "Dropout", "original_string": "def Dropout(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that sets a certain fraction of pixels in images to zero.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all images. A value\n              of 1.0 would mean that all pixels will be dropped and 0.0 that\n              no pixels would be dropped. A value of 0.05 corresponds to 5\n              percent of all pixels dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n              If you instead want to provide the probability as a stochastic\n              parameter, you can usually do ``imgaug.parameters.Binomial(1-p)``\n              to convert parameter `p` to a 0/1 representation.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float p, then for p percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Dropout(0.02)\n\n    drops 2 percent of all pixels.\n\n    >>> aug = iaa.Dropout((0.0, 0.05))\n\n    drops in each image a random fraction of all pixels, where the fraction\n    is in the range ``0.0 <= x <= 0.05``.\n\n    >>> aug = iaa.Dropout(0.02, per_channel=True)\n\n    drops 2 percent of all pixels in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.Dropout(0.02, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.\n\n    \"\"\"\n    if ia.is_single_number(p):\n        p2 = iap.Binomial(1 - p)\n    elif ia.is_iterable(p):\n        ia.do_assert(len(p) == 2)\n        ia.do_assert(p[0] < p[1])\n        ia.do_assert(0 <= p[0] <= 1.0)\n        ia.do_assert(0 <= p[1] <= 1.0)\n        p2 = iap.Binomial(iap.Uniform(1 - p[1], 1 - p[0]))\n    elif isinstance(p, iap.StochasticParameter):\n        p2 = p\n    else:\n        raise Exception(\"Expected p to be float or int or StochasticParameter, got %s.\" % (type(p),))\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return MultiplyElementwise(p2, per_channel=per_channel, name=name, deterministic=deterministic,\n                               random_state=random_state)", "language": "python", "code": "def Dropout(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that sets a certain fraction of pixels in images to zero.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all images. A value\n              of 1.0 would mean that all pixels will be dropped and 0.0 that\n              no pixels would be dropped. A value of 0.05 corresponds to 5\n              percent of all pixels dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n              If you instead want to provide the probability as a stochastic\n              parameter, you can usually do ``imgaug.parameters.Binomial(1-p)``\n              to convert parameter `p` to a 0/1 representation.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float p, then for p percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Dropout(0.02)\n\n    drops 2 percent of all pixels.\n\n    >>> aug = iaa.Dropout((0.0, 0.05))\n\n    drops in each image a random fraction of all pixels, where the fraction\n    is in the range ``0.0 <= x <= 0.05``.\n\n    >>> aug = iaa.Dropout(0.02, per_channel=True)\n\n    drops 2 percent of all pixels in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.Dropout(0.02, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.\n\n    \"\"\"\n    if ia.is_single_number(p):\n        p2 = iap.Binomial(1 - p)\n    elif ia.is_iterable(p):\n        ia.do_assert(len(p) == 2)\n        ia.do_assert(p[0] < p[1])\n        ia.do_assert(0 <= p[0] <= 1.0)\n        ia.do_assert(0 <= p[1] <= 1.0)\n        p2 = iap.Binomial(iap.Uniform(1 - p[1], 1 - p[0]))\n    elif isinstance(p, iap.StochasticParameter):\n        p2 = p\n    else:\n        raise Exception(\"Expected p to be float or int or StochasticParameter, got %s.\" % (type(p),))\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return MultiplyElementwise(p2, per_channel=per_channel, name=name, deterministic=deterministic,\n                               random_state=random_state)", "code_tokens": ["def", "Dropout", "(", "p", "=", "0", ",", "per_channel", "=", "False", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "if", "ia", ".", "is_single_number", "(", "p", ")", ":", "p2", "=", "iap", ".", "Binomial", "(", "1", "-", "p", ")", "elif", "ia", ".", "is_iterable", "(", "p", ")", ":", "ia", ".", "do_assert", "(", "len", "(", "p", ")", "==", "2", ")", "ia", ".", "do_assert", "(", "p", "[", "0", "]", "<", "p", "[", "1", "]", ")", "ia", ".", "do_assert", "(", "0", "<=", "p", "[", "0", "]", "<=", "1.0", ")", "ia", ".", "do_assert", "(", "0", "<=", "p", "[", "1", "]", "<=", "1.0", ")", "p2", "=", "iap", ".", "Binomial", "(", "iap", ".", "Uniform", "(", "1", "-", "p", "[", "1", "]", ",", "1", "-", "p", "[", "0", "]", ")", ")", "elif", "isinstance", "(", "p", ",", "iap", ".", "StochasticParameter", ")", ":", "p2", "=", "p", "else", ":", "raise", "Exception", "(", "\"Expected p to be float or int or StochasticParameter, got %s.\"", "%", "(", "type", "(", "p", ")", ",", ")", ")", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "MultiplyElementwise", "(", "p2", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that sets a certain fraction of pixels in images to zero.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all images. A value\n              of 1.0 would mean that all pixels will be dropped and 0.0 that\n              no pixels would be dropped. A value of 0.05 corresponds to 5\n              percent of all pixels dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n              If you instead want to provide the probability as a stochastic\n              parameter, you can usually do ``imgaug.parameters.Binomial(1-p)``\n              to convert parameter `p` to a 0/1 representation.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float p, then for p percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Dropout(0.02)\n\n    drops 2 percent of all pixels.\n\n    >>> aug = iaa.Dropout((0.0, 0.05))\n\n    drops in each image a random fraction of all pixels, where the fraction\n    is in the range ``0.0 <= x <= 0.05``.\n\n    >>> aug = iaa.Dropout(0.02, per_channel=True)\n\n    drops 2 percent of all pixels in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.Dropout(0.02, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.", "docstring_tokens": ["Augmenter", "that", "sets", "a", "certain", "fraction", "of", "pixels", "in", "images", "to", "zero", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L977-L1059", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "CoarseDropout", "original_string": "def CoarseDropout(p=0, size_px=None, size_percent=None, per_channel=False, min_size=4, name=None, deterministic=False,\n                  random_state=None):\n    \"\"\"\n    Augmenter that sets rectangular areas within images to zero.\n\n    In contrast to Dropout, these areas can have larger sizes.\n    (E.g. you might end up with three large black rectangles in an image.)\n    Note that the current implementation leads to correlated sizes,\n    so when there is one large area that is dropped, there is a high likelihood\n    that all other dropped areas are also large.\n\n    This method is implemented by generating the dropout mask at a\n    lower resolution (than the image has) and then upsampling the mask\n    before dropping the pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all pixels. A value\n              of 1.0 would mean, that all pixels will be dropped. A value of\n              0.0 would lead to no pixels being dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a ``1x1`` low resolution mask, leading easily\n        to the whole image being dropped.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5)\n\n    drops 2 percent of all pixels on an lower-resolution image that has\n    50 percent of the original image's size, leading to dropped areas that\n    have roughly 2x2 pixels size.\n\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_percent=(0.05, 0.5))\n\n    generates a dropout mask at 5 to 50 percent of image's size. In that mask,\n    0 to 5 percent of all pixels are dropped (random per image).\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_px=(2, 16))\n\n    same as previous example, but the lower resolution image has 2 to 16 pixels\n    size.\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=True)\n\n    drops 2 percent of all pixels at 50 percent resolution (2x2 sizes)\n    in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.\n\n    \"\"\"\n    if ia.is_single_number(p):\n        p2 = iap.Binomial(1 - p)\n    elif ia.is_iterable(p):\n        ia.do_assert(len(p) == 2)\n        ia.do_assert(p[0] < p[1])\n        ia.do_assert(0 <= p[0] <= 1.0)\n        ia.do_assert(0 <= p[1] <= 1.0)\n        p2 = iap.Binomial(iap.Uniform(1 - p[1], 1 - p[0]))\n    elif isinstance(p, iap.StochasticParameter):\n        p2 = p\n    else:\n        raise Exception(\"Expected p to be float or int or StochasticParameter, got %s.\" % (type(p),))\n\n    if size_px is not None:\n        p3 = iap.FromLowerResolution(other_param=p2, size_px=size_px, min_size=min_size)\n    elif size_percent is not None:\n        p3 = iap.FromLowerResolution(other_param=p2, size_percent=size_percent, min_size=min_size)\n    else:\n        raise Exception(\"Either size_px or size_percent must be set.\")\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return MultiplyElementwise(p3, per_channel=per_channel, name=name, deterministic=deterministic,\n                               random_state=random_state)", "language": "python", "code": "def CoarseDropout(p=0, size_px=None, size_percent=None, per_channel=False, min_size=4, name=None, deterministic=False,\n                  random_state=None):\n    \"\"\"\n    Augmenter that sets rectangular areas within images to zero.\n\n    In contrast to Dropout, these areas can have larger sizes.\n    (E.g. you might end up with three large black rectangles in an image.)\n    Note that the current implementation leads to correlated sizes,\n    so when there is one large area that is dropped, there is a high likelihood\n    that all other dropped areas are also large.\n\n    This method is implemented by generating the dropout mask at a\n    lower resolution (than the image has) and then upsampling the mask\n    before dropping the pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all pixels. A value\n              of 1.0 would mean, that all pixels will be dropped. A value of\n              0.0 would lead to no pixels being dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a ``1x1`` low resolution mask, leading easily\n        to the whole image being dropped.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5)\n\n    drops 2 percent of all pixels on an lower-resolution image that has\n    50 percent of the original image's size, leading to dropped areas that\n    have roughly 2x2 pixels size.\n\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_percent=(0.05, 0.5))\n\n    generates a dropout mask at 5 to 50 percent of image's size. In that mask,\n    0 to 5 percent of all pixels are dropped (random per image).\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_px=(2, 16))\n\n    same as previous example, but the lower resolution image has 2 to 16 pixels\n    size.\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=True)\n\n    drops 2 percent of all pixels at 50 percent resolution (2x2 sizes)\n    in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.\n\n    \"\"\"\n    if ia.is_single_number(p):\n        p2 = iap.Binomial(1 - p)\n    elif ia.is_iterable(p):\n        ia.do_assert(len(p) == 2)\n        ia.do_assert(p[0] < p[1])\n        ia.do_assert(0 <= p[0] <= 1.0)\n        ia.do_assert(0 <= p[1] <= 1.0)\n        p2 = iap.Binomial(iap.Uniform(1 - p[1], 1 - p[0]))\n    elif isinstance(p, iap.StochasticParameter):\n        p2 = p\n    else:\n        raise Exception(\"Expected p to be float or int or StochasticParameter, got %s.\" % (type(p),))\n\n    if size_px is not None:\n        p3 = iap.FromLowerResolution(other_param=p2, size_px=size_px, min_size=min_size)\n    elif size_percent is not None:\n        p3 = iap.FromLowerResolution(other_param=p2, size_percent=size_percent, min_size=min_size)\n    else:\n        raise Exception(\"Either size_px or size_percent must be set.\")\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return MultiplyElementwise(p3, per_channel=per_channel, name=name, deterministic=deterministic,\n                               random_state=random_state)", "code_tokens": ["def", "CoarseDropout", "(", "p", "=", "0", ",", "size_px", "=", "None", ",", "size_percent", "=", "None", ",", "per_channel", "=", "False", ",", "min_size", "=", "4", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "if", "ia", ".", "is_single_number", "(", "p", ")", ":", "p2", "=", "iap", ".", "Binomial", "(", "1", "-", "p", ")", "elif", "ia", ".", "is_iterable", "(", "p", ")", ":", "ia", ".", "do_assert", "(", "len", "(", "p", ")", "==", "2", ")", "ia", ".", "do_assert", "(", "p", "[", "0", "]", "<", "p", "[", "1", "]", ")", "ia", ".", "do_assert", "(", "0", "<=", "p", "[", "0", "]", "<=", "1.0", ")", "ia", ".", "do_assert", "(", "0", "<=", "p", "[", "1", "]", "<=", "1.0", ")", "p2", "=", "iap", ".", "Binomial", "(", "iap", ".", "Uniform", "(", "1", "-", "p", "[", "1", "]", ",", "1", "-", "p", "[", "0", "]", ")", ")", "elif", "isinstance", "(", "p", ",", "iap", ".", "StochasticParameter", ")", ":", "p2", "=", "p", "else", ":", "raise", "Exception", "(", "\"Expected p to be float or int or StochasticParameter, got %s.\"", "%", "(", "type", "(", "p", ")", ",", ")", ")", "if", "size_px", "is", "not", "None", ":", "p3", "=", "iap", ".", "FromLowerResolution", "(", "other_param", "=", "p2", ",", "size_px", "=", "size_px", ",", "min_size", "=", "min_size", ")", "elif", "size_percent", "is", "not", "None", ":", "p3", "=", "iap", ".", "FromLowerResolution", "(", "other_param", "=", "p2", ",", "size_percent", "=", "size_percent", ",", "min_size", "=", "min_size", ")", "else", ":", "raise", "Exception", "(", "\"Either size_px or size_percent must be set.\"", ")", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "MultiplyElementwise", "(", "p3", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that sets rectangular areas within images to zero.\n\n    In contrast to Dropout, these areas can have larger sizes.\n    (E.g. you might end up with three large black rectangles in an image.)\n    Note that the current implementation leads to correlated sizes,\n    so when there is one large area that is dropped, there is a high likelihood\n    that all other dropped areas are also large.\n\n    This method is implemented by generating the dropout mask at a\n    lower resolution (than the image has) and then upsampling the mask\n    before dropping the pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.MultiplyElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The probability of any pixel being dropped (i.e. set to zero).\n\n            * If a float, then that value will be used for all pixels. A value\n              of 1.0 would mean, that all pixels will be dropped. A value of\n              0.0 would lead to no pixels being dropped.\n            * If a tuple ``(a, b)``, then a value p will be sampled from the\n              range ``a <= p <= b`` per image and be used as the pixel's dropout\n              probability.\n            * If a StochasticParameter, then this parameter will be used to\n              determine per pixel whether it should be dropped (sampled value\n              of 0) or shouldn't (sampled value of 1).\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the dropout\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a ``1x1`` low resolution mask, leading easily\n        to the whole image being dropped.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5)\n\n    drops 2 percent of all pixels on an lower-resolution image that has\n    50 percent of the original image's size, leading to dropped areas that\n    have roughly 2x2 pixels size.\n\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_percent=(0.05, 0.5))\n\n    generates a dropout mask at 5 to 50 percent of image's size. In that mask,\n    0 to 5 percent of all pixels are dropped (random per image).\n\n    >>> aug = iaa.CoarseDropout((0.0, 0.05), size_px=(2, 16))\n\n    same as previous example, but the lower resolution image has 2 to 16 pixels\n    size.\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=True)\n\n    drops 2 percent of all pixels at 50 percent resolution (2x2 sizes)\n    in a channel-wise fashion, i.e. it is unlikely\n    for any pixel to have all channels set to zero (black pixels).\n\n    >>> aug = iaa.CoarseDropout(0.02, size_percent=0.5, per_channel=0.5)\n\n    same as previous example, but the `per_channel` feature is only active\n    for 50 percent of all images.", "docstring_tokens": ["Augmenter", "that", "sets", "rectangular", "areas", "within", "images", "to", "zero", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L1062-L1201", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "ImpulseNoise", "original_string": "def ImpulseNoise(p=0, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Creates an augmenter to apply impulse noise to an image.\n\n    This is identical to ``SaltAndPepper``, except that per_channel is always set to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.SaltAndPepper``.\n\n    \"\"\"\n    return SaltAndPepper(p=p, per_channel=True, name=name, deterministic=deterministic, random_state=random_state)", "language": "python", "code": "def ImpulseNoise(p=0, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Creates an augmenter to apply impulse noise to an image.\n\n    This is identical to ``SaltAndPepper``, except that per_channel is always set to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.SaltAndPepper``.\n\n    \"\"\"\n    return SaltAndPepper(p=p, per_channel=True, name=name, deterministic=deterministic, random_state=random_state)", "code_tokens": ["def", "ImpulseNoise", "(", "p", "=", "0", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "return", "SaltAndPepper", "(", "p", "=", "p", ",", "per_channel", "=", "True", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Creates an augmenter to apply impulse noise to an image.\n\n    This is identical to ``SaltAndPepper``, except that per_channel is always set to True.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.SaltAndPepper``.", "docstring_tokens": ["Creates", "an", "augmenter", "to", "apply", "impulse", "noise", "to", "an", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L1360-L1371", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "SaltAndPepper", "original_string": "def SaltAndPepper(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Adds salt and pepper noise to an image, i.e. some white-ish and black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to salt/pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that salt/pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.SaltAndPepper(0.05)\n\n    Replaces 5 percent of all pixels with salt/pepper.\n\n    \"\"\"\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=p,\n        replacement=iap.Beta(0.5, 0.5) * 255,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "language": "python", "code": "def SaltAndPepper(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Adds salt and pepper noise to an image, i.e. some white-ish and black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to salt/pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that salt/pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.SaltAndPepper(0.05)\n\n    Replaces 5 percent of all pixels with salt/pepper.\n\n    \"\"\"\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=p,\n        replacement=iap.Beta(0.5, 0.5) * 255,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "code_tokens": ["def", "SaltAndPepper", "(", "p", "=", "0", ",", "per_channel", "=", "False", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "ReplaceElementwise", "(", "mask", "=", "p", ",", "replacement", "=", "iap", ".", "Beta", "(", "0.5", ",", "0.5", ")", "*", "255", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Adds salt and pepper noise to an image, i.e. some white-ish and black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to salt/pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that salt/pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.SaltAndPepper(0.05)\n\n    Replaces 5 percent of all pixels with salt/pepper.", "docstring_tokens": ["Adds", "salt", "and", "pepper", "noise", "to", "an", "image", "i", ".", "e", ".", "some", "white", "-", "ish", "and", "black", "-", "ish", "pixels", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L1374-L1430", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "Pepper", "original_string": "def Pepper(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Adds pepper noise to an image, i.e. black-ish pixels.\n\n    This is similar to dropout, but slower and the black pixels are not uniformly black.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Pepper(0.05)\n\n    Replaces 5 percent of all pixels with pepper.\n\n    \"\"\"\n\n    replacement01 = iap.ForceSign(\n        iap.Beta(0.5, 0.5) - 0.5,\n        positive=False,\n        mode=\"invert\"\n    ) + 0.5\n    replacement = replacement01 * 255\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=p,\n        replacement=replacement,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "language": "python", "code": "def Pepper(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Adds pepper noise to an image, i.e. black-ish pixels.\n\n    This is similar to dropout, but slower and the black pixels are not uniformly black.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Pepper(0.05)\n\n    Replaces 5 percent of all pixels with pepper.\n\n    \"\"\"\n\n    replacement01 = iap.ForceSign(\n        iap.Beta(0.5, 0.5) - 0.5,\n        positive=False,\n        mode=\"invert\"\n    ) + 0.5\n    replacement = replacement01 * 255\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=p,\n        replacement=replacement,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "code_tokens": ["def", "Pepper", "(", "p", "=", "0", ",", "per_channel", "=", "False", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "replacement01", "=", "iap", ".", "ForceSign", "(", "iap", ".", "Beta", "(", "0.5", ",", "0.5", ")", "-", "0.5", ",", "positive", "=", "False", ",", "mode", "=", "\"invert\"", ")", "+", "0.5", "replacement", "=", "replacement01", "*", "255", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "ReplaceElementwise", "(", "mask", "=", "p", ",", "replacement", "=", "replacement", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Adds pepper noise to an image, i.e. black-ish pixels.\n\n    This is similar to dropout, but slower and the black pixels are not uniformly black.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b``.\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.Pepper(0.05)\n\n    Replaces 5 percent of all pixels with pepper.", "docstring_tokens": ["Adds", "pepper", "noise", "to", "an", "image", "i", ".", "e", ".", "black", "-", "ish", "pixels", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L1711-L1777", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "CoarsePepper", "original_string": "def CoarsePepper(p=0, size_px=None, size_percent=None, per_channel=False, min_size=4, name=None, deterministic=False,\n                 random_state=None):\n    \"\"\"\n    Adds coarse pepper noise to an image, i.e. rectangles that contain noisy black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b.``\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a 1x1 low resolution mask, leading easily\n        to the whole image being replaced.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarsePepper(0.05, size_percent=(0.01, 0.1))\n\n    Replaces 5 percent of all pixels with pepper in an image that has\n    1 to 10 percent of the input image size, then upscales the results\n    to the input image size, leading to large rectangular areas being replaced.\n\n    \"\"\"\n    mask = iap.handle_probability_param(p, \"p\", tuple_to_uniform=True, list_to_choice=True)\n\n    if size_px is not None:\n        mask_low = iap.FromLowerResolution(other_param=mask, size_px=size_px, min_size=min_size)\n    elif size_percent is not None:\n        mask_low = iap.FromLowerResolution(other_param=mask, size_percent=size_percent, min_size=min_size)\n    else:\n        raise Exception(\"Either size_px or size_percent must be set.\")\n\n    replacement01 = iap.ForceSign(\n        iap.Beta(0.5, 0.5) - 0.5,\n        positive=False,\n        mode=\"invert\"\n    ) + 0.5\n    replacement = replacement01 * 255\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=mask_low,\n        replacement=replacement,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "language": "python", "code": "def CoarsePepper(p=0, size_px=None, size_percent=None, per_channel=False, min_size=4, name=None, deterministic=False,\n                 random_state=None):\n    \"\"\"\n    Adds coarse pepper noise to an image, i.e. rectangles that contain noisy black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b.``\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a 1x1 low resolution mask, leading easily\n        to the whole image being replaced.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarsePepper(0.05, size_percent=(0.01, 0.1))\n\n    Replaces 5 percent of all pixels with pepper in an image that has\n    1 to 10 percent of the input image size, then upscales the results\n    to the input image size, leading to large rectangular areas being replaced.\n\n    \"\"\"\n    mask = iap.handle_probability_param(p, \"p\", tuple_to_uniform=True, list_to_choice=True)\n\n    if size_px is not None:\n        mask_low = iap.FromLowerResolution(other_param=mask, size_px=size_px, min_size=min_size)\n    elif size_percent is not None:\n        mask_low = iap.FromLowerResolution(other_param=mask, size_percent=size_percent, min_size=min_size)\n    else:\n        raise Exception(\"Either size_px or size_percent must be set.\")\n\n    replacement01 = iap.ForceSign(\n        iap.Beta(0.5, 0.5) - 0.5,\n        positive=False,\n        mode=\"invert\"\n    ) + 0.5\n    replacement = replacement01 * 255\n\n    if name is None:\n        name = \"Unnamed%s\" % (ia.caller_name(),)\n\n    return ReplaceElementwise(\n        mask=mask_low,\n        replacement=replacement,\n        per_channel=per_channel,\n        name=name,\n        deterministic=deterministic,\n        random_state=random_state\n    )", "code_tokens": ["def", "CoarsePepper", "(", "p", "=", "0", ",", "size_px", "=", "None", ",", "size_percent", "=", "None", ",", "per_channel", "=", "False", ",", "min_size", "=", "4", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "mask", "=", "iap", ".", "handle_probability_param", "(", "p", ",", "\"p\"", ",", "tuple_to_uniform", "=", "True", ",", "list_to_choice", "=", "True", ")", "if", "size_px", "is", "not", "None", ":", "mask_low", "=", "iap", ".", "FromLowerResolution", "(", "other_param", "=", "mask", ",", "size_px", "=", "size_px", ",", "min_size", "=", "min_size", ")", "elif", "size_percent", "is", "not", "None", ":", "mask_low", "=", "iap", ".", "FromLowerResolution", "(", "other_param", "=", "mask", ",", "size_percent", "=", "size_percent", ",", "min_size", "=", "min_size", ")", "else", ":", "raise", "Exception", "(", "\"Either size_px or size_percent must be set.\"", ")", "replacement01", "=", "iap", ".", "ForceSign", "(", "iap", ".", "Beta", "(", "0.5", ",", "0.5", ")", "-", "0.5", ",", "positive", "=", "False", ",", "mode", "=", "\"invert\"", ")", "+", "0.5", "replacement", "=", "replacement01", "*", "255", "if", "name", "is", "None", ":", "name", "=", "\"Unnamed%s\"", "%", "(", "ia", ".", "caller_name", "(", ")", ",", ")", "return", "ReplaceElementwise", "(", "mask", "=", "mask_low", ",", "replacement", "=", "replacement", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Adds coarse pepper noise to an image, i.e. rectangles that contain noisy black-ish pixels.\n\n    dtype support::\n\n        See ``imgaug.augmenters.arithmetic.ReplaceElementwise``.\n\n    Parameters\n    ----------\n    p : float or tuple of float or list of float or imgaug.parameters.StochasticParameter, optional\n        Probability of changing a pixel to pepper noise.\n\n            * If a float, then that value will be used for all images as the\n              probability.\n            * If a tuple ``(a, b)``, then a probability will be sampled per image\n              from the range ``a <= x <= b.``\n            * If a list, then a random value will be sampled from that list\n              per image.\n            * If a StochasticParameter, then this parameter will be used as\n              the *mask*, i.e. it is expected to contain values between\n              0.0 and 1.0, where 1.0 means that pepper is to be added\n              at that location.\n\n    size_px : int or tuple of int or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask in absolute pixel dimensions.\n\n            * If an integer, then that size will be used for both height and\n              width. E.g. a value of 3 would lead to a ``3x3`` mask, which is then\n              upsampled to ``HxW``, where ``H`` is the image size and W the image width.\n            * If a tuple ``(a, b)``, then two values ``M``, ``N`` will be sampled from the\n              range ``[a..b]`` and the mask will be generated at size ``MxN``, then\n              upsampled to ``HxW``.\n            * If a StochasticParameter, then this parameter will be used to\n              determine the sizes. It is expected to be discrete.\n\n    size_percent : float or tuple of float or imgaug.parameters.StochasticParameter, optional\n        The size of the lower resolution image from which to sample the noise\n        mask *in percent* of the input image.\n\n            * If a float, then that value will be used as the percentage of the\n              height and width (relative to the original size). E.g. for value\n              p, the mask will be sampled from ``(p*H)x(p*W)`` and later upsampled\n              to ``HxW``.\n            * If a tuple ``(a, b)``, then two values ``m``, ``n`` will be sampled from the\n              interval ``(a, b)`` and used as the percentages, i.e the mask size\n              will be ``(m*H)x(n*W)``.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the percentage values. It is expected to be continuous.\n\n    per_channel : bool or float, optional\n        Whether to use the same value (is dropped / is not dropped)\n        for all channels of a pixel (False) or to sample a new value for each\n        channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    min_size : int, optional\n        Minimum size of the low resolution mask, both width and height. If\n        `size_percent` or `size_px` leads to a lower value than this, `min_size`\n        will be used instead. This should never have a value of less than 2,\n        otherwise one may end up with a 1x1 low resolution mask, leading easily\n        to the whole image being replaced.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> aug = iaa.CoarsePepper(0.05, size_percent=(0.01, 0.1))\n\n    Replaces 5 percent of all pixels with pepper in an image that has\n    1 to 10 percent of the input image size, then upscales the results\n    to the input image size, leading to large rectangular areas being replaced.", "docstring_tokens": ["Adds", "coarse", "pepper", "noise", "to", "an", "image", "i", ".", "e", ".", "rectangles", "that", "contain", "noisy", "black", "-", "ish", "pixels", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L1780-L1890", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/augmenters/arithmetic.py", "func_name": "ContrastNormalization", "original_string": "def ContrastNormalization(alpha=1.0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that changes the contrast of images.\n\n    dtype support:\n\n        See ``imgaug.augmenters.contrast.LinearContrast``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Strength of the contrast normalization. Higher values than 1.0\n        lead to higher contrast, lower values decrease the contrast.\n\n            * If a number, then that value will be used for all images.\n            * If a tuple ``(a, b)``, then a value will be sampled per image from\n              the range ``a <= x <= b`` and be used as the alpha value.\n            * If a list, then a random value will be sampled per image from\n              that list.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the alpha value per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> iaa.ContrastNormalization((0.5, 1.5))\n\n    Decreases oder improves contrast per image by a random factor between\n    0.5 and 1.5. The factor 0.5 means that any difference from the center value\n    (i.e. 128) will be halved, leading to less contrast.\n\n    >>> iaa.ContrastNormalization((0.5, 1.5), per_channel=0.5)\n\n    Same as before, but for 50 percent of all images the normalization is done\n    independently per channel (i.e. factors can vary per channel for the same\n    image). In the other 50 percent of all images, the factor is the same for\n    all channels.\n\n    \"\"\"\n    # placed here to avoid cyclic dependency\n    from . import contrast as contrast_lib\n    return contrast_lib.LinearContrast(alpha=alpha, per_channel=per_channel, name=name, deterministic=deterministic,\n                                       random_state=random_state)", "language": "python", "code": "def ContrastNormalization(alpha=1.0, per_channel=False, name=None, deterministic=False, random_state=None):\n    \"\"\"\n    Augmenter that changes the contrast of images.\n\n    dtype support:\n\n        See ``imgaug.augmenters.contrast.LinearContrast``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Strength of the contrast normalization. Higher values than 1.0\n        lead to higher contrast, lower values decrease the contrast.\n\n            * If a number, then that value will be used for all images.\n            * If a tuple ``(a, b)``, then a value will be sampled per image from\n              the range ``a <= x <= b`` and be used as the alpha value.\n            * If a list, then a random value will be sampled per image from\n              that list.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the alpha value per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> iaa.ContrastNormalization((0.5, 1.5))\n\n    Decreases oder improves contrast per image by a random factor between\n    0.5 and 1.5. The factor 0.5 means that any difference from the center value\n    (i.e. 128) will be halved, leading to less contrast.\n\n    >>> iaa.ContrastNormalization((0.5, 1.5), per_channel=0.5)\n\n    Same as before, but for 50 percent of all images the normalization is done\n    independently per channel (i.e. factors can vary per channel for the same\n    image). In the other 50 percent of all images, the factor is the same for\n    all channels.\n\n    \"\"\"\n    # placed here to avoid cyclic dependency\n    from . import contrast as contrast_lib\n    return contrast_lib.LinearContrast(alpha=alpha, per_channel=per_channel, name=name, deterministic=deterministic,\n                                       random_state=random_state)", "code_tokens": ["def", "ContrastNormalization", "(", "alpha", "=", "1.0", ",", "per_channel", "=", "False", ",", "name", "=", "None", ",", "deterministic", "=", "False", ",", "random_state", "=", "None", ")", ":", "# placed here to avoid cyclic dependency", "from", ".", "import", "contrast", "as", "contrast_lib", "return", "contrast_lib", ".", "LinearContrast", "(", "alpha", "=", "alpha", ",", "per_channel", "=", "per_channel", ",", "name", "=", "name", ",", "deterministic", "=", "deterministic", ",", "random_state", "=", "random_state", ")"], "docstring": "Augmenter that changes the contrast of images.\n\n    dtype support:\n\n        See ``imgaug.augmenters.contrast.LinearContrast``.\n\n    Parameters\n    ----------\n    alpha : number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional\n        Strength of the contrast normalization. Higher values than 1.0\n        lead to higher contrast, lower values decrease the contrast.\n\n            * If a number, then that value will be used for all images.\n            * If a tuple ``(a, b)``, then a value will be sampled per image from\n              the range ``a <= x <= b`` and be used as the alpha value.\n            * If a list, then a random value will be sampled per image from\n              that list.\n            * If a StochasticParameter, then this parameter will be used to\n              sample the alpha value per image.\n\n    per_channel : bool or float, optional\n        Whether to use the same value for all channels (False)\n        or to sample a new value for each channel (True).\n        If this value is a float ``p``, then for ``p`` percent of all images\n        `per_channel` will be treated as True, otherwise as False.\n\n    name : None or str, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    deterministic : bool, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    random_state : None or int or numpy.random.RandomState, optional\n        See :func:`imgaug.augmenters.meta.Augmenter.__init__`.\n\n    Examples\n    --------\n    >>> iaa.ContrastNormalization((0.5, 1.5))\n\n    Decreases oder improves contrast per image by a random factor between\n    0.5 and 1.5. The factor 0.5 means that any difference from the center value\n    (i.e. 128) will be halved, leading to less contrast.\n\n    >>> iaa.ContrastNormalization((0.5, 1.5), per_channel=0.5)\n\n    Same as before, but for 50 percent of all images the normalization is done\n    independently per channel (i.e. factors can vary per channel for the same\n    image). In the other 50 percent of all images, the factor is the same for\n    all channels.", "docstring_tokens": ["Augmenter", "that", "changes", "the", "contrast", "of", "images", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/augmenters/arithmetic.py#L2151-L2207", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "is_single_float", "original_string": "def is_single_float(val):\n    \"\"\"\n    Checks whether a variable is a float.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a float. Otherwise False.\n\n    \"\"\"\n    return isinstance(val, numbers.Real) and not is_single_integer(val) and not isinstance(val, bool)", "language": "python", "code": "def is_single_float(val):\n    \"\"\"\n    Checks whether a variable is a float.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a float. Otherwise False.\n\n    \"\"\"\n    return isinstance(val, numbers.Real) and not is_single_integer(val) and not isinstance(val, bool)", "code_tokens": ["def", "is_single_float", "(", "val", ")", ":", "return", "isinstance", "(", "val", ",", "numbers", ".", "Real", ")", "and", "not", "is_single_integer", "(", "val", ")", "and", "not", "isinstance", "(", "val", ",", "bool", ")"], "docstring": "Checks whether a variable is a float.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a float. Otherwise False.", "docstring_tokens": ["Checks", "whether", "a", "variable", "is", "a", "float", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L94-L109", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "is_integer_array", "original_string": "def is_integer_array(val):\n    \"\"\"\n    Checks whether a variable is a numpy integer array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy integer array. Otherwise False.\n\n    \"\"\"\n    return is_np_array(val) and issubclass(val.dtype.type, np.integer)", "language": "python", "code": "def is_integer_array(val):\n    \"\"\"\n    Checks whether a variable is a numpy integer array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy integer array. Otherwise False.\n\n    \"\"\"\n    return is_np_array(val) and issubclass(val.dtype.type, np.integer)", "code_tokens": ["def", "is_integer_array", "(", "val", ")", ":", "return", "is_np_array", "(", "val", ")", "and", "issubclass", "(", "val", ".", "dtype", ".", "type", ",", "np", ".", "integer", ")"], "docstring": "Checks whether a variable is a numpy integer array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy integer array. Otherwise False.", "docstring_tokens": ["Checks", "whether", "a", "variable", "is", "a", "numpy", "integer", "array", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L185-L200", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "is_float_array", "original_string": "def is_float_array(val):\n    \"\"\"\n    Checks whether a variable is a numpy float array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy float array. Otherwise False.\n\n    \"\"\"\n    return is_np_array(val) and issubclass(val.dtype.type, np.floating)", "language": "python", "code": "def is_float_array(val):\n    \"\"\"\n    Checks whether a variable is a numpy float array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy float array. Otherwise False.\n\n    \"\"\"\n    return is_np_array(val) and issubclass(val.dtype.type, np.floating)", "code_tokens": ["def", "is_float_array", "(", "val", ")", ":", "return", "is_np_array", "(", "val", ")", "and", "issubclass", "(", "val", ".", "dtype", ".", "type", ",", "np", ".", "floating", ")"], "docstring": "Checks whether a variable is a numpy float array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy float array. Otherwise False.", "docstring_tokens": ["Checks", "whether", "a", "variable", "is", "a", "numpy", "float", "array", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L203-L218", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "new_random_state", "original_string": "def new_random_state(seed=None, fully_random=False):\n    \"\"\"\n    Returns a new random state.\n\n    Parameters\n    ----------\n    seed : None or int, optional\n        Optional seed value to use.\n        The same datatypes are allowed as for ``numpy.random.RandomState(seed)``.\n\n    fully_random : bool, optional\n        Whether to use numpy's random initialization for the\n        RandomState (used if set to True). If False, a seed is sampled from\n        the global random state, which is a bit faster and hence the default.\n\n    Returns\n    -------\n    numpy.random.RandomState\n        The new random state.\n\n    \"\"\"\n    if seed is None:\n        if not fully_random:\n            # sample manually a seed instead of just RandomState(),\n            # because the latter one\n            # is way slower.\n            seed = CURRENT_RANDOM_STATE.randint(SEED_MIN_VALUE, SEED_MAX_VALUE, 1)[0]\n    return np.random.RandomState(seed)", "language": "python", "code": "def new_random_state(seed=None, fully_random=False):\n    \"\"\"\n    Returns a new random state.\n\n    Parameters\n    ----------\n    seed : None or int, optional\n        Optional seed value to use.\n        The same datatypes are allowed as for ``numpy.random.RandomState(seed)``.\n\n    fully_random : bool, optional\n        Whether to use numpy's random initialization for the\n        RandomState (used if set to True). If False, a seed is sampled from\n        the global random state, which is a bit faster and hence the default.\n\n    Returns\n    -------\n    numpy.random.RandomState\n        The new random state.\n\n    \"\"\"\n    if seed is None:\n        if not fully_random:\n            # sample manually a seed instead of just RandomState(),\n            # because the latter one\n            # is way slower.\n            seed = CURRENT_RANDOM_STATE.randint(SEED_MIN_VALUE, SEED_MAX_VALUE, 1)[0]\n    return np.random.RandomState(seed)", "code_tokens": ["def", "new_random_state", "(", "seed", "=", "None", ",", "fully_random", "=", "False", ")", ":", "if", "seed", "is", "None", ":", "if", "not", "fully_random", ":", "# sample manually a seed instead of just RandomState(),", "# because the latter one", "# is way slower.", "seed", "=", "CURRENT_RANDOM_STATE", ".", "randint", "(", "SEED_MIN_VALUE", ",", "SEED_MAX_VALUE", ",", "1", ")", "[", "0", "]", "return", "np", ".", "random", ".", "RandomState", "(", "seed", ")"], "docstring": "Returns a new random state.\n\n    Parameters\n    ----------\n    seed : None or int, optional\n        Optional seed value to use.\n        The same datatypes are allowed as for ``numpy.random.RandomState(seed)``.\n\n    fully_random : bool, optional\n        Whether to use numpy's random initialization for the\n        RandomState (used if set to True). If False, a seed is sampled from\n        the global random state, which is a bit faster and hence the default.\n\n    Returns\n    -------\n    numpy.random.RandomState\n        The new random state.", "docstring_tokens": ["Returns", "a", "new", "random", "state", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L336-L363", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "copy_random_state", "original_string": "def copy_random_state(random_state, force_copy=False):\n    \"\"\"\n    Creates a copy of a random state.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        The random state to copy.\n\n    force_copy : bool, optional\n        If True, this function will always create a copy of every random\n        state. If False, it will not copy numpy's default random state,\n        but all other random states.\n\n    Returns\n    -------\n    rs_copy : numpy.random.RandomState\n        The copied random state.\n\n    \"\"\"\n    if random_state == np.random and not force_copy:\n        return random_state\n    else:\n        rs_copy = dummy_random_state()\n        orig_state = random_state.get_state()\n        rs_copy.set_state(orig_state)\n        return rs_copy", "language": "python", "code": "def copy_random_state(random_state, force_copy=False):\n    \"\"\"\n    Creates a copy of a random state.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        The random state to copy.\n\n    force_copy : bool, optional\n        If True, this function will always create a copy of every random\n        state. If False, it will not copy numpy's default random state,\n        but all other random states.\n\n    Returns\n    -------\n    rs_copy : numpy.random.RandomState\n        The copied random state.\n\n    \"\"\"\n    if random_state == np.random and not force_copy:\n        return random_state\n    else:\n        rs_copy = dummy_random_state()\n        orig_state = random_state.get_state()\n        rs_copy.set_state(orig_state)\n        return rs_copy", "code_tokens": ["def", "copy_random_state", "(", "random_state", ",", "force_copy", "=", "False", ")", ":", "if", "random_state", "==", "np", ".", "random", "and", "not", "force_copy", ":", "return", "random_state", "else", ":", "rs_copy", "=", "dummy_random_state", "(", ")", "orig_state", "=", "random_state", ".", "get_state", "(", ")", "rs_copy", ".", "set_state", "(", "orig_state", ")", "return", "rs_copy"], "docstring": "Creates a copy of a random state.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        The random state to copy.\n\n    force_copy : bool, optional\n        If True, this function will always create a copy of every random\n        state. If False, it will not copy numpy's default random state,\n        but all other random states.\n\n    Returns\n    -------\n    rs_copy : numpy.random.RandomState\n        The copied random state.", "docstring_tokens": ["Creates", "a", "copy", "of", "a", "random", "state", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L379-L405", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "derive_random_states", "original_string": "def derive_random_states(random_state, n=1):\n    \"\"\"\n    Create N new random states based on an existing random state or seed.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        Random state or seed from which to derive new random states.\n\n    n : int, optional\n        Number of random states to derive.\n\n    Returns\n    -------\n    list of numpy.random.RandomState\n        Derived random states.\n\n    \"\"\"\n    seed_ = random_state.randint(SEED_MIN_VALUE, SEED_MAX_VALUE, 1)[0]\n    return [new_random_state(seed_+i) for i in sm.xrange(n)]", "language": "python", "code": "def derive_random_states(random_state, n=1):\n    \"\"\"\n    Create N new random states based on an existing random state or seed.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        Random state or seed from which to derive new random states.\n\n    n : int, optional\n        Number of random states to derive.\n\n    Returns\n    -------\n    list of numpy.random.RandomState\n        Derived random states.\n\n    \"\"\"\n    seed_ = random_state.randint(SEED_MIN_VALUE, SEED_MAX_VALUE, 1)[0]\n    return [new_random_state(seed_+i) for i in sm.xrange(n)]", "code_tokens": ["def", "derive_random_states", "(", "random_state", ",", "n", "=", "1", ")", ":", "seed_", "=", "random_state", ".", "randint", "(", "SEED_MIN_VALUE", ",", "SEED_MAX_VALUE", ",", "1", ")", "[", "0", "]", "return", "[", "new_random_state", "(", "seed_", "+", "i", ")", "for", "i", "in", "sm", ".", "xrange", "(", "n", ")", "]"], "docstring": "Create N new random states based on an existing random state or seed.\n\n    Parameters\n    ----------\n    random_state : numpy.random.RandomState\n        Random state or seed from which to derive new random states.\n\n    n : int, optional\n        Number of random states to derive.\n\n    Returns\n    -------\n    list of numpy.random.RandomState\n        Derived random states.", "docstring_tokens": ["Create", "N", "new", "random", "states", "based", "on", "an", "existing", "random", "state", "or", "seed", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L427-L446", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "_quokka_normalize_extract", "original_string": "def _quokka_normalize_extract(extract):\n    \"\"\"\n    Generate a normalized rectangle to be extract from the standard quokka image.\n\n    Parameters\n    ----------\n    extract : 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Unnormalized representation of the image subarea to be extracted.\n\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)``\n              will be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. (643, 960, *)). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    bb : imgaug.BoundingBox\n        Normalized representation of the area to extract from the standard quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n\n    if extract == \"square\":\n        bb = BoundingBox(x1=0, y1=0, x2=643, y2=643)\n    elif isinstance(extract, tuple) and len(extract) == 4:\n        bb = BoundingBox(x1=extract[0], y1=extract[1], x2=extract[2], y2=extract[3])\n    elif isinstance(extract, BoundingBox):\n        bb = extract\n    elif isinstance(extract, BoundingBoxesOnImage):\n        do_assert(len(extract.bounding_boxes) == 1)\n        do_assert(extract.shape[0:2] == (643, 960))\n        bb = extract.bounding_boxes[0]\n    else:\n        raise Exception(\n            \"Expected 'square' or tuple of four entries or BoundingBox or BoundingBoxesOnImage \"\n            + \"for parameter 'extract', got %s.\" % (type(extract),)\n        )\n    return bb", "language": "python", "code": "def _quokka_normalize_extract(extract):\n    \"\"\"\n    Generate a normalized rectangle to be extract from the standard quokka image.\n\n    Parameters\n    ----------\n    extract : 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Unnormalized representation of the image subarea to be extracted.\n\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)``\n              will be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. (643, 960, *)). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    bb : imgaug.BoundingBox\n        Normalized representation of the area to extract from the standard quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n\n    if extract == \"square\":\n        bb = BoundingBox(x1=0, y1=0, x2=643, y2=643)\n    elif isinstance(extract, tuple) and len(extract) == 4:\n        bb = BoundingBox(x1=extract[0], y1=extract[1], x2=extract[2], y2=extract[3])\n    elif isinstance(extract, BoundingBox):\n        bb = extract\n    elif isinstance(extract, BoundingBoxesOnImage):\n        do_assert(len(extract.bounding_boxes) == 1)\n        do_assert(extract.shape[0:2] == (643, 960))\n        bb = extract.bounding_boxes[0]\n    else:\n        raise Exception(\n            \"Expected 'square' or tuple of four entries or BoundingBox or BoundingBoxesOnImage \"\n            + \"for parameter 'extract', got %s.\" % (type(extract),)\n        )\n    return bb", "code_tokens": ["def", "_quokka_normalize_extract", "(", "extract", ")", ":", "# TODO get rid of this deferred import", "from", "imgaug", ".", "augmentables", ".", "bbs", "import", "BoundingBox", ",", "BoundingBoxesOnImage", "if", "extract", "==", "\"square\"", ":", "bb", "=", "BoundingBox", "(", "x1", "=", "0", ",", "y1", "=", "0", ",", "x2", "=", "643", ",", "y2", "=", "643", ")", "elif", "isinstance", "(", "extract", ",", "tuple", ")", "and", "len", "(", "extract", ")", "==", "4", ":", "bb", "=", "BoundingBox", "(", "x1", "=", "extract", "[", "0", "]", ",", "y1", "=", "extract", "[", "1", "]", ",", "x2", "=", "extract", "[", "2", "]", ",", "y2", "=", "extract", "[", "3", "]", ")", "elif", "isinstance", "(", "extract", ",", "BoundingBox", ")", ":", "bb", "=", "extract", "elif", "isinstance", "(", "extract", ",", "BoundingBoxesOnImage", ")", ":", "do_assert", "(", "len", "(", "extract", ".", "bounding_boxes", ")", "==", "1", ")", "do_assert", "(", "extract", ".", "shape", "[", "0", ":", "2", "]", "==", "(", "643", ",", "960", ")", ")", "bb", "=", "extract", ".", "bounding_boxes", "[", "0", "]", "else", ":", "raise", "Exception", "(", "\"Expected 'square' or tuple of four entries or BoundingBox or BoundingBoxesOnImage \"", "+", "\"for parameter 'extract', got %s.\"", "%", "(", "type", "(", "extract", ")", ",", ")", ")", "return", "bb"], "docstring": "Generate a normalized rectangle to be extract from the standard quokka image.\n\n    Parameters\n    ----------\n    extract : 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Unnormalized representation of the image subarea to be extracted.\n\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)``\n              will be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. (643, 960, *)). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    bb : imgaug.BoundingBox\n        Normalized representation of the area to extract from the standard quokka image.", "docstring_tokens": ["Generate", "a", "normalized", "rectangle", "to", "be", "extract", "from", "the", "standard", "quokka", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L464-L506", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "_compute_resized_shape", "original_string": "def _compute_resized_shape(from_shape, to_shape):\n    \"\"\"\n    Computes the intended new shape of an image-like array after resizing.\n\n    Parameters\n    ----------\n    from_shape : tuple or ndarray\n        Old shape of the array. Usually expected to be a tuple of form ``(H, W)`` or ``(H, W, C)`` or\n        alternatively an array with two or three dimensions.\n\n    to_shape : None or tuple of ints or tuple of floats or int or float or ndarray\n        New shape of the array.\n\n            * If None, then `from_shape` will be used as the new shape.\n            * If an int ``V``, then the new shape will be ``(V, V, [C])``, where ``C`` will be added if it\n              is part of `from_shape`.\n            * If a float ``V``, then the new shape will be ``(H*V, W*V, [C])``, where ``H`` and ``W`` are the old\n              height/width.\n            * If a tuple ``(H', W', [C'])`` of ints, then ``H'`` and ``W'`` will be used as the new height\n              and width.\n            * If a tuple ``(H', W', [C'])`` of floats (except ``C``), then ``H'`` and ``W'`` will\n              be used as the new height and width.\n            * If a numpy array, then the array's shape will be used.\n\n    Returns\n    -------\n    to_shape_computed : tuple of int\n        New shape.\n\n    \"\"\"\n    if is_np_array(from_shape):\n        from_shape = from_shape.shape\n    if is_np_array(to_shape):\n        to_shape = to_shape.shape\n\n    to_shape_computed = list(from_shape)\n\n    if to_shape is None:\n        pass\n    elif isinstance(to_shape, tuple):\n        do_assert(len(from_shape) in [2, 3])\n        do_assert(len(to_shape) in [2, 3])\n\n        if len(from_shape) == 3 and len(to_shape) == 3:\n            do_assert(from_shape[2] == to_shape[2])\n        elif len(to_shape) == 3:\n            to_shape_computed.append(to_shape[2])\n\n        do_assert(all([v is None or is_single_number(v) for v in to_shape[0:2]]),\n                  \"Expected the first two entries in to_shape to be None or numbers, \"\n                  + \"got types %s.\" % (str([type(v) for v in to_shape[0:2]]),))\n\n        for i, from_shape_i in enumerate(from_shape[0:2]):\n            if to_shape[i] is None:\n                to_shape_computed[i] = from_shape_i\n            elif is_single_integer(to_shape[i]):\n                to_shape_computed[i] = to_shape[i]\n            else:  # float\n                to_shape_computed[i] = int(np.round(from_shape_i * to_shape[i]))\n    elif is_single_integer(to_shape) or is_single_float(to_shape):\n        to_shape_computed = _compute_resized_shape(from_shape, (to_shape, to_shape))\n    else:\n        raise Exception(\"Expected to_shape to be None or ndarray or tuple of floats or tuple of ints or single int \"\n                        + \"or single float, got %s.\" % (type(to_shape),))\n\n    return tuple(to_shape_computed)", "language": "python", "code": "def _compute_resized_shape(from_shape, to_shape):\n    \"\"\"\n    Computes the intended new shape of an image-like array after resizing.\n\n    Parameters\n    ----------\n    from_shape : tuple or ndarray\n        Old shape of the array. Usually expected to be a tuple of form ``(H, W)`` or ``(H, W, C)`` or\n        alternatively an array with two or three dimensions.\n\n    to_shape : None or tuple of ints or tuple of floats or int or float or ndarray\n        New shape of the array.\n\n            * If None, then `from_shape` will be used as the new shape.\n            * If an int ``V``, then the new shape will be ``(V, V, [C])``, where ``C`` will be added if it\n              is part of `from_shape`.\n            * If a float ``V``, then the new shape will be ``(H*V, W*V, [C])``, where ``H`` and ``W`` are the old\n              height/width.\n            * If a tuple ``(H', W', [C'])`` of ints, then ``H'`` and ``W'`` will be used as the new height\n              and width.\n            * If a tuple ``(H', W', [C'])`` of floats (except ``C``), then ``H'`` and ``W'`` will\n              be used as the new height and width.\n            * If a numpy array, then the array's shape will be used.\n\n    Returns\n    -------\n    to_shape_computed : tuple of int\n        New shape.\n\n    \"\"\"\n    if is_np_array(from_shape):\n        from_shape = from_shape.shape\n    if is_np_array(to_shape):\n        to_shape = to_shape.shape\n\n    to_shape_computed = list(from_shape)\n\n    if to_shape is None:\n        pass\n    elif isinstance(to_shape, tuple):\n        do_assert(len(from_shape) in [2, 3])\n        do_assert(len(to_shape) in [2, 3])\n\n        if len(from_shape) == 3 and len(to_shape) == 3:\n            do_assert(from_shape[2] == to_shape[2])\n        elif len(to_shape) == 3:\n            to_shape_computed.append(to_shape[2])\n\n        do_assert(all([v is None or is_single_number(v) for v in to_shape[0:2]]),\n                  \"Expected the first two entries in to_shape to be None or numbers, \"\n                  + \"got types %s.\" % (str([type(v) for v in to_shape[0:2]]),))\n\n        for i, from_shape_i in enumerate(from_shape[0:2]):\n            if to_shape[i] is None:\n                to_shape_computed[i] = from_shape_i\n            elif is_single_integer(to_shape[i]):\n                to_shape_computed[i] = to_shape[i]\n            else:  # float\n                to_shape_computed[i] = int(np.round(from_shape_i * to_shape[i]))\n    elif is_single_integer(to_shape) or is_single_float(to_shape):\n        to_shape_computed = _compute_resized_shape(from_shape, (to_shape, to_shape))\n    else:\n        raise Exception(\"Expected to_shape to be None or ndarray or tuple of floats or tuple of ints or single int \"\n                        + \"or single float, got %s.\" % (type(to_shape),))\n\n    return tuple(to_shape_computed)", "code_tokens": ["def", "_compute_resized_shape", "(", "from_shape", ",", "to_shape", ")", ":", "if", "is_np_array", "(", "from_shape", ")", ":", "from_shape", "=", "from_shape", ".", "shape", "if", "is_np_array", "(", "to_shape", ")", ":", "to_shape", "=", "to_shape", ".", "shape", "to_shape_computed", "=", "list", "(", "from_shape", ")", "if", "to_shape", "is", "None", ":", "pass", "elif", "isinstance", "(", "to_shape", ",", "tuple", ")", ":", "do_assert", "(", "len", "(", "from_shape", ")", "in", "[", "2", ",", "3", "]", ")", "do_assert", "(", "len", "(", "to_shape", ")", "in", "[", "2", ",", "3", "]", ")", "if", "len", "(", "from_shape", ")", "==", "3", "and", "len", "(", "to_shape", ")", "==", "3", ":", "do_assert", "(", "from_shape", "[", "2", "]", "==", "to_shape", "[", "2", "]", ")", "elif", "len", "(", "to_shape", ")", "==", "3", ":", "to_shape_computed", ".", "append", "(", "to_shape", "[", "2", "]", ")", "do_assert", "(", "all", "(", "[", "v", "is", "None", "or", "is_single_number", "(", "v", ")", "for", "v", "in", "to_shape", "[", "0", ":", "2", "]", "]", ")", ",", "\"Expected the first two entries in to_shape to be None or numbers, \"", "+", "\"got types %s.\"", "%", "(", "str", "(", "[", "type", "(", "v", ")", "for", "v", "in", "to_shape", "[", "0", ":", "2", "]", "]", ")", ",", ")", ")", "for", "i", ",", "from_shape_i", "in", "enumerate", "(", "from_shape", "[", "0", ":", "2", "]", ")", ":", "if", "to_shape", "[", "i", "]", "is", "None", ":", "to_shape_computed", "[", "i", "]", "=", "from_shape_i", "elif", "is_single_integer", "(", "to_shape", "[", "i", "]", ")", ":", "to_shape_computed", "[", "i", "]", "=", "to_shape", "[", "i", "]", "else", ":", "# float", "to_shape_computed", "[", "i", "]", "=", "int", "(", "np", ".", "round", "(", "from_shape_i", "*", "to_shape", "[", "i", "]", ")", ")", "elif", "is_single_integer", "(", "to_shape", ")", "or", "is_single_float", "(", "to_shape", ")", ":", "to_shape_computed", "=", "_compute_resized_shape", "(", "from_shape", ",", "(", "to_shape", ",", "to_shape", ")", ")", "else", ":", "raise", "Exception", "(", "\"Expected to_shape to be None or ndarray or tuple of floats or tuple of ints or single int \"", "+", "\"or single float, got %s.\"", "%", "(", "type", "(", "to_shape", ")", ",", ")", ")", "return", "tuple", "(", "to_shape_computed", ")"], "docstring": "Computes the intended new shape of an image-like array after resizing.\n\n    Parameters\n    ----------\n    from_shape : tuple or ndarray\n        Old shape of the array. Usually expected to be a tuple of form ``(H, W)`` or ``(H, W, C)`` or\n        alternatively an array with two or three dimensions.\n\n    to_shape : None or tuple of ints or tuple of floats or int or float or ndarray\n        New shape of the array.\n\n            * If None, then `from_shape` will be used as the new shape.\n            * If an int ``V``, then the new shape will be ``(V, V, [C])``, where ``C`` will be added if it\n              is part of `from_shape`.\n            * If a float ``V``, then the new shape will be ``(H*V, W*V, [C])``, where ``H`` and ``W`` are the old\n              height/width.\n            * If a tuple ``(H', W', [C'])`` of ints, then ``H'`` and ``W'`` will be used as the new height\n              and width.\n            * If a tuple ``(H', W', [C'])`` of floats (except ``C``), then ``H'`` and ``W'`` will\n              be used as the new height and width.\n            * If a numpy array, then the array's shape will be used.\n\n    Returns\n    -------\n    to_shape_computed : tuple of int\n        New shape.", "docstring_tokens": ["Computes", "the", "intended", "new", "shape", "of", "an", "image", "-", "like", "array", "after", "resizing", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L509-L574", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "quokka", "original_string": "def quokka(size=None, extract=None):\n    \"\"\"\n    Returns an image of a quokka as a numpy array.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        Size of the output image. Input into :func:`imgaug.imgaug.imresize_single_image`.\n        Usually expected to be a tuple ``(H, W)``, where ``H`` is the desired height\n        and ``W`` is the width. If None, then the image will not be resized.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea of the quokka image to extract:\n\n            * If None, then the whole image will be used.\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)`` will\n              be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. ``(643, 960, *)``). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    img : (H,W,3) ndarray\n        The image array of dtype uint8.\n\n    \"\"\"\n    img = imageio.imread(QUOKKA_FP, pilmode=\"RGB\")\n    if extract is not None:\n        bb = _quokka_normalize_extract(extract)\n        img = bb.extract_from_image(img)\n    if size is not None:\n        shape_resized = _compute_resized_shape(img.shape, size)\n        img = imresize_single_image(img, shape_resized[0:2])\n    return img", "language": "python", "code": "def quokka(size=None, extract=None):\n    \"\"\"\n    Returns an image of a quokka as a numpy array.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        Size of the output image. Input into :func:`imgaug.imgaug.imresize_single_image`.\n        Usually expected to be a tuple ``(H, W)``, where ``H`` is the desired height\n        and ``W`` is the width. If None, then the image will not be resized.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea of the quokka image to extract:\n\n            * If None, then the whole image will be used.\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)`` will\n              be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. ``(643, 960, *)``). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    img : (H,W,3) ndarray\n        The image array of dtype uint8.\n\n    \"\"\"\n    img = imageio.imread(QUOKKA_FP, pilmode=\"RGB\")\n    if extract is not None:\n        bb = _quokka_normalize_extract(extract)\n        img = bb.extract_from_image(img)\n    if size is not None:\n        shape_resized = _compute_resized_shape(img.shape, size)\n        img = imresize_single_image(img, shape_resized[0:2])\n    return img", "code_tokens": ["def", "quokka", "(", "size", "=", "None", ",", "extract", "=", "None", ")", ":", "img", "=", "imageio", ".", "imread", "(", "QUOKKA_FP", ",", "pilmode", "=", "\"RGB\"", ")", "if", "extract", "is", "not", "None", ":", "bb", "=", "_quokka_normalize_extract", "(", "extract", ")", "img", "=", "bb", ".", "extract_from_image", "(", "img", ")", "if", "size", "is", "not", "None", ":", "shape_resized", "=", "_compute_resized_shape", "(", "img", ".", "shape", ",", "size", ")", "img", "=", "imresize_single_image", "(", "img", ",", "shape_resized", "[", "0", ":", "2", "]", ")", "return", "img"], "docstring": "Returns an image of a quokka as a numpy array.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        Size of the output image. Input into :func:`imgaug.imgaug.imresize_single_image`.\n        Usually expected to be a tuple ``(H, W)``, where ``H`` is the desired height\n        and ``W`` is the width. If None, then the image will not be resized.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea of the quokka image to extract:\n\n            * If None, then the whole image will be used.\n            * If string ``square``, then a squared area ``(x: 0 to max 643, y: 0 to max 643)`` will\n              be extracted from the image.\n            * If a tuple, then expected to contain four numbers denoting ``x1``, ``y1``, ``x2``\n              and ``y2``.\n            * If a BoundingBox, then that bounding box's area will be extracted from the image.\n            * If a BoundingBoxesOnImage, then expected to contain exactly one bounding box\n              and a shape matching the full image dimensions (i.e. ``(643, 960, *)``). Then the\n              one bounding box will be used similar to BoundingBox.\n\n    Returns\n    -------\n    img : (H,W,3) ndarray\n        The image array of dtype uint8.", "docstring_tokens": ["Returns", "an", "image", "of", "a", "quokka", "as", "a", "numpy", "array", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L577-L614", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "quokka_segmentation_map", "original_string": "def quokka_segmentation_map(size=None, extract=None):\n    \"\"\"\n    Returns a segmentation map for the standard example quokka image.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        See :func:`imgaug.quokka`.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    result : imgaug.SegmentationMapOnImage\n        Segmentation map object.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.segmaps import SegmentationMapOnImage\n\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n\n    xx = []\n    yy = []\n    for kp_dict in json_dict[\"polygons\"][0][\"keypoints\"]:\n        x = kp_dict[\"x\"]\n        y = kp_dict[\"y\"]\n        xx.append(x)\n        yy.append(y)\n\n    img_seg = np.zeros((643, 960, 1), dtype=np.float32)\n    rr, cc = skimage.draw.polygon(np.array(yy), np.array(xx), shape=img_seg.shape)\n    img_seg[rr, cc] = 1.0\n\n    if extract is not None:\n        bb = _quokka_normalize_extract(extract)\n        img_seg = bb.extract_from_image(img_seg)\n\n    segmap = SegmentationMapOnImage(img_seg, shape=img_seg.shape[0:2] + (3,))\n\n    if size is not None:\n        shape_resized = _compute_resized_shape(img_seg.shape, size)\n        segmap = segmap.resize(shape_resized[0:2])\n        segmap.shape = tuple(shape_resized[0:2]) + (3,)\n\n    return segmap", "language": "python", "code": "def quokka_segmentation_map(size=None, extract=None):\n    \"\"\"\n    Returns a segmentation map for the standard example quokka image.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        See :func:`imgaug.quokka`.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    result : imgaug.SegmentationMapOnImage\n        Segmentation map object.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.segmaps import SegmentationMapOnImage\n\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n\n    xx = []\n    yy = []\n    for kp_dict in json_dict[\"polygons\"][0][\"keypoints\"]:\n        x = kp_dict[\"x\"]\n        y = kp_dict[\"y\"]\n        xx.append(x)\n        yy.append(y)\n\n    img_seg = np.zeros((643, 960, 1), dtype=np.float32)\n    rr, cc = skimage.draw.polygon(np.array(yy), np.array(xx), shape=img_seg.shape)\n    img_seg[rr, cc] = 1.0\n\n    if extract is not None:\n        bb = _quokka_normalize_extract(extract)\n        img_seg = bb.extract_from_image(img_seg)\n\n    segmap = SegmentationMapOnImage(img_seg, shape=img_seg.shape[0:2] + (3,))\n\n    if size is not None:\n        shape_resized = _compute_resized_shape(img_seg.shape, size)\n        segmap = segmap.resize(shape_resized[0:2])\n        segmap.shape = tuple(shape_resized[0:2]) + (3,)\n\n    return segmap", "code_tokens": ["def", "quokka_segmentation_map", "(", "size", "=", "None", ",", "extract", "=", "None", ")", ":", "# TODO get rid of this deferred import", "from", "imgaug", ".", "augmentables", ".", "segmaps", "import", "SegmentationMapOnImage", "with", "open", "(", "QUOKKA_ANNOTATIONS_FP", ",", "\"r\"", ")", "as", "f", ":", "json_dict", "=", "json", ".", "load", "(", "f", ")", "xx", "=", "[", "]", "yy", "=", "[", "]", "for", "kp_dict", "in", "json_dict", "[", "\"polygons\"", "]", "[", "0", "]", "[", "\"keypoints\"", "]", ":", "x", "=", "kp_dict", "[", "\"x\"", "]", "y", "=", "kp_dict", "[", "\"y\"", "]", "xx", ".", "append", "(", "x", ")", "yy", ".", "append", "(", "y", ")", "img_seg", "=", "np", ".", "zeros", "(", "(", "643", ",", "960", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "rr", ",", "cc", "=", "skimage", ".", "draw", ".", "polygon", "(", "np", ".", "array", "(", "yy", ")", ",", "np", ".", "array", "(", "xx", ")", ",", "shape", "=", "img_seg", ".", "shape", ")", "img_seg", "[", "rr", ",", "cc", "]", "=", "1.0", "if", "extract", "is", "not", "None", ":", "bb", "=", "_quokka_normalize_extract", "(", "extract", ")", "img_seg", "=", "bb", ".", "extract_from_image", "(", "img_seg", ")", "segmap", "=", "SegmentationMapOnImage", "(", "img_seg", ",", "shape", "=", "img_seg", ".", "shape", "[", "0", ":", "2", "]", "+", "(", "3", ",", ")", ")", "if", "size", "is", "not", "None", ":", "shape_resized", "=", "_compute_resized_shape", "(", "img_seg", ".", "shape", ",", "size", ")", "segmap", "=", "segmap", ".", "resize", "(", "shape_resized", "[", "0", ":", "2", "]", ")", "segmap", ".", "shape", "=", "tuple", "(", "shape_resized", "[", "0", ":", "2", "]", ")", "+", "(", "3", ",", ")", "return", "segmap"], "docstring": "Returns a segmentation map for the standard example quokka image.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int, optional\n        See :func:`imgaug.quokka`.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    result : imgaug.SegmentationMapOnImage\n        Segmentation map object.", "docstring_tokens": ["Returns", "a", "segmentation", "map", "for", "the", "standard", "example", "quokka", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L678-L725", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "quokka_keypoints", "original_string": "def quokka_keypoints(size=None, extract=None):\n    \"\"\"\n    Returns example keypoints on the standard example quokke image.\n\n    The keypoints cover the eyes, ears, nose and paws.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the keypoints are placed. If None, then the keypoints\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    kpsoi : imgaug.KeypointsOnImage\n        Example keypoints on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    keypoints = []\n    for kp_dict in json_dict[\"keypoints\"]:\n        keypoints.append(Keypoint(x=kp_dict[\"x\"] - left, y=kp_dict[\"y\"] - top))\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    kpsoi = KeypointsOnImage(keypoints, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        kpsoi = kpsoi.on(shape_resized)\n    return kpsoi", "language": "python", "code": "def quokka_keypoints(size=None, extract=None):\n    \"\"\"\n    Returns example keypoints on the standard example quokke image.\n\n    The keypoints cover the eyes, ears, nose and paws.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the keypoints are placed. If None, then the keypoints\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    kpsoi : imgaug.KeypointsOnImage\n        Example keypoints on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    keypoints = []\n    for kp_dict in json_dict[\"keypoints\"]:\n        keypoints.append(Keypoint(x=kp_dict[\"x\"] - left, y=kp_dict[\"y\"] - top))\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    kpsoi = KeypointsOnImage(keypoints, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        kpsoi = kpsoi.on(shape_resized)\n    return kpsoi", "code_tokens": ["def", "quokka_keypoints", "(", "size", "=", "None", ",", "extract", "=", "None", ")", ":", "# TODO get rid of this deferred import", "from", "imgaug", ".", "augmentables", ".", "kps", "import", "Keypoint", ",", "KeypointsOnImage", "left", ",", "top", "=", "0", ",", "0", "if", "extract", "is", "not", "None", ":", "bb_extract", "=", "_quokka_normalize_extract", "(", "extract", ")", "left", "=", "bb_extract", ".", "x1", "top", "=", "bb_extract", ".", "y1", "with", "open", "(", "QUOKKA_ANNOTATIONS_FP", ",", "\"r\"", ")", "as", "f", ":", "json_dict", "=", "json", ".", "load", "(", "f", ")", "keypoints", "=", "[", "]", "for", "kp_dict", "in", "json_dict", "[", "\"keypoints\"", "]", ":", "keypoints", ".", "append", "(", "Keypoint", "(", "x", "=", "kp_dict", "[", "\"x\"", "]", "-", "left", ",", "y", "=", "kp_dict", "[", "\"y\"", "]", "-", "top", ")", ")", "if", "extract", "is", "not", "None", ":", "shape", "=", "(", "bb_extract", ".", "height", ",", "bb_extract", ".", "width", ",", "3", ")", "else", ":", "shape", "=", "(", "643", ",", "960", ",", "3", ")", "kpsoi", "=", "KeypointsOnImage", "(", "keypoints", ",", "shape", "=", "shape", ")", "if", "size", "is", "not", "None", ":", "shape_resized", "=", "_compute_resized_shape", "(", "shape", ",", "size", ")", "kpsoi", "=", "kpsoi", ".", "on", "(", "shape_resized", ")", "return", "kpsoi"], "docstring": "Returns example keypoints on the standard example quokke image.\n\n    The keypoints cover the eyes, ears, nose and paws.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the keypoints are placed. If None, then the keypoints\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    kpsoi : imgaug.KeypointsOnImage\n        Example keypoints on the quokka image.", "docstring_tokens": ["Returns", "example", "keypoints", "on", "the", "standard", "example", "quokke", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L728-L771", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "quokka_bounding_boxes", "original_string": "def quokka_bounding_boxes(size=None, extract=None):\n    \"\"\"\n    Returns example bounding boxes on the standard example quokke image.\n\n    Currently only a single bounding box is returned that covers the quokka.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the BBs are placed. If None, then the BBs\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    bbsoi : imgaug.BoundingBoxesOnImage\n        Example BBs on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    bbs = []\n    for bb_dict in json_dict[\"bounding_boxes\"]:\n        bbs.append(\n            BoundingBox(\n                x1=bb_dict[\"x1\"] - left,\n                y1=bb_dict[\"y1\"] - top,\n                x2=bb_dict[\"x2\"] - left,\n                y2=bb_dict[\"y2\"] - top\n            )\n        )\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    bbsoi = BoundingBoxesOnImage(bbs, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        bbsoi = bbsoi.on(shape_resized)\n    return bbsoi", "language": "python", "code": "def quokka_bounding_boxes(size=None, extract=None):\n    \"\"\"\n    Returns example bounding boxes on the standard example quokke image.\n\n    Currently only a single bounding box is returned that covers the quokka.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the BBs are placed. If None, then the BBs\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    bbsoi : imgaug.BoundingBoxesOnImage\n        Example BBs on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    bbs = []\n    for bb_dict in json_dict[\"bounding_boxes\"]:\n        bbs.append(\n            BoundingBox(\n                x1=bb_dict[\"x1\"] - left,\n                y1=bb_dict[\"y1\"] - top,\n                x2=bb_dict[\"x2\"] - left,\n                y2=bb_dict[\"y2\"] - top\n            )\n        )\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    bbsoi = BoundingBoxesOnImage(bbs, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        bbsoi = bbsoi.on(shape_resized)\n    return bbsoi", "code_tokens": ["def", "quokka_bounding_boxes", "(", "size", "=", "None", ",", "extract", "=", "None", ")", ":", "# TODO get rid of this deferred import", "from", "imgaug", ".", "augmentables", ".", "bbs", "import", "BoundingBox", ",", "BoundingBoxesOnImage", "left", ",", "top", "=", "0", ",", "0", "if", "extract", "is", "not", "None", ":", "bb_extract", "=", "_quokka_normalize_extract", "(", "extract", ")", "left", "=", "bb_extract", ".", "x1", "top", "=", "bb_extract", ".", "y1", "with", "open", "(", "QUOKKA_ANNOTATIONS_FP", ",", "\"r\"", ")", "as", "f", ":", "json_dict", "=", "json", ".", "load", "(", "f", ")", "bbs", "=", "[", "]", "for", "bb_dict", "in", "json_dict", "[", "\"bounding_boxes\"", "]", ":", "bbs", ".", "append", "(", "BoundingBox", "(", "x1", "=", "bb_dict", "[", "\"x1\"", "]", "-", "left", ",", "y1", "=", "bb_dict", "[", "\"y1\"", "]", "-", "top", ",", "x2", "=", "bb_dict", "[", "\"x2\"", "]", "-", "left", ",", "y2", "=", "bb_dict", "[", "\"y2\"", "]", "-", "top", ")", ")", "if", "extract", "is", "not", "None", ":", "shape", "=", "(", "bb_extract", ".", "height", ",", "bb_extract", ".", "width", ",", "3", ")", "else", ":", "shape", "=", "(", "643", ",", "960", ",", "3", ")", "bbsoi", "=", "BoundingBoxesOnImage", "(", "bbs", ",", "shape", "=", "shape", ")", "if", "size", "is", "not", "None", ":", "shape_resized", "=", "_compute_resized_shape", "(", "shape", ",", "size", ")", "bbsoi", "=", "bbsoi", ".", "on", "(", "shape_resized", ")", "return", "bbsoi"], "docstring": "Returns example bounding boxes on the standard example quokke image.\n\n    Currently only a single bounding box is returned that covers the quokka.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the BBs are placed. If None, then the BBs\n        are not projected to any new size (positions on the original image are used).\n        Floats lead to relative size changes, ints to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    bbsoi : imgaug.BoundingBoxesOnImage\n        Example BBs on the quokka image.", "docstring_tokens": ["Returns", "example", "bounding", "boxes", "on", "the", "standard", "example", "quokke", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L774-L824", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "quokka_polygons", "original_string": "def quokka_polygons(size=None, extract=None):\n    \"\"\"\n    Returns example polygons on the standard example quokke image.\n\n    The result contains one polygon, covering the quokka's outline.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the polygons are placed. If None,\n        then the polygons are not projected to any new size (positions on the\n        original image are used). Floats lead to relative size changes, ints\n        to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or \\\n              imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    psoi : imgaug.PolygonsOnImage\n        Example polygons on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.polys import Polygon, PolygonsOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    polygons = []\n    for poly_json in json_dict[\"polygons\"]:\n        polygons.append(\n            Polygon([(point[\"x\"] - left, point[\"y\"] - top)\n                    for point in poly_json[\"keypoints\"]])\n        )\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    psoi = PolygonsOnImage(polygons, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        psoi = psoi.on(shape_resized)\n    return psoi", "language": "python", "code": "def quokka_polygons(size=None, extract=None):\n    \"\"\"\n    Returns example polygons on the standard example quokke image.\n\n    The result contains one polygon, covering the quokka's outline.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the polygons are placed. If None,\n        then the polygons are not projected to any new size (positions on the\n        original image are used). Floats lead to relative size changes, ints\n        to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or \\\n              imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    psoi : imgaug.PolygonsOnImage\n        Example polygons on the quokka image.\n\n    \"\"\"\n    # TODO get rid of this deferred import\n    from imgaug.augmentables.polys import Polygon, PolygonsOnImage\n\n    left, top = 0, 0\n    if extract is not None:\n        bb_extract = _quokka_normalize_extract(extract)\n        left = bb_extract.x1\n        top = bb_extract.y1\n    with open(QUOKKA_ANNOTATIONS_FP, \"r\") as f:\n        json_dict = json.load(f)\n    polygons = []\n    for poly_json in json_dict[\"polygons\"]:\n        polygons.append(\n            Polygon([(point[\"x\"] - left, point[\"y\"] - top)\n                    for point in poly_json[\"keypoints\"]])\n        )\n    if extract is not None:\n        shape = (bb_extract.height, bb_extract.width, 3)\n    else:\n        shape = (643, 960, 3)\n    psoi = PolygonsOnImage(polygons, shape=shape)\n    if size is not None:\n        shape_resized = _compute_resized_shape(shape, size)\n        psoi = psoi.on(shape_resized)\n    return psoi", "code_tokens": ["def", "quokka_polygons", "(", "size", "=", "None", ",", "extract", "=", "None", ")", ":", "# TODO get rid of this deferred import", "from", "imgaug", ".", "augmentables", ".", "polys", "import", "Polygon", ",", "PolygonsOnImage", "left", ",", "top", "=", "0", ",", "0", "if", "extract", "is", "not", "None", ":", "bb_extract", "=", "_quokka_normalize_extract", "(", "extract", ")", "left", "=", "bb_extract", ".", "x1", "top", "=", "bb_extract", ".", "y1", "with", "open", "(", "QUOKKA_ANNOTATIONS_FP", ",", "\"r\"", ")", "as", "f", ":", "json_dict", "=", "json", ".", "load", "(", "f", ")", "polygons", "=", "[", "]", "for", "poly_json", "in", "json_dict", "[", "\"polygons\"", "]", ":", "polygons", ".", "append", "(", "Polygon", "(", "[", "(", "point", "[", "\"x\"", "]", "-", "left", ",", "point", "[", "\"y\"", "]", "-", "top", ")", "for", "point", "in", "poly_json", "[", "\"keypoints\"", "]", "]", ")", ")", "if", "extract", "is", "not", "None", ":", "shape", "=", "(", "bb_extract", ".", "height", ",", "bb_extract", ".", "width", ",", "3", ")", "else", ":", "shape", "=", "(", "643", ",", "960", ",", "3", ")", "psoi", "=", "PolygonsOnImage", "(", "polygons", ",", "shape", "=", "shape", ")", "if", "size", "is", "not", "None", ":", "shape_resized", "=", "_compute_resized_shape", "(", "shape", ",", "size", ")", "psoi", "=", "psoi", ".", "on", "(", "shape_resized", ")", "return", "psoi"], "docstring": "Returns example polygons on the standard example quokke image.\n\n    The result contains one polygon, covering the quokka's outline.\n\n    Parameters\n    ----------\n    size : None or float or tuple of int or tuple of float, optional\n        Size of the output image on which the polygons are placed. If None,\n        then the polygons are not projected to any new size (positions on the\n        original image are used). Floats lead to relative size changes, ints\n        to absolute sizes in pixels.\n\n    extract : None or 'square' or tuple of number or imgaug.BoundingBox or \\\n              imgaug.BoundingBoxesOnImage\n        Subarea to extract from the image. See :func:`imgaug.quokka`.\n\n    Returns\n    -------\n    psoi : imgaug.PolygonsOnImage\n        Example polygons on the quokka image.", "docstring_tokens": ["Returns", "example", "polygons", "on", "the", "standard", "example", "quokke", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L827-L875", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "angle_between_vectors", "original_string": "def angle_between_vectors(v1, v2):\n    \"\"\"\n    Returns the angle in radians between vectors `v1` and `v2`.\n\n    From http://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python\n\n    Parameters\n    ----------\n    v1 : (N,) ndarray\n        First vector.\n\n    v2 : (N,) ndarray\n        Second vector.\n\n    Returns\n    -------\n    out : float\n        Angle in radians.\n\n    Examples\n    --------\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([0, 1, 0]))\n    1.570796...\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([1, 0, 0]))\n    0.0\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([-1, 0, 0]))\n    3.141592...\n\n    \"\"\"\n    l1 = np.linalg.norm(v1)\n    l2 = np.linalg.norm(v2)\n    v1_u = (v1 / l1) if l1 > 0 else np.float32(v1) * 0\n    v2_u = (v2 / l2) if l2 > 0 else np.float32(v2) * 0\n    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))", "language": "python", "code": "def angle_between_vectors(v1, v2):\n    \"\"\"\n    Returns the angle in radians between vectors `v1` and `v2`.\n\n    From http://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python\n\n    Parameters\n    ----------\n    v1 : (N,) ndarray\n        First vector.\n\n    v2 : (N,) ndarray\n        Second vector.\n\n    Returns\n    -------\n    out : float\n        Angle in radians.\n\n    Examples\n    --------\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([0, 1, 0]))\n    1.570796...\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([1, 0, 0]))\n    0.0\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([-1, 0, 0]))\n    3.141592...\n\n    \"\"\"\n    l1 = np.linalg.norm(v1)\n    l2 = np.linalg.norm(v2)\n    v1_u = (v1 / l1) if l1 > 0 else np.float32(v1) * 0\n    v2_u = (v2 / l2) if l2 > 0 else np.float32(v2) * 0\n    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))", "code_tokens": ["def", "angle_between_vectors", "(", "v1", ",", "v2", ")", ":", "l1", "=", "np", ".", "linalg", ".", "norm", "(", "v1", ")", "l2", "=", "np", ".", "linalg", ".", "norm", "(", "v2", ")", "v1_u", "=", "(", "v1", "/", "l1", ")", "if", "l1", ">", "0", "else", "np", ".", "float32", "(", "v1", ")", "*", "0", "v2_u", "=", "(", "v2", "/", "l2", ")", "if", "l2", ">", "0", "else", "np", ".", "float32", "(", "v2", ")", "*", "0", "return", "np", ".", "arccos", "(", "np", ".", "clip", "(", "np", ".", "dot", "(", "v1_u", ",", "v2_u", ")", ",", "-", "1.0", ",", "1.0", ")", ")"], "docstring": "Returns the angle in radians between vectors `v1` and `v2`.\n\n    From http://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python\n\n    Parameters\n    ----------\n    v1 : (N,) ndarray\n        First vector.\n\n    v2 : (N,) ndarray\n        Second vector.\n\n    Returns\n    -------\n    out : float\n        Angle in radians.\n\n    Examples\n    --------\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([0, 1, 0]))\n    1.570796...\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([1, 0, 0]))\n    0.0\n\n    >>> angle_between_vectors(np.float32([1, 0, 0]), np.float32([-1, 0, 0]))\n    3.141592...", "docstring_tokens": ["Returns", "the", "angle", "in", "radians", "between", "vectors", "v1", "and", "v2", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L878-L913", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "compute_line_intersection_point", "original_string": "def compute_line_intersection_point(x1, y1, x2, y2, x3, y3, x4, y4):\n    \"\"\"\n    Compute the intersection point of two lines.\n\n    Taken from https://stackoverflow.com/a/20679579 .\n\n    Parameters\n    ----------\n    x1 : number\n        x coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    y1 : number\n        y coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    x2 : number\n        x coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    y2 : number\n        y coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    x3 : number\n        x coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    y3 : number\n        y coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    x4 : number\n        x coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    y4 : number\n        y coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    Returns\n    -------\n    tuple of number or bool\n        The coordinate of the intersection point as a tuple ``(x, y)``.\n        If the lines are parallel (no intersection point or an infinite number of them), the result is False.\n\n    \"\"\"\n    def _make_line(p1, p2):\n        A = (p1[1] - p2[1])\n        B = (p2[0] - p1[0])\n        C = (p1[0]*p2[1] - p2[0]*p1[1])\n        return A, B, -C\n\n    L1 = _make_line((x1, y1), (x2, y2))\n    L2 = _make_line((x3, y3), (x4, y4))\n\n    D = L1[0] * L2[1] - L1[1] * L2[0]\n    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n    if D != 0:\n        x = Dx / D\n        y = Dy / D\n        return x, y\n    else:\n        return False", "language": "python", "code": "def compute_line_intersection_point(x1, y1, x2, y2, x3, y3, x4, y4):\n    \"\"\"\n    Compute the intersection point of two lines.\n\n    Taken from https://stackoverflow.com/a/20679579 .\n\n    Parameters\n    ----------\n    x1 : number\n        x coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    y1 : number\n        y coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    x2 : number\n        x coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    y2 : number\n        y coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    x3 : number\n        x coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    y3 : number\n        y coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    x4 : number\n        x coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    y4 : number\n        y coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    Returns\n    -------\n    tuple of number or bool\n        The coordinate of the intersection point as a tuple ``(x, y)``.\n        If the lines are parallel (no intersection point or an infinite number of them), the result is False.\n\n    \"\"\"\n    def _make_line(p1, p2):\n        A = (p1[1] - p2[1])\n        B = (p2[0] - p1[0])\n        C = (p1[0]*p2[1] - p2[0]*p1[1])\n        return A, B, -C\n\n    L1 = _make_line((x1, y1), (x2, y2))\n    L2 = _make_line((x3, y3), (x4, y4))\n\n    D = L1[0] * L2[1] - L1[1] * L2[0]\n    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n    if D != 0:\n        x = Dx / D\n        y = Dy / D\n        return x, y\n    else:\n        return False", "code_tokens": ["def", "compute_line_intersection_point", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", ")", ":", "def", "_make_line", "(", "p1", ",", "p2", ")", ":", "A", "=", "(", "p1", "[", "1", "]", "-", "p2", "[", "1", "]", ")", "B", "=", "(", "p2", "[", "0", "]", "-", "p1", "[", "0", "]", ")", "C", "=", "(", "p1", "[", "0", "]", "*", "p2", "[", "1", "]", "-", "p2", "[", "0", "]", "*", "p1", "[", "1", "]", ")", "return", "A", ",", "B", ",", "-", "C", "L1", "=", "_make_line", "(", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ")", "L2", "=", "_make_line", "(", "(", "x3", ",", "y3", ")", ",", "(", "x4", ",", "y4", ")", ")", "D", "=", "L1", "[", "0", "]", "*", "L2", "[", "1", "]", "-", "L1", "[", "1", "]", "*", "L2", "[", "0", "]", "Dx", "=", "L1", "[", "2", "]", "*", "L2", "[", "1", "]", "-", "L1", "[", "1", "]", "*", "L2", "[", "2", "]", "Dy", "=", "L1", "[", "0", "]", "*", "L2", "[", "2", "]", "-", "L1", "[", "2", "]", "*", "L2", "[", "0", "]", "if", "D", "!=", "0", ":", "x", "=", "Dx", "/", "D", "y", "=", "Dy", "/", "D", "return", "x", ",", "y", "else", ":", "return", "False"], "docstring": "Compute the intersection point of two lines.\n\n    Taken from https://stackoverflow.com/a/20679579 .\n\n    Parameters\n    ----------\n    x1 : number\n        x coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    y1 : number\n        y coordinate of the first point on line 1. (The lines extends beyond this point.)\n\n    x2 : number\n        x coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    y2 : number\n        y coordinate of the second point on line 1. (The lines extends beyond this point.)\n\n    x3 : number\n        x coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    y3 : number\n        y coordinate of the first point on line 2. (The lines extends beyond this point.)\n\n    x4 : number\n        x coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    y4 : number\n        y coordinate of the second point on line 2. (The lines extends beyond this point.)\n\n    Returns\n    -------\n    tuple of number or bool\n        The coordinate of the intersection point as a tuple ``(x, y)``.\n        If the lines are parallel (no intersection point or an infinite number of them), the result is False.", "docstring_tokens": ["Compute", "the", "intersection", "point", "of", "two", "lines", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L917-L973", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "draw_text", "original_string": "def draw_text(img, y, x, text, color=(0, 255, 0), size=25):\n    \"\"\"\n    Draw text on an image.\n\n    This uses by default DejaVuSans as its font, which is included in this library.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: no\n        * ``uint32``: no\n        * ``uint64``: no\n        * ``int8``: no\n        * ``int16``: no\n        * ``int32``: no\n        * ``int64``: no\n        * ``float16``: no\n        * ``float32``: yes; not tested\n        * ``float64``: no\n        * ``float128``: no\n        * ``bool``: no\n\n        TODO check if other dtypes could be enabled\n\n    Parameters\n    ----------\n    img : (H,W,3) ndarray\n        The image array to draw text on.\n        Expected to be of dtype uint8 or float32 (value range 0.0 to 255.0).\n\n    y : int\n        x-coordinate of the top left corner of the text.\n\n    x : int\n        y- coordinate of the top left corner of the text.\n\n    text : str\n        The text to draw.\n\n    color : iterable of int, optional\n        Color of the text to draw. For RGB-images this is expected to be an RGB color.\n\n    size : int, optional\n        Font size of the text to draw.\n\n    Returns\n    -------\n    img_np : (H,W,3) ndarray\n        Input image with text drawn on it.\n\n    \"\"\"\n    do_assert(img.dtype in [np.uint8, np.float32])\n\n    input_dtype = img.dtype\n    if img.dtype == np.float32:\n        img = img.astype(np.uint8)\n\n    img = PIL_Image.fromarray(img)\n    font = PIL_ImageFont.truetype(DEFAULT_FONT_FP, size)\n    context = PIL_ImageDraw.Draw(img)\n    context.text((x, y), text, fill=tuple(color), font=font)\n    img_np = np.asarray(img)\n\n    # PIL/asarray returns read only array\n    if not img_np.flags[\"WRITEABLE\"]:\n        try:\n            # this seems to no longer work with np 1.16 (or was pillow updated?)\n            img_np.setflags(write=True)\n        except ValueError as ex:\n            if \"cannot set WRITEABLE flag to True of this array\" in str(ex):\n                img_np = np.copy(img_np)\n\n    if img_np.dtype != input_dtype:\n        img_np = img_np.astype(input_dtype)\n\n    return img_np", "language": "python", "code": "def draw_text(img, y, x, text, color=(0, 255, 0), size=25):\n    \"\"\"\n    Draw text on an image.\n\n    This uses by default DejaVuSans as its font, which is included in this library.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: no\n        * ``uint32``: no\n        * ``uint64``: no\n        * ``int8``: no\n        * ``int16``: no\n        * ``int32``: no\n        * ``int64``: no\n        * ``float16``: no\n        * ``float32``: yes; not tested\n        * ``float64``: no\n        * ``float128``: no\n        * ``bool``: no\n\n        TODO check if other dtypes could be enabled\n\n    Parameters\n    ----------\n    img : (H,W,3) ndarray\n        The image array to draw text on.\n        Expected to be of dtype uint8 or float32 (value range 0.0 to 255.0).\n\n    y : int\n        x-coordinate of the top left corner of the text.\n\n    x : int\n        y- coordinate of the top left corner of the text.\n\n    text : str\n        The text to draw.\n\n    color : iterable of int, optional\n        Color of the text to draw. For RGB-images this is expected to be an RGB color.\n\n    size : int, optional\n        Font size of the text to draw.\n\n    Returns\n    -------\n    img_np : (H,W,3) ndarray\n        Input image with text drawn on it.\n\n    \"\"\"\n    do_assert(img.dtype in [np.uint8, np.float32])\n\n    input_dtype = img.dtype\n    if img.dtype == np.float32:\n        img = img.astype(np.uint8)\n\n    img = PIL_Image.fromarray(img)\n    font = PIL_ImageFont.truetype(DEFAULT_FONT_FP, size)\n    context = PIL_ImageDraw.Draw(img)\n    context.text((x, y), text, fill=tuple(color), font=font)\n    img_np = np.asarray(img)\n\n    # PIL/asarray returns read only array\n    if not img_np.flags[\"WRITEABLE\"]:\n        try:\n            # this seems to no longer work with np 1.16 (or was pillow updated?)\n            img_np.setflags(write=True)\n        except ValueError as ex:\n            if \"cannot set WRITEABLE flag to True of this array\" in str(ex):\n                img_np = np.copy(img_np)\n\n    if img_np.dtype != input_dtype:\n        img_np = img_np.astype(input_dtype)\n\n    return img_np", "code_tokens": ["def", "draw_text", "(", "img", ",", "y", ",", "x", ",", "text", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "size", "=", "25", ")", ":", "do_assert", "(", "img", ".", "dtype", "in", "[", "np", ".", "uint8", ",", "np", ".", "float32", "]", ")", "input_dtype", "=", "img", ".", "dtype", "if", "img", ".", "dtype", "==", "np", ".", "float32", ":", "img", "=", "img", ".", "astype", "(", "np", ".", "uint8", ")", "img", "=", "PIL_Image", ".", "fromarray", "(", "img", ")", "font", "=", "PIL_ImageFont", ".", "truetype", "(", "DEFAULT_FONT_FP", ",", "size", ")", "context", "=", "PIL_ImageDraw", ".", "Draw", "(", "img", ")", "context", ".", "text", "(", "(", "x", ",", "y", ")", ",", "text", ",", "fill", "=", "tuple", "(", "color", ")", ",", "font", "=", "font", ")", "img_np", "=", "np", ".", "asarray", "(", "img", ")", "# PIL/asarray returns read only array", "if", "not", "img_np", ".", "flags", "[", "\"WRITEABLE\"", "]", ":", "try", ":", "# this seems to no longer work with np 1.16 (or was pillow updated?)", "img_np", ".", "setflags", "(", "write", "=", "True", ")", "except", "ValueError", "as", "ex", ":", "if", "\"cannot set WRITEABLE flag to True of this array\"", "in", "str", "(", "ex", ")", ":", "img_np", "=", "np", ".", "copy", "(", "img_np", ")", "if", "img_np", ".", "dtype", "!=", "input_dtype", ":", "img_np", "=", "img_np", ".", "astype", "(", "input_dtype", ")", "return", "img_np"], "docstring": "Draw text on an image.\n\n    This uses by default DejaVuSans as its font, which is included in this library.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: no\n        * ``uint32``: no\n        * ``uint64``: no\n        * ``int8``: no\n        * ``int16``: no\n        * ``int32``: no\n        * ``int64``: no\n        * ``float16``: no\n        * ``float32``: yes; not tested\n        * ``float64``: no\n        * ``float128``: no\n        * ``bool``: no\n\n        TODO check if other dtypes could be enabled\n\n    Parameters\n    ----------\n    img : (H,W,3) ndarray\n        The image array to draw text on.\n        Expected to be of dtype uint8 or float32 (value range 0.0 to 255.0).\n\n    y : int\n        x-coordinate of the top left corner of the text.\n\n    x : int\n        y- coordinate of the top left corner of the text.\n\n    text : str\n        The text to draw.\n\n    color : iterable of int, optional\n        Color of the text to draw. For RGB-images this is expected to be an RGB color.\n\n    size : int, optional\n        Font size of the text to draw.\n\n    Returns\n    -------\n    img_np : (H,W,3) ndarray\n        Input image with text drawn on it.", "docstring_tokens": ["Draw", "text", "on", "an", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L977-L1052", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "imresize_single_image", "original_string": "def imresize_single_image(image, sizes, interpolation=None):\n    \"\"\"\n    Resizes a single image.\n\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Parameters\n    ----------\n    image : (H,W,C) ndarray or (H,W) ndarray\n        Array of the image to resize.\n        Usually recommended to be of dtype uint8.\n\n    sizes : float or iterable of int or iterable of float\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    interpolation : None or str or int, optional\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Returns\n    -------\n    out : (H',W',C) ndarray or (H',W') ndarray\n        The resized image.\n\n    \"\"\"\n    grayscale = False\n    if image.ndim == 2:\n        grayscale = True\n        image = image[:, :, np.newaxis]\n    do_assert(len(image.shape) == 3, image.shape)\n    rs = imresize_many_images(image[np.newaxis, :, :, :], sizes, interpolation=interpolation)\n    if grayscale:\n        return np.squeeze(rs[0, :, :, 0])\n    else:\n        return rs[0, ...]", "language": "python", "code": "def imresize_single_image(image, sizes, interpolation=None):\n    \"\"\"\n    Resizes a single image.\n\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Parameters\n    ----------\n    image : (H,W,C) ndarray or (H,W) ndarray\n        Array of the image to resize.\n        Usually recommended to be of dtype uint8.\n\n    sizes : float or iterable of int or iterable of float\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    interpolation : None or str or int, optional\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Returns\n    -------\n    out : (H',W',C) ndarray or (H',W') ndarray\n        The resized image.\n\n    \"\"\"\n    grayscale = False\n    if image.ndim == 2:\n        grayscale = True\n        image = image[:, :, np.newaxis]\n    do_assert(len(image.shape) == 3, image.shape)\n    rs = imresize_many_images(image[np.newaxis, :, :, :], sizes, interpolation=interpolation)\n    if grayscale:\n        return np.squeeze(rs[0, :, :, 0])\n    else:\n        return rs[0, ...]", "code_tokens": ["def", "imresize_single_image", "(", "image", ",", "sizes", ",", "interpolation", "=", "None", ")", ":", "grayscale", "=", "False", "if", "image", ".", "ndim", "==", "2", ":", "grayscale", "=", "True", "image", "=", "image", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "do_assert", "(", "len", "(", "image", ".", "shape", ")", "==", "3", ",", "image", ".", "shape", ")", "rs", "=", "imresize_many_images", "(", "image", "[", "np", ".", "newaxis", ",", ":", ",", ":", ",", ":", "]", ",", "sizes", ",", "interpolation", "=", "interpolation", ")", "if", "grayscale", ":", "return", "np", ".", "squeeze", "(", "rs", "[", "0", ",", ":", ",", ":", ",", "0", "]", ")", "else", ":", "return", "rs", "[", "0", ",", "...", "]"], "docstring": "Resizes a single image.\n\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Parameters\n    ----------\n    image : (H,W,C) ndarray or (H,W) ndarray\n        Array of the image to resize.\n        Usually recommended to be of dtype uint8.\n\n    sizes : float or iterable of int or iterable of float\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    interpolation : None or str or int, optional\n        See :func:`imgaug.imgaug.imresize_many_images`.\n\n    Returns\n    -------\n    out : (H',W',C) ndarray or (H',W') ndarray\n        The resized image.", "docstring_tokens": ["Resizes", "a", "single", "image", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1257-L1293", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "compute_paddings_for_aspect_ratio", "original_string": "def compute_paddings_for_aspect_ratio(arr, aspect_ratio):\n    \"\"\"\n    Compute the amount of pixels by which an array has to be padded to fulfill an aspect ratio.\n\n    The aspect ratio is given as width/height.\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array for which to compute pad amounts.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    Returns\n    -------\n    result : tuple of int\n        Required paddign amounts to reach the target aspect ratio, given as a tuple\n        of the form ``(top, right, bottom, left)``.\n\n    \"\"\"\n    do_assert(arr.ndim in [2, 3])\n    do_assert(aspect_ratio > 0)\n    height, width = arr.shape[0:2]\n    do_assert(height > 0)\n    aspect_ratio_current = width / height\n\n    pad_top = 0\n    pad_right = 0\n    pad_bottom = 0\n    pad_left = 0\n\n    if aspect_ratio_current < aspect_ratio:\n        # vertical image, height > width\n        diff = (aspect_ratio * height) - width\n        pad_right = int(np.ceil(diff / 2))\n        pad_left = int(np.floor(diff / 2))\n    elif aspect_ratio_current > aspect_ratio:\n        # horizontal image, width > height\n        diff = ((1/aspect_ratio) * width) - height\n        pad_top = int(np.floor(diff / 2))\n        pad_bottom = int(np.ceil(diff / 2))\n\n    return pad_top, pad_right, pad_bottom, pad_left", "language": "python", "code": "def compute_paddings_for_aspect_ratio(arr, aspect_ratio):\n    \"\"\"\n    Compute the amount of pixels by which an array has to be padded to fulfill an aspect ratio.\n\n    The aspect ratio is given as width/height.\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array for which to compute pad amounts.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    Returns\n    -------\n    result : tuple of int\n        Required paddign amounts to reach the target aspect ratio, given as a tuple\n        of the form ``(top, right, bottom, left)``.\n\n    \"\"\"\n    do_assert(arr.ndim in [2, 3])\n    do_assert(aspect_ratio > 0)\n    height, width = arr.shape[0:2]\n    do_assert(height > 0)\n    aspect_ratio_current = width / height\n\n    pad_top = 0\n    pad_right = 0\n    pad_bottom = 0\n    pad_left = 0\n\n    if aspect_ratio_current < aspect_ratio:\n        # vertical image, height > width\n        diff = (aspect_ratio * height) - width\n        pad_right = int(np.ceil(diff / 2))\n        pad_left = int(np.floor(diff / 2))\n    elif aspect_ratio_current > aspect_ratio:\n        # horizontal image, width > height\n        diff = ((1/aspect_ratio) * width) - height\n        pad_top = int(np.floor(diff / 2))\n        pad_bottom = int(np.ceil(diff / 2))\n\n    return pad_top, pad_right, pad_bottom, pad_left", "code_tokens": ["def", "compute_paddings_for_aspect_ratio", "(", "arr", ",", "aspect_ratio", ")", ":", "do_assert", "(", "arr", ".", "ndim", "in", "[", "2", ",", "3", "]", ")", "do_assert", "(", "aspect_ratio", ">", "0", ")", "height", ",", "width", "=", "arr", ".", "shape", "[", "0", ":", "2", "]", "do_assert", "(", "height", ">", "0", ")", "aspect_ratio_current", "=", "width", "/", "height", "pad_top", "=", "0", "pad_right", "=", "0", "pad_bottom", "=", "0", "pad_left", "=", "0", "if", "aspect_ratio_current", "<", "aspect_ratio", ":", "# vertical image, height > width", "diff", "=", "(", "aspect_ratio", "*", "height", ")", "-", "width", "pad_right", "=", "int", "(", "np", ".", "ceil", "(", "diff", "/", "2", ")", ")", "pad_left", "=", "int", "(", "np", ".", "floor", "(", "diff", "/", "2", ")", ")", "elif", "aspect_ratio_current", ">", "aspect_ratio", ":", "# horizontal image, width > height", "diff", "=", "(", "(", "1", "/", "aspect_ratio", ")", "*", "width", ")", "-", "height", "pad_top", "=", "int", "(", "np", ".", "floor", "(", "diff", "/", "2", ")", ")", "pad_bottom", "=", "int", "(", "np", ".", "ceil", "(", "diff", "/", "2", ")", ")", "return", "pad_top", ",", "pad_right", ",", "pad_bottom", ",", "pad_left"], "docstring": "Compute the amount of pixels by which an array has to be padded to fulfill an aspect ratio.\n\n    The aspect ratio is given as width/height.\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array for which to compute pad amounts.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    Returns\n    -------\n    result : tuple of int\n        Required paddign amounts to reach the target aspect ratio, given as a tuple\n        of the form ``(top, right, bottom, left)``.", "docstring_tokens": ["Compute", "the", "amount", "of", "pixels", "by", "which", "an", "array", "has", "to", "be", "padded", "to", "fulfill", "an", "aspect", "ratio", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1426-L1473", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "pad_to_aspect_ratio", "original_string": "def pad_to_aspect_ratio(arr, aspect_ratio, mode=\"constant\", cval=0, return_pad_amounts=False):\n    \"\"\"\n    Pad an image-like array on its sides so that it matches a target aspect ratio.\n\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pad`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pad.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    mode : str, optional\n        Padding mode to use. See :func:`numpy.pad` for details.\n\n    cval : number, optional\n        Value to use for padding if `mode` is ``constant``. See :func:`numpy.pad` for details.\n\n    return_pad_amounts : bool, optional\n        If False, then only the padded image will be returned. If True, a tuple with two\n        entries will be returned, where the first entry is the padded image and the second\n        entry are the amounts by which each image side was padded. These amounts are again a\n        tuple of the form (top, right, bottom, left), with each value being an integer.\n\n    Returns\n    -------\n    arr_padded : (H',W') ndarray or (H',W',C) ndarray\n        Padded image as (H',W') or (H',W',C) ndarray, fulfulling the given aspect_ratio.\n\n    tuple of int\n        Amounts by which the image was padded on each side, given as a tuple ``(top, right, bottom, left)``.\n        This tuple is only returned if `return_pad_amounts` was set to True.\n        Otherwise only ``arr_padded`` is returned.\n\n    \"\"\"\n    pad_top, pad_right, pad_bottom, pad_left = compute_paddings_for_aspect_ratio(arr, aspect_ratio)\n    arr_padded = pad(\n        arr,\n        top=pad_top,\n        right=pad_right,\n        bottom=pad_bottom,\n        left=pad_left,\n        mode=mode,\n        cval=cval\n    )\n\n    if return_pad_amounts:\n        return arr_padded, (pad_top, pad_right, pad_bottom, pad_left)\n    else:\n        return arr_padded", "language": "python", "code": "def pad_to_aspect_ratio(arr, aspect_ratio, mode=\"constant\", cval=0, return_pad_amounts=False):\n    \"\"\"\n    Pad an image-like array on its sides so that it matches a target aspect ratio.\n\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pad`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pad.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    mode : str, optional\n        Padding mode to use. See :func:`numpy.pad` for details.\n\n    cval : number, optional\n        Value to use for padding if `mode` is ``constant``. See :func:`numpy.pad` for details.\n\n    return_pad_amounts : bool, optional\n        If False, then only the padded image will be returned. If True, a tuple with two\n        entries will be returned, where the first entry is the padded image and the second\n        entry are the amounts by which each image side was padded. These amounts are again a\n        tuple of the form (top, right, bottom, left), with each value being an integer.\n\n    Returns\n    -------\n    arr_padded : (H',W') ndarray or (H',W',C) ndarray\n        Padded image as (H',W') or (H',W',C) ndarray, fulfulling the given aspect_ratio.\n\n    tuple of int\n        Amounts by which the image was padded on each side, given as a tuple ``(top, right, bottom, left)``.\n        This tuple is only returned if `return_pad_amounts` was set to True.\n        Otherwise only ``arr_padded`` is returned.\n\n    \"\"\"\n    pad_top, pad_right, pad_bottom, pad_left = compute_paddings_for_aspect_ratio(arr, aspect_ratio)\n    arr_padded = pad(\n        arr,\n        top=pad_top,\n        right=pad_right,\n        bottom=pad_bottom,\n        left=pad_left,\n        mode=mode,\n        cval=cval\n    )\n\n    if return_pad_amounts:\n        return arr_padded, (pad_top, pad_right, pad_bottom, pad_left)\n    else:\n        return arr_padded", "code_tokens": ["def", "pad_to_aspect_ratio", "(", "arr", ",", "aspect_ratio", ",", "mode", "=", "\"constant\"", ",", "cval", "=", "0", ",", "return_pad_amounts", "=", "False", ")", ":", "pad_top", ",", "pad_right", ",", "pad_bottom", ",", "pad_left", "=", "compute_paddings_for_aspect_ratio", "(", "arr", ",", "aspect_ratio", ")", "arr_padded", "=", "pad", "(", "arr", ",", "top", "=", "pad_top", ",", "right", "=", "pad_right", ",", "bottom", "=", "pad_bottom", ",", "left", "=", "pad_left", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "if", "return_pad_amounts", ":", "return", "arr_padded", ",", "(", "pad_top", ",", "pad_right", ",", "pad_bottom", ",", "pad_left", ")", "else", ":", "return", "arr_padded"], "docstring": "Pad an image-like array on its sides so that it matches a target aspect ratio.\n\n    Depending on which dimension is smaller (height or width), only the corresponding\n    sides (left/right or top/bottom) will be padded. In each case, both of the sides will\n    be padded equally.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pad`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pad.\n\n    aspect_ratio : float\n        Target aspect ratio, given as width/height. E.g. 2.0 denotes the image having twice\n        as much width as height.\n\n    mode : str, optional\n        Padding mode to use. See :func:`numpy.pad` for details.\n\n    cval : number, optional\n        Value to use for padding if `mode` is ``constant``. See :func:`numpy.pad` for details.\n\n    return_pad_amounts : bool, optional\n        If False, then only the padded image will be returned. If True, a tuple with two\n        entries will be returned, where the first entry is the padded image and the second\n        entry are the amounts by which each image side was padded. These amounts are again a\n        tuple of the form (top, right, bottom, left), with each value being an integer.\n\n    Returns\n    -------\n    arr_padded : (H',W') ndarray or (H',W',C) ndarray\n        Padded image as (H',W') or (H',W',C) ndarray, fulfulling the given aspect_ratio.\n\n    tuple of int\n        Amounts by which the image was padded on each side, given as a tuple ``(top, right, bottom, left)``.\n        This tuple is only returned if `return_pad_amounts` was set to True.\n        Otherwise only ``arr_padded`` is returned.", "docstring_tokens": ["Pad", "an", "image", "-", "like", "array", "on", "its", "sides", "so", "that", "it", "matches", "a", "target", "aspect", "ratio", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1476-L1534", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "pool", "original_string": "def pool(arr, block_size, func, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array by pooling values within blocks.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; tested\n        * ``uint32``: yes; tested (2)\n        * ``uint64``: no (1)\n        * ``int8``: yes; tested\n        * ``int16``: yes; tested\n        * ``int32``: yes; tested (2)\n        * ``int64``: no (1)\n        * ``float16``: yes; tested\n        * ``float32``: yes; tested\n        * ``float64``: yes; tested\n        * ``float128``: yes; tested (2)\n        * ``bool``: yes; tested\n\n        - (1) results too inaccurate (at least when using np.average as func)\n        - (2) Note that scikit-image documentation says that the wrapped pooling function converts\n              inputs to float64. Actual tests showed no indication of that happening (at least when\n              using preserve_dtype=True).\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. Ideally of datatype ``numpy.float64``.\n\n    block_size : int or tuple of int\n        Spatial size of each group of values to pool, aka kernel size.\n        If a single integer, then a symmetric block of that size along height and width will be used.\n        If a tuple of two values, it is assumed to be the block size along height and width of the image-like,\n        with pooling happening per channel.\n        If a tuple of three values, it is assumed to be the block size along height, width and channels.\n\n    func : callable\n        Function to apply to a given block in order to convert it to a single number,\n        e.g. :func:`numpy.average`, :func:`numpy.min`, :func:`numpy.max`.\n\n    cval : number, optional\n        Value to use in order to pad the array along its border if the array cannot be divided\n        by `block_size` without remainder.\n\n    preserve_dtype : bool, optional\n        Whether to convert the array back to the input datatype if it is changed away from\n        that in the pooling process.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after pooling.\n\n    \"\"\"\n    # TODO find better way to avoid circular import\n    from . import dtypes as iadt\n    iadt.gate_dtypes(arr,\n                     allowed=[\"bool\", \"uint8\", \"uint16\", \"uint32\", \"int8\", \"int16\", \"int32\",\n                              \"float16\", \"float32\", \"float64\", \"float128\"],\n                     disallowed=[\"uint64\", \"uint128\", \"uint256\", \"int64\", \"int128\", \"int256\",\n                                 \"float256\"],\n                     augmenter=None)\n\n    do_assert(arr.ndim in [2, 3])\n    is_valid_int = is_single_integer(block_size) and block_size >= 1\n    is_valid_tuple = is_iterable(block_size) and len(block_size) in [2, 3] \\\n        and [is_single_integer(val) and val >= 1 for val in block_size]\n    do_assert(is_valid_int or is_valid_tuple)\n\n    if is_single_integer(block_size):\n        block_size = [block_size, block_size]\n    if len(block_size) < arr.ndim:\n        block_size = list(block_size) + [1]\n\n    input_dtype = arr.dtype\n    arr_reduced = skimage.measure.block_reduce(arr, tuple(block_size), func, cval=cval)\n    if preserve_dtype and arr_reduced.dtype.type != input_dtype:\n        arr_reduced = arr_reduced.astype(input_dtype)\n    return arr_reduced", "language": "python", "code": "def pool(arr, block_size, func, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array by pooling values within blocks.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; tested\n        * ``uint32``: yes; tested (2)\n        * ``uint64``: no (1)\n        * ``int8``: yes; tested\n        * ``int16``: yes; tested\n        * ``int32``: yes; tested (2)\n        * ``int64``: no (1)\n        * ``float16``: yes; tested\n        * ``float32``: yes; tested\n        * ``float64``: yes; tested\n        * ``float128``: yes; tested (2)\n        * ``bool``: yes; tested\n\n        - (1) results too inaccurate (at least when using np.average as func)\n        - (2) Note that scikit-image documentation says that the wrapped pooling function converts\n              inputs to float64. Actual tests showed no indication of that happening (at least when\n              using preserve_dtype=True).\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. Ideally of datatype ``numpy.float64``.\n\n    block_size : int or tuple of int\n        Spatial size of each group of values to pool, aka kernel size.\n        If a single integer, then a symmetric block of that size along height and width will be used.\n        If a tuple of two values, it is assumed to be the block size along height and width of the image-like,\n        with pooling happening per channel.\n        If a tuple of three values, it is assumed to be the block size along height, width and channels.\n\n    func : callable\n        Function to apply to a given block in order to convert it to a single number,\n        e.g. :func:`numpy.average`, :func:`numpy.min`, :func:`numpy.max`.\n\n    cval : number, optional\n        Value to use in order to pad the array along its border if the array cannot be divided\n        by `block_size` without remainder.\n\n    preserve_dtype : bool, optional\n        Whether to convert the array back to the input datatype if it is changed away from\n        that in the pooling process.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after pooling.\n\n    \"\"\"\n    # TODO find better way to avoid circular import\n    from . import dtypes as iadt\n    iadt.gate_dtypes(arr,\n                     allowed=[\"bool\", \"uint8\", \"uint16\", \"uint32\", \"int8\", \"int16\", \"int32\",\n                              \"float16\", \"float32\", \"float64\", \"float128\"],\n                     disallowed=[\"uint64\", \"uint128\", \"uint256\", \"int64\", \"int128\", \"int256\",\n                                 \"float256\"],\n                     augmenter=None)\n\n    do_assert(arr.ndim in [2, 3])\n    is_valid_int = is_single_integer(block_size) and block_size >= 1\n    is_valid_tuple = is_iterable(block_size) and len(block_size) in [2, 3] \\\n        and [is_single_integer(val) and val >= 1 for val in block_size]\n    do_assert(is_valid_int or is_valid_tuple)\n\n    if is_single_integer(block_size):\n        block_size = [block_size, block_size]\n    if len(block_size) < arr.ndim:\n        block_size = list(block_size) + [1]\n\n    input_dtype = arr.dtype\n    arr_reduced = skimage.measure.block_reduce(arr, tuple(block_size), func, cval=cval)\n    if preserve_dtype and arr_reduced.dtype.type != input_dtype:\n        arr_reduced = arr_reduced.astype(input_dtype)\n    return arr_reduced", "code_tokens": ["def", "pool", "(", "arr", ",", "block_size", ",", "func", ",", "cval", "=", "0", ",", "preserve_dtype", "=", "True", ")", ":", "# TODO find better way to avoid circular import", "from", ".", "import", "dtypes", "as", "iadt", "iadt", ".", "gate_dtypes", "(", "arr", ",", "allowed", "=", "[", "\"bool\"", ",", "\"uint8\"", ",", "\"uint16\"", ",", "\"uint32\"", ",", "\"int8\"", ",", "\"int16\"", ",", "\"int32\"", ",", "\"float16\"", ",", "\"float32\"", ",", "\"float64\"", ",", "\"float128\"", "]", ",", "disallowed", "=", "[", "\"uint64\"", ",", "\"uint128\"", ",", "\"uint256\"", ",", "\"int64\"", ",", "\"int128\"", ",", "\"int256\"", ",", "\"float256\"", "]", ",", "augmenter", "=", "None", ")", "do_assert", "(", "arr", ".", "ndim", "in", "[", "2", ",", "3", "]", ")", "is_valid_int", "=", "is_single_integer", "(", "block_size", ")", "and", "block_size", ">=", "1", "is_valid_tuple", "=", "is_iterable", "(", "block_size", ")", "and", "len", "(", "block_size", ")", "in", "[", "2", ",", "3", "]", "and", "[", "is_single_integer", "(", "val", ")", "and", "val", ">=", "1", "for", "val", "in", "block_size", "]", "do_assert", "(", "is_valid_int", "or", "is_valid_tuple", ")", "if", "is_single_integer", "(", "block_size", ")", ":", "block_size", "=", "[", "block_size", ",", "block_size", "]", "if", "len", "(", "block_size", ")", "<", "arr", ".", "ndim", ":", "block_size", "=", "list", "(", "block_size", ")", "+", "[", "1", "]", "input_dtype", "=", "arr", ".", "dtype", "arr_reduced", "=", "skimage", ".", "measure", ".", "block_reduce", "(", "arr", ",", "tuple", "(", "block_size", ")", ",", "func", ",", "cval", "=", "cval", ")", "if", "preserve_dtype", "and", "arr_reduced", ".", "dtype", ".", "type", "!=", "input_dtype", ":", "arr_reduced", "=", "arr_reduced", ".", "astype", "(", "input_dtype", ")", "return", "arr_reduced"], "docstring": "Resize an array by pooling values within blocks.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; tested\n        * ``uint32``: yes; tested (2)\n        * ``uint64``: no (1)\n        * ``int8``: yes; tested\n        * ``int16``: yes; tested\n        * ``int32``: yes; tested (2)\n        * ``int64``: no (1)\n        * ``float16``: yes; tested\n        * ``float32``: yes; tested\n        * ``float64``: yes; tested\n        * ``float128``: yes; tested (2)\n        * ``bool``: yes; tested\n\n        - (1) results too inaccurate (at least when using np.average as func)\n        - (2) Note that scikit-image documentation says that the wrapped pooling function converts\n              inputs to float64. Actual tests showed no indication of that happening (at least when\n              using preserve_dtype=True).\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. Ideally of datatype ``numpy.float64``.\n\n    block_size : int or tuple of int\n        Spatial size of each group of values to pool, aka kernel size.\n        If a single integer, then a symmetric block of that size along height and width will be used.\n        If a tuple of two values, it is assumed to be the block size along height and width of the image-like,\n        with pooling happening per channel.\n        If a tuple of three values, it is assumed to be the block size along height, width and channels.\n\n    func : callable\n        Function to apply to a given block in order to convert it to a single number,\n        e.g. :func:`numpy.average`, :func:`numpy.min`, :func:`numpy.max`.\n\n    cval : number, optional\n        Value to use in order to pad the array along its border if the array cannot be divided\n        by `block_size` without remainder.\n\n    preserve_dtype : bool, optional\n        Whether to convert the array back to the input datatype if it is changed away from\n        that in the pooling process.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after pooling.", "docstring_tokens": ["Resize", "an", "array", "by", "pooling", "values", "within", "blocks", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1537-L1616", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "avg_pool", "original_string": "def avg_pool(arr, block_size, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array using average pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See :func:`imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after average pooling.\n\n    \"\"\"\n    return pool(arr, block_size, np.average, cval=cval, preserve_dtype=preserve_dtype)", "language": "python", "code": "def avg_pool(arr, block_size, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array using average pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See :func:`imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after average pooling.\n\n    \"\"\"\n    return pool(arr, block_size, np.average, cval=cval, preserve_dtype=preserve_dtype)", "code_tokens": ["def", "avg_pool", "(", "arr", ",", "block_size", ",", "cval", "=", "0", ",", "preserve_dtype", "=", "True", ")", ":", "return", "pool", "(", "arr", ",", "block_size", ",", "np", ".", "average", ",", "cval", "=", "cval", ",", "preserve_dtype", "=", "preserve_dtype", ")"], "docstring": "Resize an array using average pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See :func:`imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after average pooling.", "docstring_tokens": ["Resize", "an", "array", "using", "average", "pooling", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1619-L1647", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "max_pool", "original_string": "def max_pool(arr, block_size, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array using max-pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See `imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after max-pooling.\n\n    \"\"\"\n    return pool(arr, block_size, np.max, cval=cval, preserve_dtype=preserve_dtype)", "language": "python", "code": "def max_pool(arr, block_size, cval=0, preserve_dtype=True):\n    \"\"\"\n    Resize an array using max-pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See `imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after max-pooling.\n\n    \"\"\"\n    return pool(arr, block_size, np.max, cval=cval, preserve_dtype=preserve_dtype)", "code_tokens": ["def", "max_pool", "(", "arr", ",", "block_size", ",", "cval", "=", "0", ",", "preserve_dtype", "=", "True", ")", ":", "return", "pool", "(", "arr", ",", "block_size", ",", "np", ".", "max", ",", "cval", "=", "cval", ",", "preserve_dtype", "=", "preserve_dtype", ")"], "docstring": "Resize an array using max-pooling.\n\n    dtype support::\n\n        See :func:`imgaug.imgaug.pool`.\n\n    Parameters\n    ----------\n    arr : (H,W) ndarray or (H,W,C) ndarray\n        Image-like array to pool. See :func:`imgaug.pool` for details.\n\n    block_size : int or tuple of int or tuple of int\n        Size of each block of values to pool. See `imgaug.pool` for details.\n\n    cval : number, optional\n        Padding value. See :func:`imgaug.pool` for details.\n\n    preserve_dtype : bool, optional\n        Whether to preserve the input array dtype. See :func:`imgaug.pool` for details.\n\n    Returns\n    -------\n    arr_reduced : (H',W') ndarray or (H',W',C') ndarray\n        Array after max-pooling.", "docstring_tokens": ["Resize", "an", "array", "using", "max", "-", "pooling", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1650-L1678", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "draw_grid", "original_string": "def draw_grid(images, rows=None, cols=None):\n    \"\"\"\n    Converts multiple input images into a single image showing them in a grid.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; fully tested\n        * ``uint32``: yes; fully tested\n        * ``uint64``: yes; fully tested\n        * ``int8``: yes; fully tested\n        * ``int16``: yes; fully tested\n        * ``int32``: yes; fully tested\n        * ``int64``: yes; fully tested\n        * ``float16``: yes; fully tested\n        * ``float32``: yes; fully tested\n        * ``float64``: yes; fully tested\n        * ``float128``: yes; fully tested\n        * ``bool``: yes; fully tested\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        The input images to convert to a grid.\n\n    rows : None or int, optional\n        The number of rows to show in the grid.\n        If None, it will be automatically derived.\n\n    cols : None or int, optional\n        The number of cols to show in the grid.\n        If None, it will be automatically derived.\n\n    Returns\n    -------\n    grid : (H',W',3) ndarray\n        Image of the generated grid.\n\n    \"\"\"\n    nb_images = len(images)\n    do_assert(nb_images > 0)\n\n    if is_np_array(images):\n        do_assert(images.ndim == 4)\n    else:\n        do_assert(is_iterable(images) and is_np_array(images[0]) and images[0].ndim == 3)\n        dts = [image.dtype.name for image in images]\n        nb_dtypes = len(set(dts))\n        do_assert(nb_dtypes == 1, (\"All images provided to draw_grid() must have the same dtype, \"\n                                   + \"found %d dtypes (%s)\") % (nb_dtypes, \", \".join(dts)))\n\n    cell_height = max([image.shape[0] for image in images])\n    cell_width = max([image.shape[1] for image in images])\n    channels = set([image.shape[2] for image in images])\n    do_assert(\n        len(channels) == 1,\n        \"All images are expected to have the same number of channels, \"\n        + \"but got channel set %s with length %d instead.\" % (str(channels), len(channels))\n    )\n    nb_channels = list(channels)[0]\n    if rows is None and cols is None:\n        rows = cols = int(math.ceil(math.sqrt(nb_images)))\n    elif rows is not None:\n        cols = int(math.ceil(nb_images / rows))\n    elif cols is not None:\n        rows = int(math.ceil(nb_images / cols))\n    do_assert(rows * cols >= nb_images)\n\n    width = cell_width * cols\n    height = cell_height * rows\n    dt = images.dtype if is_np_array(images) else images[0].dtype\n    grid = np.zeros((height, width, nb_channels), dtype=dt)\n    cell_idx = 0\n    for row_idx in sm.xrange(rows):\n        for col_idx in sm.xrange(cols):\n            if cell_idx < nb_images:\n                image = images[cell_idx]\n                cell_y1 = cell_height * row_idx\n                cell_y2 = cell_y1 + image.shape[0]\n                cell_x1 = cell_width * col_idx\n                cell_x2 = cell_x1 + image.shape[1]\n                grid[cell_y1:cell_y2, cell_x1:cell_x2, :] = image\n            cell_idx += 1\n\n    return grid", "language": "python", "code": "def draw_grid(images, rows=None, cols=None):\n    \"\"\"\n    Converts multiple input images into a single image showing them in a grid.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; fully tested\n        * ``uint32``: yes; fully tested\n        * ``uint64``: yes; fully tested\n        * ``int8``: yes; fully tested\n        * ``int16``: yes; fully tested\n        * ``int32``: yes; fully tested\n        * ``int64``: yes; fully tested\n        * ``float16``: yes; fully tested\n        * ``float32``: yes; fully tested\n        * ``float64``: yes; fully tested\n        * ``float128``: yes; fully tested\n        * ``bool``: yes; fully tested\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        The input images to convert to a grid.\n\n    rows : None or int, optional\n        The number of rows to show in the grid.\n        If None, it will be automatically derived.\n\n    cols : None or int, optional\n        The number of cols to show in the grid.\n        If None, it will be automatically derived.\n\n    Returns\n    -------\n    grid : (H',W',3) ndarray\n        Image of the generated grid.\n\n    \"\"\"\n    nb_images = len(images)\n    do_assert(nb_images > 0)\n\n    if is_np_array(images):\n        do_assert(images.ndim == 4)\n    else:\n        do_assert(is_iterable(images) and is_np_array(images[0]) and images[0].ndim == 3)\n        dts = [image.dtype.name for image in images]\n        nb_dtypes = len(set(dts))\n        do_assert(nb_dtypes == 1, (\"All images provided to draw_grid() must have the same dtype, \"\n                                   + \"found %d dtypes (%s)\") % (nb_dtypes, \", \".join(dts)))\n\n    cell_height = max([image.shape[0] for image in images])\n    cell_width = max([image.shape[1] for image in images])\n    channels = set([image.shape[2] for image in images])\n    do_assert(\n        len(channels) == 1,\n        \"All images are expected to have the same number of channels, \"\n        + \"but got channel set %s with length %d instead.\" % (str(channels), len(channels))\n    )\n    nb_channels = list(channels)[0]\n    if rows is None and cols is None:\n        rows = cols = int(math.ceil(math.sqrt(nb_images)))\n    elif rows is not None:\n        cols = int(math.ceil(nb_images / rows))\n    elif cols is not None:\n        rows = int(math.ceil(nb_images / cols))\n    do_assert(rows * cols >= nb_images)\n\n    width = cell_width * cols\n    height = cell_height * rows\n    dt = images.dtype if is_np_array(images) else images[0].dtype\n    grid = np.zeros((height, width, nb_channels), dtype=dt)\n    cell_idx = 0\n    for row_idx in sm.xrange(rows):\n        for col_idx in sm.xrange(cols):\n            if cell_idx < nb_images:\n                image = images[cell_idx]\n                cell_y1 = cell_height * row_idx\n                cell_y2 = cell_y1 + image.shape[0]\n                cell_x1 = cell_width * col_idx\n                cell_x2 = cell_x1 + image.shape[1]\n                grid[cell_y1:cell_y2, cell_x1:cell_x2, :] = image\n            cell_idx += 1\n\n    return grid", "code_tokens": ["def", "draw_grid", "(", "images", ",", "rows", "=", "None", ",", "cols", "=", "None", ")", ":", "nb_images", "=", "len", "(", "images", ")", "do_assert", "(", "nb_images", ">", "0", ")", "if", "is_np_array", "(", "images", ")", ":", "do_assert", "(", "images", ".", "ndim", "==", "4", ")", "else", ":", "do_assert", "(", "is_iterable", "(", "images", ")", "and", "is_np_array", "(", "images", "[", "0", "]", ")", "and", "images", "[", "0", "]", ".", "ndim", "==", "3", ")", "dts", "=", "[", "image", ".", "dtype", ".", "name", "for", "image", "in", "images", "]", "nb_dtypes", "=", "len", "(", "set", "(", "dts", ")", ")", "do_assert", "(", "nb_dtypes", "==", "1", ",", "(", "\"All images provided to draw_grid() must have the same dtype, \"", "+", "\"found %d dtypes (%s)\"", ")", "%", "(", "nb_dtypes", ",", "\", \"", ".", "join", "(", "dts", ")", ")", ")", "cell_height", "=", "max", "(", "[", "image", ".", "shape", "[", "0", "]", "for", "image", "in", "images", "]", ")", "cell_width", "=", "max", "(", "[", "image", ".", "shape", "[", "1", "]", "for", "image", "in", "images", "]", ")", "channels", "=", "set", "(", "[", "image", ".", "shape", "[", "2", "]", "for", "image", "in", "images", "]", ")", "do_assert", "(", "len", "(", "channels", ")", "==", "1", ",", "\"All images are expected to have the same number of channels, \"", "+", "\"but got channel set %s with length %d instead.\"", "%", "(", "str", "(", "channels", ")", ",", "len", "(", "channels", ")", ")", ")", "nb_channels", "=", "list", "(", "channels", ")", "[", "0", "]", "if", "rows", "is", "None", "and", "cols", "is", "None", ":", "rows", "=", "cols", "=", "int", "(", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "nb_images", ")", ")", ")", "elif", "rows", "is", "not", "None", ":", "cols", "=", "int", "(", "math", ".", "ceil", "(", "nb_images", "/", "rows", ")", ")", "elif", "cols", "is", "not", "None", ":", "rows", "=", "int", "(", "math", ".", "ceil", "(", "nb_images", "/", "cols", ")", ")", "do_assert", "(", "rows", "*", "cols", ">=", "nb_images", ")", "width", "=", "cell_width", "*", "cols", "height", "=", "cell_height", "*", "rows", "dt", "=", "images", ".", "dtype", "if", "is_np_array", "(", "images", ")", "else", "images", "[", "0", "]", ".", "dtype", "grid", "=", "np", ".", "zeros", "(", "(", "height", ",", "width", ",", "nb_channels", ")", ",", "dtype", "=", "dt", ")", "cell_idx", "=", "0", "for", "row_idx", "in", "sm", ".", "xrange", "(", "rows", ")", ":", "for", "col_idx", "in", "sm", ".", "xrange", "(", "cols", ")", ":", "if", "cell_idx", "<", "nb_images", ":", "image", "=", "images", "[", "cell_idx", "]", "cell_y1", "=", "cell_height", "*", "row_idx", "cell_y2", "=", "cell_y1", "+", "image", ".", "shape", "[", "0", "]", "cell_x1", "=", "cell_width", "*", "col_idx", "cell_x2", "=", "cell_x1", "+", "image", ".", "shape", "[", "1", "]", "grid", "[", "cell_y1", ":", "cell_y2", ",", "cell_x1", ":", "cell_x2", ",", ":", "]", "=", "image", "cell_idx", "+=", "1", "return", "grid"], "docstring": "Converts multiple input images into a single image showing them in a grid.\n\n    dtype support::\n\n        * ``uint8``: yes; fully tested\n        * ``uint16``: yes; fully tested\n        * ``uint32``: yes; fully tested\n        * ``uint64``: yes; fully tested\n        * ``int8``: yes; fully tested\n        * ``int16``: yes; fully tested\n        * ``int32``: yes; fully tested\n        * ``int64``: yes; fully tested\n        * ``float16``: yes; fully tested\n        * ``float32``: yes; fully tested\n        * ``float64``: yes; fully tested\n        * ``float128``: yes; fully tested\n        * ``bool``: yes; fully tested\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        The input images to convert to a grid.\n\n    rows : None or int, optional\n        The number of rows to show in the grid.\n        If None, it will be automatically derived.\n\n    cols : None or int, optional\n        The number of cols to show in the grid.\n        If None, it will be automatically derived.\n\n    Returns\n    -------\n    grid : (H',W',3) ndarray\n        Image of the generated grid.", "docstring_tokens": ["Converts", "multiple", "input", "images", "into", "a", "single", "image", "showing", "them", "in", "a", "grid", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1681-L1765", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "show_grid", "original_string": "def show_grid(images, rows=None, cols=None):\n    \"\"\"\n    Converts the input images to a grid image and shows it in a new window.\n\n    dtype support::\n\n        minimum of (\n            :func:`imgaug.imgaug.draw_grid`,\n            :func:`imgaug.imgaug.imshow`\n        )\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        See :func:`imgaug.draw_grid`.\n\n    rows : None or int, optional\n        See :func:`imgaug.draw_grid`.\n\n    cols : None or int, optional\n        See :func:`imgaug.draw_grid`.\n\n    \"\"\"\n    grid = draw_grid(images, rows=rows, cols=cols)\n    imshow(grid)", "language": "python", "code": "def show_grid(images, rows=None, cols=None):\n    \"\"\"\n    Converts the input images to a grid image and shows it in a new window.\n\n    dtype support::\n\n        minimum of (\n            :func:`imgaug.imgaug.draw_grid`,\n            :func:`imgaug.imgaug.imshow`\n        )\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        See :func:`imgaug.draw_grid`.\n\n    rows : None or int, optional\n        See :func:`imgaug.draw_grid`.\n\n    cols : None or int, optional\n        See :func:`imgaug.draw_grid`.\n\n    \"\"\"\n    grid = draw_grid(images, rows=rows, cols=cols)\n    imshow(grid)", "code_tokens": ["def", "show_grid", "(", "images", ",", "rows", "=", "None", ",", "cols", "=", "None", ")", ":", "grid", "=", "draw_grid", "(", "images", ",", "rows", "=", "rows", ",", "cols", "=", "cols", ")", "imshow", "(", "grid", ")"], "docstring": "Converts the input images to a grid image and shows it in a new window.\n\n    dtype support::\n\n        minimum of (\n            :func:`imgaug.imgaug.draw_grid`,\n            :func:`imgaug.imgaug.imshow`\n        )\n\n    Parameters\n    ----------\n    images : (N,H,W,3) ndarray or iterable of (H,W,3) array\n        See :func:`imgaug.draw_grid`.\n\n    rows : None or int, optional\n        See :func:`imgaug.draw_grid`.\n\n    cols : None or int, optional\n        See :func:`imgaug.draw_grid`.", "docstring_tokens": ["Converts", "the", "input", "images", "to", "a", "grid", "image", "and", "shows", "it", "in", "a", "new", "window", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1768-L1792", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "imshow", "original_string": "def imshow(image, backend=IMSHOW_BACKEND_DEFAULT):\n    \"\"\"\n    Shows an image in a window.\n\n    dtype support::\n\n        * ``uint8``: yes; not tested\n        * ``uint16``: ?\n        * ``uint32``: ?\n        * ``uint64``: ?\n        * ``int8``: ?\n        * ``int16``: ?\n        * ``int32``: ?\n        * ``int64``: ?\n        * ``float16``: ?\n        * ``float32``: ?\n        * ``float64``: ?\n        * ``float128``: ?\n        * ``bool``: ?\n\n    Parameters\n    ----------\n    image : (H,W,3) ndarray\n        Image to show.\n\n    backend : {'matplotlib', 'cv2'}, optional\n        Library to use to show the image. May be either matplotlib or OpenCV ('cv2').\n        OpenCV tends to be faster, but apparently causes more technical issues.\n\n    \"\"\"\n    do_assert(backend in [\"matplotlib\", \"cv2\"], \"Expected backend 'matplotlib' or 'cv2', got %s.\" % (backend,))\n\n    if backend == \"cv2\":\n        image_bgr = image\n        if image.ndim == 3 and image.shape[2] in [3, 4]:\n            image_bgr = image[..., 0:3][..., ::-1]\n\n        win_name = \"imgaug-default-window\"\n        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n        cv2.imshow(win_name, image_bgr)\n        cv2.waitKey(0)\n        cv2.destroyWindow(win_name)\n    else:\n        # import only when necessary (faster startup; optional dependency; less fragile -- see issue #225)\n        import matplotlib.pyplot as plt\n\n        dpi = 96\n        h, w = image.shape[0] / dpi, image.shape[1] / dpi\n        w = max(w, 6)  # if the figure is too narrow, the footer may appear and make the fig suddenly wider (ugly)\n        fig, ax = plt.subplots(figsize=(w, h), dpi=dpi)\n        fig.canvas.set_window_title(\"imgaug.imshow(%s)\" % (image.shape,))\n        ax.imshow(image, cmap=\"gray\")  # cmap is only activate for grayscale images\n        plt.show()", "language": "python", "code": "def imshow(image, backend=IMSHOW_BACKEND_DEFAULT):\n    \"\"\"\n    Shows an image in a window.\n\n    dtype support::\n\n        * ``uint8``: yes; not tested\n        * ``uint16``: ?\n        * ``uint32``: ?\n        * ``uint64``: ?\n        * ``int8``: ?\n        * ``int16``: ?\n        * ``int32``: ?\n        * ``int64``: ?\n        * ``float16``: ?\n        * ``float32``: ?\n        * ``float64``: ?\n        * ``float128``: ?\n        * ``bool``: ?\n\n    Parameters\n    ----------\n    image : (H,W,3) ndarray\n        Image to show.\n\n    backend : {'matplotlib', 'cv2'}, optional\n        Library to use to show the image. May be either matplotlib or OpenCV ('cv2').\n        OpenCV tends to be faster, but apparently causes more technical issues.\n\n    \"\"\"\n    do_assert(backend in [\"matplotlib\", \"cv2\"], \"Expected backend 'matplotlib' or 'cv2', got %s.\" % (backend,))\n\n    if backend == \"cv2\":\n        image_bgr = image\n        if image.ndim == 3 and image.shape[2] in [3, 4]:\n            image_bgr = image[..., 0:3][..., ::-1]\n\n        win_name = \"imgaug-default-window\"\n        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n        cv2.imshow(win_name, image_bgr)\n        cv2.waitKey(0)\n        cv2.destroyWindow(win_name)\n    else:\n        # import only when necessary (faster startup; optional dependency; less fragile -- see issue #225)\n        import matplotlib.pyplot as plt\n\n        dpi = 96\n        h, w = image.shape[0] / dpi, image.shape[1] / dpi\n        w = max(w, 6)  # if the figure is too narrow, the footer may appear and make the fig suddenly wider (ugly)\n        fig, ax = plt.subplots(figsize=(w, h), dpi=dpi)\n        fig.canvas.set_window_title(\"imgaug.imshow(%s)\" % (image.shape,))\n        ax.imshow(image, cmap=\"gray\")  # cmap is only activate for grayscale images\n        plt.show()", "code_tokens": ["def", "imshow", "(", "image", ",", "backend", "=", "IMSHOW_BACKEND_DEFAULT", ")", ":", "do_assert", "(", "backend", "in", "[", "\"matplotlib\"", ",", "\"cv2\"", "]", ",", "\"Expected backend 'matplotlib' or 'cv2', got %s.\"", "%", "(", "backend", ",", ")", ")", "if", "backend", "==", "\"cv2\"", ":", "image_bgr", "=", "image", "if", "image", ".", "ndim", "==", "3", "and", "image", ".", "shape", "[", "2", "]", "in", "[", "3", ",", "4", "]", ":", "image_bgr", "=", "image", "[", "...", ",", "0", ":", "3", "]", "[", "...", ",", ":", ":", "-", "1", "]", "win_name", "=", "\"imgaug-default-window\"", "cv2", ".", "namedWindow", "(", "win_name", ",", "cv2", ".", "WINDOW_NORMAL", ")", "cv2", ".", "imshow", "(", "win_name", ",", "image_bgr", ")", "cv2", ".", "waitKey", "(", "0", ")", "cv2", ".", "destroyWindow", "(", "win_name", ")", "else", ":", "# import only when necessary (faster startup; optional dependency; less fragile -- see issue #225)", "import", "matplotlib", ".", "pyplot", "as", "plt", "dpi", "=", "96", "h", ",", "w", "=", "image", ".", "shape", "[", "0", "]", "/", "dpi", ",", "image", ".", "shape", "[", "1", "]", "/", "dpi", "w", "=", "max", "(", "w", ",", "6", ")", "# if the figure is too narrow, the footer may appear and make the fig suddenly wider (ugly)", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "w", ",", "h", ")", ",", "dpi", "=", "dpi", ")", "fig", ".", "canvas", ".", "set_window_title", "(", "\"imgaug.imshow(%s)\"", "%", "(", "image", ".", "shape", ",", ")", ")", "ax", ".", "imshow", "(", "image", ",", "cmap", "=", "\"gray\"", ")", "# cmap is only activate for grayscale images", "plt", ".", "show", "(", ")"], "docstring": "Shows an image in a window.\n\n    dtype support::\n\n        * ``uint8``: yes; not tested\n        * ``uint16``: ?\n        * ``uint32``: ?\n        * ``uint64``: ?\n        * ``int8``: ?\n        * ``int16``: ?\n        * ``int32``: ?\n        * ``int64``: ?\n        * ``float16``: ?\n        * ``float32``: ?\n        * ``float64``: ?\n        * ``float128``: ?\n        * ``bool``: ?\n\n    Parameters\n    ----------\n    image : (H,W,3) ndarray\n        Image to show.\n\n    backend : {'matplotlib', 'cv2'}, optional\n        Library to use to show the image. May be either matplotlib or OpenCV ('cv2').\n        OpenCV tends to be faster, but apparently causes more technical issues.", "docstring_tokens": ["Shows", "an", "image", "in", "a", "window", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1795-L1847", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "warn_deprecated", "original_string": "def warn_deprecated(msg, stacklevel=2):\n    \"\"\"Generate a non-silent deprecation warning with stacktrace.\n\n    The used warning is ``imgaug.imgaug.DeprecationWarning``.\n\n    Parameters\n    ----------\n    msg : str\n        The message of the warning.\n\n    stacklevel : int, optional\n        How many steps above this function to \"jump\" in the stacktrace for\n        the displayed file and line number of the error message.\n        Usually 2.\n\n    \"\"\"\n    import warnings\n    warnings.warn(msg,\n                  category=DeprecationWarning,\n                  stacklevel=stacklevel)", "language": "python", "code": "def warn_deprecated(msg, stacklevel=2):\n    \"\"\"Generate a non-silent deprecation warning with stacktrace.\n\n    The used warning is ``imgaug.imgaug.DeprecationWarning``.\n\n    Parameters\n    ----------\n    msg : str\n        The message of the warning.\n\n    stacklevel : int, optional\n        How many steps above this function to \"jump\" in the stacktrace for\n        the displayed file and line number of the error message.\n        Usually 2.\n\n    \"\"\"\n    import warnings\n    warnings.warn(msg,\n                  category=DeprecationWarning,\n                  stacklevel=stacklevel)", "code_tokens": ["def", "warn_deprecated", "(", "msg", ",", "stacklevel", "=", "2", ")", ":", "import", "warnings", "warnings", ".", "warn", "(", "msg", ",", "category", "=", "DeprecationWarning", ",", "stacklevel", "=", "stacklevel", ")"], "docstring": "Generate a non-silent deprecation warning with stacktrace.\n\n    The used warning is ``imgaug.imgaug.DeprecationWarning``.\n\n    Parameters\n    ----------\n    msg : str\n        The message of the warning.\n\n    stacklevel : int, optional\n        How many steps above this function to \"jump\" in the stacktrace for\n        the displayed file and line number of the error message.\n        Usually 2.", "docstring_tokens": ["Generate", "a", "non", "-", "silent", "deprecation", "warning", "with", "stacktrace", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L2046-L2065", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "HooksImages.is_activated", "original_string": "def is_activated(self, images, augmenter, parents, default):\n        \"\"\"\n        Returns whether an augmenter may be executed.\n\n        Returns\n        -------\n        bool\n            If True, the augmenter may be executed. If False, it may not be executed.\n\n        \"\"\"\n        if self.activator is None:\n            return default\n        else:\n            return self.activator(images, augmenter, parents, default)", "language": "python", "code": "def is_activated(self, images, augmenter, parents, default):\n        \"\"\"\n        Returns whether an augmenter may be executed.\n\n        Returns\n        -------\n        bool\n            If True, the augmenter may be executed. If False, it may not be executed.\n\n        \"\"\"\n        if self.activator is None:\n            return default\n        else:\n            return self.activator(images, augmenter, parents, default)", "code_tokens": ["def", "is_activated", "(", "self", ",", "images", ",", "augmenter", ",", "parents", ",", "default", ")", ":", "if", "self", ".", "activator", "is", "None", ":", "return", "default", "else", ":", "return", "self", ".", "activator", "(", "images", ",", "augmenter", ",", "parents", ",", "default", ")"], "docstring": "Returns whether an augmenter may be executed.\n\n        Returns\n        -------\n        bool\n            If True, the augmenter may be executed. If False, it may not be executed.", "docstring_tokens": ["Returns", "whether", "an", "augmenter", "may", "be", "executed", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1941-L1954", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/imgaug.py", "func_name": "HooksImages.postprocess", "original_string": "def postprocess(self, images, augmenter, parents):\n        \"\"\"\n        A function to be called after the augmentation of images was\n        performed.\n\n        Returns\n        -------\n        (N,H,W,C) ndarray or (N,H,W) ndarray or list of (H,W,C) ndarray or list of (H,W) ndarray\n            The input images, optionally modified.\n\n        \"\"\"\n        if self.postprocessor is None:\n            return images\n        else:\n            return self.postprocessor(images, augmenter, parents)", "language": "python", "code": "def postprocess(self, images, augmenter, parents):\n        \"\"\"\n        A function to be called after the augmentation of images was\n        performed.\n\n        Returns\n        -------\n        (N,H,W,C) ndarray or (N,H,W) ndarray or list of (H,W,C) ndarray or list of (H,W) ndarray\n            The input images, optionally modified.\n\n        \"\"\"\n        if self.postprocessor is None:\n            return images\n        else:\n            return self.postprocessor(images, augmenter, parents)", "code_tokens": ["def", "postprocess", "(", "self", ",", "images", ",", "augmenter", ",", "parents", ")", ":", "if", "self", ".", "postprocessor", "is", "None", ":", "return", "images", "else", ":", "return", "self", ".", "postprocessor", "(", "images", ",", "augmenter", ",", "parents", ")"], "docstring": "A function to be called after the augmentation of images was\n        performed.\n\n        Returns\n        -------\n        (N,H,W,C) ndarray or (N,H,W) ndarray or list of (H,W,C) ndarray or list of (H,W) ndarray\n            The input images, optionally modified.", "docstring_tokens": ["A", "function", "to", "be", "called", "after", "the", "augmentation", "of", "images", "was", "performed", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/imgaug.py#L1989-L2003", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.pool", "original_string": "def pool(self):\n        \"\"\"Return the multiprocessing.Pool instance or create it if not done yet.\n\n        Returns\n        -------\n        multiprocessing.Pool\n            The multiprocessing.Pool used internally by this imgaug.multicore.Pool.\n\n        \"\"\"\n        if self._pool is None:\n            processes = self.processes\n            if processes is not None and processes < 0:\n                try:\n                    # cpu count includes the hyperthreads, e.g. 8 for 4 cores + hyperthreading\n                    processes = multiprocessing.cpu_count() - abs(processes)\n                    processes = max(processes, 1)\n                except (ImportError, NotImplementedError):\n                    processes = None\n\n            self._pool = multiprocessing.Pool(processes,\n                                              initializer=_Pool_initialize_worker,\n                                              initargs=(self.augseq, self.seed),\n                                              maxtasksperchild=self.maxtasksperchild)\n        return self._pool", "language": "python", "code": "def pool(self):\n        \"\"\"Return the multiprocessing.Pool instance or create it if not done yet.\n\n        Returns\n        -------\n        multiprocessing.Pool\n            The multiprocessing.Pool used internally by this imgaug.multicore.Pool.\n\n        \"\"\"\n        if self._pool is None:\n            processes = self.processes\n            if processes is not None and processes < 0:\n                try:\n                    # cpu count includes the hyperthreads, e.g. 8 for 4 cores + hyperthreading\n                    processes = multiprocessing.cpu_count() - abs(processes)\n                    processes = max(processes, 1)\n                except (ImportError, NotImplementedError):\n                    processes = None\n\n            self._pool = multiprocessing.Pool(processes,\n                                              initializer=_Pool_initialize_worker,\n                                              initargs=(self.augseq, self.seed),\n                                              maxtasksperchild=self.maxtasksperchild)\n        return self._pool", "code_tokens": ["def", "pool", "(", "self", ")", ":", "if", "self", ".", "_pool", "is", "None", ":", "processes", "=", "self", ".", "processes", "if", "processes", "is", "not", "None", "and", "processes", "<", "0", ":", "try", ":", "# cpu count includes the hyperthreads, e.g. 8 for 4 cores + hyperthreading", "processes", "=", "multiprocessing", ".", "cpu_count", "(", ")", "-", "abs", "(", "processes", ")", "processes", "=", "max", "(", "processes", ",", "1", ")", "except", "(", "ImportError", ",", "NotImplementedError", ")", ":", "processes", "=", "None", "self", ".", "_pool", "=", "multiprocessing", ".", "Pool", "(", "processes", ",", "initializer", "=", "_Pool_initialize_worker", ",", "initargs", "=", "(", "self", ".", "augseq", ",", "self", ".", "seed", ")", ",", "maxtasksperchild", "=", "self", ".", "maxtasksperchild", ")", "return", "self", ".", "_pool"], "docstring": "Return the multiprocessing.Pool instance or create it if not done yet.\n\n        Returns\n        -------\n        multiprocessing.Pool\n            The multiprocessing.Pool used internally by this imgaug.multicore.Pool.", "docstring_tokens": ["Return", "the", "multiprocessing", ".", "Pool", "instance", "or", "create", "it", "if", "not", "done", "yet", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L85-L108", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.map_batches", "original_string": "def map_batches(self, batches, chunksize=None):\n        \"\"\"\n        Augment batches.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Returns\n        -------\n        list of imgaug.augmentables.batches.Batch\n            Augmented batches.\n\n        \"\"\"\n        assert isinstance(batches, list), (\"Expected to get a list as 'batches', got type %s. \"\n                                           + \"Call imap_batches() if you use generators.\") % (type(batches),)\n        return self.pool.map(_Pool_starworker, self._handle_batch_ids(batches), chunksize=chunksize)", "language": "python", "code": "def map_batches(self, batches, chunksize=None):\n        \"\"\"\n        Augment batches.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Returns\n        -------\n        list of imgaug.augmentables.batches.Batch\n            Augmented batches.\n\n        \"\"\"\n        assert isinstance(batches, list), (\"Expected to get a list as 'batches', got type %s. \"\n                                           + \"Call imap_batches() if you use generators.\") % (type(batches),)\n        return self.pool.map(_Pool_starworker, self._handle_batch_ids(batches), chunksize=chunksize)", "code_tokens": ["def", "map_batches", "(", "self", ",", "batches", ",", "chunksize", "=", "None", ")", ":", "assert", "isinstance", "(", "batches", ",", "list", ")", ",", "(", "\"Expected to get a list as 'batches', got type %s. \"", "+", "\"Call imap_batches() if you use generators.\"", ")", "%", "(", "type", "(", "batches", ")", ",", ")", "return", "self", ".", "pool", ".", "map", "(", "_Pool_starworker", ",", "self", ".", "_handle_batch_ids", "(", "batches", ")", ",", "chunksize", "=", "chunksize", ")"], "docstring": "Augment batches.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Returns\n        -------\n        list of imgaug.augmentables.batches.Batch\n            Augmented batches.", "docstring_tokens": ["Augment", "batches", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L110-L131", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.map_batches_async", "original_string": "def map_batches_async(self, batches, chunksize=None, callback=None, error_callback=None):\n        \"\"\"\n        Augment batches asynchonously.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        callback : None or callable, optional\n            Function to call upon finish. See `multiprocessing.Pool`.\n\n        error_callback : None or callable, optional\n            Function to call upon errors. See `multiprocessing.Pool`.\n\n        Returns\n        -------\n        multiprocessing.MapResult\n            Asynchonous result. See `multiprocessing.Pool`.\n\n        \"\"\"\n        assert isinstance(batches, list), (\"Expected to get a list as 'batches', got type %s. \"\n                                           + \"Call imap_batches() if you use generators.\") % (type(batches),)\n        return self.pool.map_async(_Pool_starworker, self._handle_batch_ids(batches),\n                                   chunksize=chunksize, callback=callback, error_callback=error_callback)", "language": "python", "code": "def map_batches_async(self, batches, chunksize=None, callback=None, error_callback=None):\n        \"\"\"\n        Augment batches asynchonously.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        callback : None or callable, optional\n            Function to call upon finish. See `multiprocessing.Pool`.\n\n        error_callback : None or callable, optional\n            Function to call upon errors. See `multiprocessing.Pool`.\n\n        Returns\n        -------\n        multiprocessing.MapResult\n            Asynchonous result. See `multiprocessing.Pool`.\n\n        \"\"\"\n        assert isinstance(batches, list), (\"Expected to get a list as 'batches', got type %s. \"\n                                           + \"Call imap_batches() if you use generators.\") % (type(batches),)\n        return self.pool.map_async(_Pool_starworker, self._handle_batch_ids(batches),\n                                   chunksize=chunksize, callback=callback, error_callback=error_callback)", "code_tokens": ["def", "map_batches_async", "(", "self", ",", "batches", ",", "chunksize", "=", "None", ",", "callback", "=", "None", ",", "error_callback", "=", "None", ")", ":", "assert", "isinstance", "(", "batches", ",", "list", ")", ",", "(", "\"Expected to get a list as 'batches', got type %s. \"", "+", "\"Call imap_batches() if you use generators.\"", ")", "%", "(", "type", "(", "batches", ")", ",", ")", "return", "self", ".", "pool", ".", "map_async", "(", "_Pool_starworker", ",", "self", ".", "_handle_batch_ids", "(", "batches", ")", ",", "chunksize", "=", "chunksize", ",", "callback", "=", "callback", ",", "error_callback", "=", "error_callback", ")"], "docstring": "Augment batches asynchonously.\n\n        Parameters\n        ----------\n        batches : list of imgaug.augmentables.batches.Batch\n            The batches to augment.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        callback : None or callable, optional\n            Function to call upon finish. See `multiprocessing.Pool`.\n\n        error_callback : None or callable, optional\n            Function to call upon errors. See `multiprocessing.Pool`.\n\n        Returns\n        -------\n        multiprocessing.MapResult\n            Asynchonous result. See `multiprocessing.Pool`.", "docstring_tokens": ["Augment", "batches", "asynchonously", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L133-L161", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.imap_batches", "original_string": "def imap_batches(self, batches, chunksize=1):\n        \"\"\"\n        Augment batches from a generator.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.\n\n        \"\"\"\n        assert ia.is_generator(batches), (\"Expected to get a generator as 'batches', got type %s. \"\n                                          + \"Call map_batches() if you use lists.\") % (type(batches),)\n        # TODO change this to 'yield from' once switched to 3.3+\n        gen = self.pool.imap(_Pool_starworker, self._handle_batch_ids_gen(batches), chunksize=chunksize)\n        for batch in gen:\n            yield batch", "language": "python", "code": "def imap_batches(self, batches, chunksize=1):\n        \"\"\"\n        Augment batches from a generator.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.\n\n        \"\"\"\n        assert ia.is_generator(batches), (\"Expected to get a generator as 'batches', got type %s. \"\n                                          + \"Call map_batches() if you use lists.\") % (type(batches),)\n        # TODO change this to 'yield from' once switched to 3.3+\n        gen = self.pool.imap(_Pool_starworker, self._handle_batch_ids_gen(batches), chunksize=chunksize)\n        for batch in gen:\n            yield batch", "code_tokens": ["def", "imap_batches", "(", "self", ",", "batches", ",", "chunksize", "=", "1", ")", ":", "assert", "ia", ".", "is_generator", "(", "batches", ")", ",", "(", "\"Expected to get a generator as 'batches', got type %s. \"", "+", "\"Call map_batches() if you use lists.\"", ")", "%", "(", "type", "(", "batches", ")", ",", ")", "# TODO change this to 'yield from' once switched to 3.3+", "gen", "=", "self", ".", "pool", ".", "imap", "(", "_Pool_starworker", ",", "self", ".", "_handle_batch_ids_gen", "(", "batches", ")", ",", "chunksize", "=", "chunksize", ")", "for", "batch", "in", "gen", ":", "yield", "batch"], "docstring": "Augment batches from a generator.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.", "docstring_tokens": ["Augment", "batches", "from", "a", "generator", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L163-L188", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.imap_batches_unordered", "original_string": "def imap_batches_unordered(self, batches, chunksize=1):\n        \"\"\"\n        Augment batches from a generator in a way that does not guarantee to preserve order.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.\n\n        \"\"\"\n        assert ia.is_generator(batches), (\"Expected to get a generator as 'batches', got type %s. \"\n                                          + \"Call map_batches() if you use lists.\") % (type(batches),)\n        # TODO change this to 'yield from' once switched to 3.3+\n        gen = self.pool.imap_unordered(_Pool_starworker, self._handle_batch_ids_gen(batches), chunksize=chunksize)\n        for batch in gen:\n            yield batch", "language": "python", "code": "def imap_batches_unordered(self, batches, chunksize=1):\n        \"\"\"\n        Augment batches from a generator in a way that does not guarantee to preserve order.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.\n\n        \"\"\"\n        assert ia.is_generator(batches), (\"Expected to get a generator as 'batches', got type %s. \"\n                                          + \"Call map_batches() if you use lists.\") % (type(batches),)\n        # TODO change this to 'yield from' once switched to 3.3+\n        gen = self.pool.imap_unordered(_Pool_starworker, self._handle_batch_ids_gen(batches), chunksize=chunksize)\n        for batch in gen:\n            yield batch", "code_tokens": ["def", "imap_batches_unordered", "(", "self", ",", "batches", ",", "chunksize", "=", "1", ")", ":", "assert", "ia", ".", "is_generator", "(", "batches", ")", ",", "(", "\"Expected to get a generator as 'batches', got type %s. \"", "+", "\"Call map_batches() if you use lists.\"", ")", "%", "(", "type", "(", "batches", ")", ",", ")", "# TODO change this to 'yield from' once switched to 3.3+", "gen", "=", "self", ".", "pool", ".", "imap_unordered", "(", "_Pool_starworker", ",", "self", ".", "_handle_batch_ids_gen", "(", "batches", ")", ",", "chunksize", "=", "chunksize", ")", "for", "batch", "in", "gen", ":", "yield", "batch"], "docstring": "Augment batches from a generator in a way that does not guarantee to preserve order.\n\n        Parameters\n        ----------\n        batches : generator of imgaug.augmentables.batches.Batch\n            The batches to augment, provided as a generator. Each call to the generator should yield exactly one\n            batch.\n\n        chunksize : None or int, optional\n            Rough indicator of how many tasks should be sent to each worker. Increasing this number can improve\n            performance.\n\n        Yields\n        ------\n        imgaug.augmentables.batches.Batch\n            Augmented batch.", "docstring_tokens": ["Augment", "batches", "from", "a", "generator", "in", "a", "way", "that", "does", "not", "guarantee", "to", "preserve", "order", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L190-L215", "partition": "valid"}
{"repo": "aleju/imgaug", "path": "imgaug/multicore.py", "func_name": "Pool.terminate", "original_string": "def terminate(self):\n        \"\"\"Terminate the pool immediately.\"\"\"\n        if self._pool is not None:\n            self._pool.terminate()\n            self._pool.join()\n            self._pool = None", "language": "python", "code": "def terminate(self):\n        \"\"\"Terminate the pool immediately.\"\"\"\n        if self._pool is not None:\n            self._pool.terminate()\n            self._pool.join()\n            self._pool = None", "code_tokens": ["def", "terminate", "(", "self", ")", ":", "if", "self", ".", "_pool", "is", "not", "None", ":", "self", ".", "_pool", ".", "terminate", "(", ")", "self", ".", "_pool", ".", "join", "(", ")", "self", ".", "_pool", "=", "None"], "docstring": "Terminate the pool immediately.", "docstring_tokens": ["Terminate", "the", "pool", "immediately", "."], "sha": "786be74aa855513840113ea523c5df495dc6a8af", "url": "https://github.com/aleju/imgaug/blob/786be74aa855513840113ea523c5df495dc6a8af/imgaug/multicore.py#L233-L238", "partition": "valid"}
